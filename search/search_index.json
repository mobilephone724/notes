{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#linux-related","title":"Linux Related","text":"<ul> <li>0006-linux-file</li> <li>0008-reversed_inode</li> <li>0030-intro-to-io-uring</li> </ul>"},{"location":"#others","title":"Others","text":"<ul> <li>0002-fwrapv</li> <li>0005-howToKnowWhoseIsBigger</li> <li>0007-zero2rsa</li> <li>0009-cublasdgemmtutor</li> <li>0029-link-time-optimization</li> <li>0011-roaring-bitmap</li> <li>0012-mesi</li> </ul>"},{"location":"#database-related","title":"Database Related","text":""},{"location":"#paper-reading","title":"paper reading","text":"<ul> <li>0001-database-log</li> <li>0003-google-f1</li> <li>0026-20years-database</li> <li>0027-constant_recovery</li> </ul>"},{"location":"#postgresql","title":"PostgreSQL","text":"<ul> <li>SLRU Related<ul> <li>0020-slru</li> <li>0021-clog</li> </ul> </li> <li>WAL Related<ul> <li>0022-wal-basic</li> <li>0023-wal-insert</li> </ul> </li> <li>Index Related<ul> <li>0025-hot-and-create-index</li> </ul> </li> <li>Online Scheme Change<ul> <li>0014-column-schema-change</li> <li>0028-pg_repack</li> <li>0025-hot-and-create-index</li> </ul> </li> <li>others:<ul> <li>0013-build_from_source</li> <li>0016-hashjoin</li> <li>0015-every_data_pg</li> <li>0017-pgvector</li> <li>0018-sequence_type</li> <li>0019-ssl-in-PG</li> </ul> </li> </ul>"},{"location":"0000-computer_science/0001-database-log/","title":"Basic Knowledge of Database Log","text":""},{"location":"0000-computer_science/0001-database-log/#primitive-operation-if-transactions","title":"Primitive Operation if Transactions","text":"<p>There are <code>three address spaces</code> that transaction interact in important ways: 1.  The space of disk blocks holding the database elements. 2.  The memory address space managed by buffer manager. 3.  The local address space of the transaction.</p> <p>To describe a transaction, we need some <code>operation notions</code>:(X below is a database element while t is a local varible, and we suppose a database element is no larger than a single block) 1.  INPUT(X): copy disk block containing X to memroy buffer 2.  READ(X, t): Copy X to transaction's local varible t no matter where X is, which means INPUT(X) may be executed first before READ(X,t). 3.  WRITE(X, t): Copy the value of t to X no matter where X is. 4.  OUTPUT(X): Copy the block containing X from its buffer to disk</p>"},{"location":"0000-computer_science/0001-database-log/#undo-logging","title":"undo logging","text":"<p>Undo log makes repairs to the database state by undoing the effects of transactions that may not completed before the crash.</p> <p>An Undo log has the form [T,X,v] which means transaction T has changed the database elememnt X, and its before value was v. The log record is a response to a WRITE action into memory, not an OUTPUT action.</p> <p>An undo log is suffcient to allow recovery from system failure, provided transactions and buffer manager obey two rules: 1.  If transaction T modifies database element X, then the log record of form  must be written to disk before the new value of X is written to disk 2.  If a transaction commits, the its commit log record must be written to disk only after all database elements changed by the transaction have been written to disk, but as soon there after is possible 3.  If a transaction aborts, recovery manager is need to repair the values. <p>When recovering, the recovery manager scan the log from the end. As it travels, it remembers all thos transactions T for which it has seen a [COMMIT T] record or [ABORT T] record, the: 1.  If T's COMMIT record is found, do nothing. 2.  Otherwise, T is an incomplete transaction, or aborted transaction. The recovery manager must change the value of X in the database to v,in case X had been altered just before the crash. After this, the recovery manager must write a log record [ABORT T] for each incomplete transaction T that was not previously aborted, and then flush the log</p>"},{"location":"0000-computer_science/0002-fwrapv/","title":"\"-fwrapv\" option in gcc","text":"<p>c - What does -fwrapv do? - Stack Overflow</p> <p><code>-fwrapv</code> tells the compiler that overflow of signed integer arithmetic must be treated as well-defined behavior, even though it is undefined in the C standard.</p> <p>It has two meaning full results:</p> <ol> <li>INT_MAX + 1 is overflowed to INT_MIN correctly. This is almost the default behavior in gcc.</li> <li>Don\u2019t let the compiler assume <code>x + 1 &gt; x</code>.</li> </ol> <p>See the program below</p> <pre><code>\u256d\u2500ycz at 9f38a58b120d in /home/dev 24-08-05 - 13:28:02\n\u2570\u2500\u25cb cat test.c\n#include &lt;stdio.h&gt;\n\n#define INT_MAX 0x7FFFFFFF\n\nstatic int compare(int x) {return x + 1 &gt; x;}\n\nint main()\n{\n    int x = 0;\n    printf(\"%d is bigger than %d?\\n%d\\n\", x + 1, x, compare(x));\n    x = INT_MAX;\n    printf(\"%d is bigger than %d?\\n%d\\n\", x + 1, x, compare(x));\n\n    return 0;\n}\n\u256d\u2500ycz at 9f38a58b120d in /home/dev 24-08-05 - 13:28:06\n\u2570\u2500\u25cb gcc test.c &amp;&amp; ./a.out \n1 is bigger than 0?\n1\n-2147483648 is bigger than 2147483647?\n1\n\u256d\u2500ycz at 9f38a58b120d in /home/dev 24-08-05 - 13:28:13\n\u2570\u2500\u25cb gcc test.c -fwrapv &amp;&amp; ./a.out \n1 is bigger than 0?\n1\n-2147483648 is bigger than 2147483647?\n0\n</code></pre>"},{"location":"0000-computer_science/0005-howToKnowWhoseIsBigger/","title":"Alice and Bob how to know whose number is bigger without giving away their own's","text":"","tags":["Zero\u2014Knowledge Proof"]},{"location":"0000-computer_science/0005-howToKnowWhoseIsBigger/#definiteness","title":"Definiteness\uff1a","text":"<p>Suppose Alice has number \\(i\\) and Bob has number \\(j\\) and \\(1\\leq i,j \\leq 9\\). We need a protocol for them to decide whether \\(i &lt; j\\) in the end(aside from their own values)</p>","tags":["Zero\u2014Knowledge Proof"]},{"location":"0000-computer_science/0005-howToKnowWhoseIsBigger/#solution","title":"Solution:","text":"<p>Let \\(M\\) be the set of all \\(N\\)-bit nonnegative integers</p> <p>Let \\(Q_N\\) be the set of all one-one and onto function from \\(M\\) to \\(M\\) </p> <ol> <li>Alice generates a public key from \\(Q_N\\), called \\(E_a\\), and the inverse function of \\(E_a\\) is \\(D_a\\)</li> <li>Bob picks a random value \\(x \\in M\\), compute \\(k = E_a(x)\\), then send \\(k - j\\) to Alice</li> <li>Alice computes \\(y_u=D_a(k - j + u)\\) for \\(u = 1,2,\\dots,9\\)</li> <li>Alice generates a random prime \\(p\\) of \\(N/2\\)-bit, and computes \\(z_u=y_u(\\mod p)\\) for all \\(u\\).</li> <li>Alice repeats step 4 until all \\(z_u\\) differ by at least 2 in the \\(\\mod p\\) sense</li> <li>Alice sends the \\(p\\) and \\(z_1,z_2,\\dots,z_i,z_{i+1}+1,\\dots,z_{9} +1\\) (all in \\(\\mod p\\) sense)to Bob</li> <li>Bob looks at the \\(j\\)-th value(not counting p) sent from Alice, and decides that \\(i\\geq j\\) if it is equal to \\(x \\mod p\\), or \\(i&lt;j\\) otherwise</li> </ol>","tags":["Zero\u2014Knowledge Proof"]},{"location":"0000-computer_science/0006-linux-file/","title":"APUE/Chapter3: file and I/O","text":"<p>The functions described in this chapter are often referred to as unbuffered I/O(which each read or write invokes a system call in the kernel), in contrast to the standard I/O routines</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#file-descriptors","title":"File Descriptors","text":"<ol> <li>To the kernel, all open files are referred to by file descriptors. A file descriptor is a non-negative integer. When we open an existing file or create a new file, the kernel returns a file descriptor to the process. When we want to read or write a file, we identify the file with the file descriptor that was returned by <code>open</code> or <code>creat</code> as an argument to either read or write.</li> <li>By convention, UNIX System shells associate file descriptor 0 with the standard input of a process, file descriptor 1 with the standard output, and file descriptor 2 with the standard error</li> <li>File descriptors range from 0 through OPEN_MAX\u22121</li> </ol>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#open-and-openat","title":"<code>open</code> and <code>openat</code>","text":"<ol> <li> <p>code <pre><code>#include &lt;fcntl.h&gt;\nint open(const char *path, int oflag, ... /* mode_t mode */ );\nint openat(int fd, const char *path, int oflag, ... /* mode_t mode */ );\n//Both return: file descriptor if OK, \u22121 on error\n</code></pre></p> </li> <li> <p>This function has a multitude of options, which are specified by the <code>oflag</code> argument. This argument is formed by <code>ORing</code> together one or more of the following constants from the<code>&lt;fcntl.h&gt;</code> header</p> </li> <li> <p><code>O_SYNC</code> Have each write wait for physical I/O to complete, including I/O necessary to update file attributes modified as a result of the write. <code>O_DSYNC</code> Have each write wait for physical I/O to complete, but don\u2019t wait for file attributes to be updated if they don\u2019t affect the ability to read the data just written. The O_DSYNC flag affects a file\u2019s attributes only when they need to be updated to reflect a change in the file\u2019s data (for example, update the file\u2019s size to reflect more data)</p> </li> <li> <p>O_RSYNC Have each read operation on the file descriptor wait until any pending writes for the same portion of the file are complete</p> </li> <li> <p>The fd parameter distinguishes the openat function from the open function. There are three possibilities</p> <ol> <li>The path parameter specifies an absolute pathname. In this case, the fd parameter is ignored and the openat function behaves like the open function.</li> <li>The path parameter specifies a relative pathname and the fd parameter is a file descriptor that specifies the starting location in the file system where the relative pathname is to be evaluated. The fd parameter is obtained by opening the directory where the relative pathname is to be evaluated.</li> <li>The path parameter specifies a relative pathname and the fd parameter has the special value AT_FDCWD. In this case, the pathname is evaluated starting in the current working directory and the openat function behaves like the open function.</li> </ol> </li> <li><code>openat</code> solved two problems<ol> <li>It gives threads a way to use relative pathnames to open files in directories other than the current working directory while all threads in the same process share the same current working directory, so this makes it difficult for multiple threads in the same process to work in different directories at the same time</li> <li>it provides a way to avoid time-of-check-to-time-of-use (TOCTTOU) errors whose baisc idea is that a program is vulnerable if it makes two file-based function calls where the second call depends on the results of the first call. Because the two calls are not atomic, the file can change between the two calls, thereby invalidating the results of the first call, leading to a program error.</li> </ol> </li> </ol>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#creat-function","title":"<code>creat</code> function","text":"<p><pre><code>#include &lt;fcntl.h&gt;\nint creat(const char *path, mode_t mode);\n</code></pre> This is equivalent to</p> <pre><code>open(path, O_WRONLY | O_CREAT | O_TRUNC, mode);\n</code></pre>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#close-function","title":"<code>close</code> function","text":"<p><pre><code>#include &lt;unistd.h&gt;\nint close(int fd);\n</code></pre> When a process terminates, all of its open files are closed automatically by the kernel</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#lseek-function","title":"<code>lseek</code> function","text":"<ol> <li>Every open file has an associated ''current file offset,\u2019\u2019 normally a non-negative integer that measures the number of bytes from the beginning of the file.Read and write operations normally start at the current file offset and cause the offset to be incremented by the number of bytes read or written An open file\u2019s offset can be set explicitly by calling lseek     <pre><code>#include &lt;unistd.h&gt;\noff_t lseek(int fd, off_t offset, int whence);\n</code></pre><ol> <li>If <code>whence</code> is <code>SEEK_SET</code>, the file\u2019s offset is set to offset bytes from the beginning of the file</li> <li>If <code>whence</code> is <code>SEEK_CUR</code>, the file\u2019s offset is set to its current value plus the offset. The offset can be positive or negative</li> <li>If <code>whence</code> is <code>SEEK_END</code>, the file\u2019s offset is set to the size of the file plus the offset. The offset can be positive or negative</li> </ol> </li> <li>Because a successful call to lseek returns the new file offset, we can seek zero bytes from the current position to determine the current offset <pre><code>off_t currpos;\ncurrpos = lseek(fd, 0, SEEK_CUR);\n</code></pre>     This technique can also be used to determine if a file is capable of seeking. If the file descriptor refers to a pipe, FIFO, or socket, lseek sets errno to ESPIPE and returns \u22121</li> <li>Normally,a file\u2019s current offset must be a non-negative integer . Because negative offsets are possible, we should be careful to compare the return value from lseek as being equal to or not equal to \u22121, rather than testing whether it is less than 0.</li> <li>The file\u2019s offset can be greater than the file\u2019s current size, in which case the next  write to the file will extend the file. This is referred to as creating a hole in a file and is  allowed. Any bytes in a file that have not been written are read back as 0. </li> <li>A hole in a file isn\u2019t required to have storage backing it on disk</li> </ol>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#read-function","title":"<code>read</code> function","text":"<p><pre><code>#include &lt;unistd.h&gt;\nssize_t read(int fd, void *buf, size_t nbytes);\n</code></pre> If the read is successful, the number of bytes read is returned. If the end of file is encountered, 0 is returned. There are several cases in which the number of bytes actually read is less than the amount requested: 1.  When reading from a regular file, if the end of file is reached before the requested number of bytes has been read. 2.  When reading from a terminal device. 3.  When reading from a network 4.  When reading from a pipe or FIFO. 5.  When reading from a record-oriented device 6.  When interrupted by a signal and a partial amount of data has already been read. classic definition <pre><code>int read(int fd, char *buf, unsigned nbytes);\n</code></pre> difference 1.  <code>void *</code> to <code>char *</code> 2.  <code>0</code> for end-of-file and <code>-1</code> for an error</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#write-function","title":"<code>write</code> function","text":"<p><pre><code>#include &lt;unistd.h&gt;\nssize_t write(int fd, const void *buf, size_t nbytes)\n</code></pre> The return value is usually equal to the <code>nbytes</code> argument; otherwise, an error has occurred. A common cause for a write error is either filling up a disk or exceeding the file size limit for a given process</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#io-efficiency","title":"I/O efficiency","text":"<p>an example <pre><code>#include \"apue.h\"\n#define BUFFSIZE 4096\nint main(void)\n{\n    int n;\n    char buf[BUFFSIZE];\n    while ((n = read(STDIN_FILENO, buf, BUFFSIZE)) &gt; 0)\n        if (write(STDOUT_FILENO, buf, n) != n)\n            err_sys(\"write error\");\n    if (n &lt; 0)\n        err_sys(\"read error\");\n    exit(0);\n}\n</code></pre> some caveats 1.   It reads from standard input and writes to standard output, assuming that these have been set up by the shell before this program is executed 2.   The program doesn\u2019t close the input file or output file. 3.   This example works for both text files and binary file</p> <p>how we chose the BUFFSIZE value?</p> <p></p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#file-sharing","title":"file sharing","text":"<p>The UNIX System supports the sharing of open files among different processes.</p> <p>The kernel uses three data structures to represent an open file, and the relationships among them determine the effect one process has on another with regard to file sharing</p> <ol> <li>Every process has an entry in the process table. Within each process table entry is a table of open file descriptors, which we can think of as a vector, with one entry per descriptor. Associated with each file descriptor are<ol> <li>The file descriptor flags </li> <li>A pointer to a file table entry</li> </ol> </li> <li>The kernel maintains a file table for all open files. Each file table entry contains</li> <li>The file status flags for the file, such as read, write, append, sync, and nonblocking; more on these in Section 3.14</li> <li>The current file offset</li> <li>A pointer to the v-node table entry for the file</li> <li>Each open file (or device) has a v-node structure that contains information about the type of file and pointers to functions that operate on the file. For most files, the v-node also contains the <code>i-node</code> for the file. This information is read from disk when the file is opened, so that all the pertinent information about the file is readily available. For example, the <code>i-node</code> contains the owner of the file, the size of the file, pointers to where the actual data blocks for the file are located on disk, and so on </li> </ol> <p>If two independent processes have the same file open, we could have the arrangement</p> <p>Each process that opens the file gets its own file table entry, but only a single v-node table entry is required for a given file. One reason each process gets its own file table entry is so that each process has its own current offset for the file.</p> <ol> <li>After each write is complete, the current file offset in the file table entry is incremented by the number of bytes written. If this causes the current file offset to exceed the current file size, the current file size in the i-node table entry is set to the current file offset (for example, the file is extended).</li> <li>If a file is opened with the <code>O_APPEND</code> flag, a corresponding flag is set in the file status flags of the file table entry. Each time a write is performed for a file with this append flag set, the current file offset in the file table entry is first set to the current file size from the i-node table entry. This forces every write to be appended to the current end of file.</li> <li>If a file is positioned to its current end of file using lseek, all that happens is the current file offset in the file table entry is set to the current file size from the i-node table entry (Note that this is not the same as if the file was opened with the O_APPEND flag)</li> <li>The lseek function modifies only the current file offset in the file table entry. No I/O takes place</li> </ol> <p>It is possible for more than one file descriptor entry to point to the same file table entry. This also happens after a fork when the parent and the child share the same file table entry for each open descriptor</p> <p>Note the difference in scope between the file descriptor flags and the file status flags. The former apply only to a single descriptor in a single process, whereas the latter apply to all descriptors in any process that point to the given file table entry</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#atomic-operations","title":"Atomic Operations","text":"<p>Any operation that requires more than one function call cannot be atomic, as there is always the possibility that the kernel might temporarily suspend the process between the two function calls</p> <p><pre><code>#include &lt;unistd.h&gt;\nssize_t pread(int fd, void *buf, size_t nbytes, off_t offset);\n//Returns: number of bytes read, 0 if end of file, \u22121 on error\nssize_t pwrite(int fd, const void *buf, size_t nbytes, off_t offset);\n//Returns: number of bytes written if OK, \u22121 on error\n</code></pre> If the operation is performed atomically, either all the steps are performed (on success) or none are performed (on failure).</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#dup-and-dup2-functions","title":"dup and dup2 Functions","text":"<p>An existing file descriptor is duplicated by either of the following functions</p> <p><pre><code>#include &lt;unistd.h&gt;\nint dup(int fd);\nint dup2(int fd, int fd2);\n//Both return: new file descriptor if OK, \u22121 on error\n</code></pre> With dup2, we specify the value of the new descriptor with the fd2 argument. If fd2 is already open, it is first closed. If fd equals fd2, then dup2 returns fd2 without closing it. Otherwise, the FD_CLOEXEC file descriptor flag is cleared for fd2, so that fd2 is left open if the process calls exec</p> <p></p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#syncfsync-and-fdatasync-function","title":"<code>sync</code>,<code>fsync</code> , and <code>fdatasync</code> function","text":"<p>Traditional implementations of the UNIX System have a buffer cache or page cache in the kernel through which most disk I/O passes. When we write data to a file, the data is normally copied by the kernel into one of its buffers and queued for writing to disk at some later time. This is called delayed write</p> <p>To ensure consistency of the file system on disk with the contents of the buffer cache, the sync, fsync, and fdatasync functions are provided.</p> <pre><code>#include &lt;unistd.h&gt;\nint fsync(int fd);\nint fdatasync(int fd);\n    //Returns: 0 if OK, \u22121 on error\nvoid sync(void);\n</code></pre> <p>The <code>sync</code> function simply queues all the modified block buffers for writing and returns; it does not wait for the disk writes to take place.The function sync is normally called periodically (usually every 30 seconds) from a system daemon, often called update.</p> <p>The function <code>fsync</code> refers only to a single file, specified by the file descriptor fd, and waits for the disk writes to complete before returning.(database)</p> <p>The fdatasync function is similar to fsync, but it affects only the data portions of a file. With fsync, the file\u2019s attributes are also updated synchronously</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#fcntl-function","title":"<code>fcntl</code> function","text":"<pre><code>#include &lt;fcntl.h&gt;\nint fcntl(int fd, int cmd, ... /* int arg */ );\n//Returns: depends on cmd if OK (see following), \u22121 on error\n</code></pre> <p>The fcntl function is used for five different purposes 1. Duplicate an existing descriptor (cmd = F_DUPFD or F_DUPFD_CLOEXEC) 2. Get/set file descriptor flags (cmd = F_GETFD or F_SETFD) 3. Get/set file status flags (cmd = F_GETFL or F_SETFL) 4. Get/set asynchronous I/O ownership (cmd = F_GETOWN or F_SETOWN) 5. Get/set record locks (cmd = F_GETLK, F_SETLK, or F_SETLKW)</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#ioctl-function","title":"<code>ioctl</code> function","text":"<p>The <code>ioctl</code> function has always been the catchall for I/O operations. Terminal I/O was the biggest user of this function</p> <pre><code>#include &lt;unistd.h&gt; /* System V */\n#include &lt;sys/ioctl.h&gt; /* BSD and Linux */\nint ioctl(int fd, int request, ...);\n//Returns: \u22121 on error, something else if OK\n</code></pre> <p>Normally, additional device-specific headers are required. For example, the <code>ioctl</code> commands for terminal I/O, beyond the basic operations specified by POSIX.1, all require the  header.</p> <p>Each device driver can define its own set of <code>ioctl</code> commands. The system, however, provides generic <code>ioctl</code> commands for different classes of devices</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0006-linux-file/#devfd","title":"<code>/dev/fd</code>","text":"<p>Newer systems provide a directory named <code>/dev/fd</code> whose entries are files named 0, 1, 2, and so on</p> <p>In the function call </p> <pre><code>fd = open(\"/dev/fd/0\", mode); \n</code></pre> <p>most systems ignore the specified mode, whereas others require that it be a subset of the mode used when the referenced file (standard input, in this case) was originally opened. Because the previous open is equivalent to </p> <pre><code>fd = dup(0); \n</code></pre> <p>the descriptors 0 and <code>fd</code> share the same file table entry</p> <p>For example, if descriptor 0 was opened read-only, we can only read on <code>fd</code>. Even if the system ignores the open mode and the call succeeds, we still can\u2019t write to <code>fd</code>.</p> <p>The main use of the <code>/dev/fd</code> files is from the shell. It allows programs that use pathname arguments to handle standard input and standard output in the same manner as other pathnames, like <code>cat -</code> to <code>cat /dev/fd/0</code></p> <p>The special meaning of <code>-</code> as a command-line argument to refer to the standard input or the standard output is a kludge that has crept into many programs. There are also problems if we specify - as the first file, as it looks like the start of another command-line option. Using <code>/dev/fd</code> is a step toward uniformity and cleanliness.</p>","tags":["OS","LINUX","FILE","I/O"]},{"location":"0000-computer_science/0007-zero2rsa/","title":"ZERO TO RSA","text":""},{"location":"0000-computer_science/0007-zero2rsa/#0rsa","title":"\u4ece0\u8bc1\u660eRSA","text":"<p>RSA \u7b97\u6cd5\uff08\u5373\u4e00\u4e2a\u975e\u5bf9\u79f0\u52a0\u5bc6\u7b97\u6cd5\uff09\u9664\u4e86\u5e94\u7528\u975e\u5e38\u5e7f\u6cdb\u5916\uff0c\u5176\u7279\u6027\u4e5f\u975e\u5e38\u5438\u5f15\u4eba\uff08\u8d77\u7801\u975e\u5e38\u5438\u5f15\u6211\uff09\u3002\u6211\u5728\u7f51\u4e0a\u627e\u4e86\u5f88\u591a\u5173\u4e8eRSA\u7684\u8bc1\u660e\uff0c\u8981\u4e48\u4e0d\u591f\u8be6\u7ec6\uff08\u4f8b\u5982\u7f3a\u5931\u5bf9\u524d\u7f6e\u5b9a\u7406\u7684\u8bc1\u660e\uff09\uff0c\u8981\u4e48\u9700\u8981\u5f15\u51fa\u8f83\u591a\u590d\u6742\u7684\u6570\u8bba\u6982\u5ff5\u3002\u4f5c\u8005\u672c\u8eab\u6c34\u5e73\u4e0d\u9ad8\uff0c\u8bd5\u56fe\u7ed5\u8fc7\u8fd9\u4e9b\u590d\u6742\u7684\u6982\u5ff5\uff0c\u4ece\u521d\u7b49\u6570\u5b66\u7684\u5f00\u59cb\uff0c\u5b8c\u5907\u5730\u8bc1\u660eRSA\u3002</p> <p>\u5173\u4e8eRSA\u7684\u80cc\u666f\u77e5\u8bc6\u53ef\u80fd\u5f88\u591a\uff0c\u53ef\u4ee5\u6162\u6162\u9605\u8bfb\uff0c\u6211\u5728\u6b64\u5c1d\u8bd5\u4ece\u521d\u7b49\u6570\u5b66\u5f00\u59cb\u8bc1\u660e\u3002\u8fd9\u4e9b\u80cc\u666f\u77e5\u8bc6\u7684\u8bc1\u660e\u6709\u4e00\u5b9a\u7684\u987a\u5e8f\uff0c\u5982\u679c\u8bfb\u8005\u53d1\u73b0\u67d0\u4e2a\u8bc1\u660e\u770b\u4e0d\u61c2\uff0c\u53ef\u4ee5\u5411\u524d\u7ffb\u9605\u3002</p> <p>\u53c2\u8003\u7684\u6587\u7ae0\u5982\u4e0b\uff1a\uff08\u56e0\u4e3a\u53c2\u8003\u7684\u6587\u7ae0\u592a\u591a\uff0c\u5927\u6982\u7387\u4e0d\u5168\uff09</p> <ul> <li>\u8d39\u9a6c\u5c0f\u5b9a\u7406</li> <li>\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406</li> <li>\u962e\u4e00\u5cf0\u7684\u535a\u5ba2\u2014\u2014RSA\u7b97\u6cd5\u539f\u7406\uff08\u4e00\uff09</li> <li>\u962e\u4e00\u5cf0\u7684\u535a\u5ba2\u2014\u2014RSA\u7b97\u6cd5\u539f\u7406\uff08\u4e8c\uff09</li> <li>\u521d\u7b49\u6570\u8bba\u7b14\u8bb0Part 1\uff1a \u6b27\u62c9\u5b9a\u7406</li> <li>\u7b97\u6cd5\u5b66\u4e60\u7b14\u8bb0(9)\uff1a\u9006\u5143</li> </ul>"},{"location":"0000-computer_science/0007-zero2rsa/#_1","title":"\u8d39\u9a6c\u5c0f\u5b9a\u7406","text":""},{"location":"0000-computer_science/0007-zero2rsa/#_2","title":"\u7b80\u4ecb","text":"<p>\u5982\u679c \\(p\\) \u662f\u8d28\u6570\u4e14 \\(\\mathrm{gcd}(a,p)=1\\) , \u90a3\u4e48 \\(a^{p-1}\\equiv 1\\ (\\mathrm{mod}\\ p)\\)</p> <p>\u5728\u8bc1\u660e\u8be5\u5b9a\u7406\u524d\uff0c\u5148\u8bc1\u660e\u4e00\u4e2a\u7b80\u5355\u7684\u5f15\u7406</p>"},{"location":"0000-computer_science/0007-zero2rsa/#1","title":"\u5f15\u74061","text":"<p>\u5982\u679c \\(p\\) \u662f\u8d28\u6570\uff0c\u4e14 \\(\\mathrm{gcd}(a,p)=1\\) , \u90a3\u4e48</p> \\[ \\lbrace ka \\ \\mathrm{mod}\\ p | k = \\lbrace 1,2,...,p -1 \\rbrace \\rbrace= \\lbrace 1,2,3,...,p-1 \\rbrace \\] <p>\u5373\u4e8c\u8005\u5b58\u5728\u4e00\u5bf9\u4e00\u7684\u5173\u7cfb\u3002\u7531\u4e8e\u8fd9\u4e24\u4e2a\u96c6\u5408\u7684\u5143\u7d20\u4e2a\u6570\u76f8\u540c\uff0c\u6240\u4ee5\u53ea\u8981\u8bc1\u660e\u5de6\u4fa7\u96c6\u5408\u6ca1\u6709\u91cd\u590d\u5143\u7d20\u5373\u53ef</p> <p>\u8bc1\u660e\uff1a\u5047\u8bbe\u5b58\u5728 \\(k_1\\) \u548c \\(k_2\\) \u6ee1\u8db3 \\(1 \\leq k_1 &lt; k_2 \\leq p-1\\) \uff0c\u4e14 \\(k_1a\\ \\mathrm{mod}\\ p = k_2a\\ \\mathrm{mod}\\ p\\) . \u90a3\u4e48\u53ef\u77e5</p> \\[ (k_1+p-k_2)a\\ \\mathrm{mod}\\ p = pa\\ \\mathrm{mod}\\ p=0 \\] <p>\u5373 \\((k_1+p-k_2)a\\ \\mathrm{mod}\\ p=0\\) \u3002\u7531\u4e8e \\(p\\) \u662f\u8d28\u6570\uff0c\u90a3\u4e48 \\((k_1+p-k_2)a\\) \u4e00\u5b9a\u662f \\(p\\)\u200b\u200b \u7684\u500d\u6570\uff0c\u8fd9\u663e\u7136\u4e0d\u53ef\u80fd\u3002</p>"},{"location":"0000-computer_science/0007-zero2rsa/#_3","title":"\u8bc1\u660e\u8d39\u9a6c\u5c0f\u5b9a\u7406","text":"\\[ \\begin{align} (1a)(2a)(3a)...((p-1)a)\\ \\mathrm{mod}\\ p &amp;= (a^{p-1}(p-1)!)\\ \\mathrm{mod}\\ p \\newline (1a\\ \\mathrm{mod}\\ p)(2a\\ \\mathrm{mod}\\ p)...((p-1)a\\ \\mathrm{mod}\\ p) &amp;=  (a^{p-1}(p-1)!)\\ \\mathrm{mod}\\ p\\newline (p-1)! &amp;= (a^{p-1}(p-1)!)\\ \\mathrm{mod}\\ p \\end{align} \\] <p>\u6574\u7406\u5f97 \\(a^{p-1}\\equiv 1\\ (\\mathrm{mod}\\ p)\\)\u200b</p>"},{"location":"0000-computer_science/0007-zero2rsa/#_4","title":"\u6a21\u9006\u5143","text":""},{"location":"0000-computer_science/0007-zero2rsa/#_5","title":"\u7b80\u4ecb","text":"<p>\u5b9a\u4e49\uff1a \\(a\\) \u5bf9 \\(n\\) \u7684\u6a21\u9006\u5143\u662f\u6ee1\u8db3 \\(ab\\equiv 1\\ (\\mathrm{mod}\\ n)\\) \u7684 \\(b\\)\u200b</p> <p>\u6a21\u9006\u5143\u7684\u5b58\u5728\u6027\uff1a\u6a21\u9006\u5143\u5b58\u5728\u7684\u5145\u8981\u6761\u4ef6\u662f \\(\\mathrm{gcd}(a,n)=1\\)\u200b</p> <p>\u4e3a\u8bc1\u660e\u8be5\u5b58\u5728\u6027\u5b9a\u7406\uff0c\u9700\u8981\u5148\u8bc1\u660e\u5f15\u74062</p>"},{"location":"0000-computer_science/0007-zero2rsa/#2","title":"\u5f15\u74062","text":"<p>\u82e5 \\(\\mathrm{gcd}(a,n)=g\\) \uff0c\u5219\u5b58\u5728 \\(x,y\\in Z\\)\uff0c\u6ee1\u8db3 \\(ax+ny=g\\)</p> <p>\u8bc1\u660e\uff1a</p> <ul> <li>\u8bbe\u96c6\u5408 $S=\\lbrace ax+ny|x,y\\in Z \\rbrace $\uff0c\u663e\u7136\uff0c\u5b58\u5728 \\(s\\in S\\) \u5e76\u4e14 \\(s&gt;0\\)</li> <li>\u8bbe \\(d\\) \u4e3a \\(S\\) \u4e2d\u6700\u5c0f\u7684\uff0c\u5927\u4e8e \\(0\\) \u7684\u5143\u7d20</li> <li>\u82e5 \\(a\\ \\mathrm{mod}\\ p\\neq 0\\) \uff0c\u5219\u5b58\u5728 \\(k,r\\) \u6ee1\u8db3 \\(a=kd+r\\) \uff0c\u5176\u4e2d \\(0 &lt; r &lt; k\\) \uff0c\u5e26\u5165 \\(d=ax_0+ny_0\\) \uff0c\u5f97\u5230 \\(r=a(1-kx_0)+n(-ky_0)\\) \u3002 \u663e\u7136 \\(r\\in S\\) \uff0c\u53c8 \\(0 &lt; r &lt; k\\) \uff0c\u8fd9\u4e0e \\(d\\) \u4e3a \\(S\\) \u4e2d\u6700\u5c0f\u7684\u5927\u4e8e \\(0\\) \u7684\u5047\u8bbe\u4e0d\u7b26\u3002</li> <li>\u6545 \\(a\\ \\mathrm{mod}\\ d=0\\) \uff0c\u540c\u7406 \\(n\\ \\mathrm{mod}\\ d=0\\)</li> <li>\u6240\u4ee5 \\(d\\) \u4e3a \\(a\\) \u548c \\(n\\) \u5171\u540c\u7684\u56e0\u6570\u3002\u8bbe \\(g=ld\\) \uff0c \\(l\\geq0\\) \u4e14 \\(l\\in Z\\) \uff0c\u90a3\u4e48\u6709 \\(g=ld=a(lx_0)+n(ly_0)\\) \u3002</li> </ul>"},{"location":"0000-computer_science/0007-zero2rsa/#_6","title":"\u8bc1\u660e\u6a21\u9006\u5143","text":"<p>\u73b0\u5728\u8bc1\u660e\u6a21\u9006\u5143</p> <p>\u5145\u5206\u6027</p> <ul> <li>\u5df2\u77e5 \\(\\mathrm{gcd}(a,n)=1\\) \uff0c\u5219\u6709 \\(1=ax_0+ny_0\\)</li> <li>$(ax_0+ny_0)\\ \\mathrm{mod}\\ n = ax_0 \\ \\mathrm{mod}\\ n $\u200b</li> <li>\\((ax_0+ny_0)\\ \\mathrm{mod}\\ n= 1 \\ \\mathrm{mod}\\ n=1\\)</li> <li>\u6545 \\(ax_0 \\ \\mathrm{mod}\\ n=1\\) \u5373 \\(ax_0\\ \\equiv 1\\ (\\mathrm{mod}\\ n)\\) \uff0c \\(b=x_0\\)</li> </ul> <p>\u5fc5\u8981\u6027\uff1a</p> <ul> <li>\u5df2\u7ecf\u5b58\u5728 \\(b\\) \u6ee1\u8db3 \\(ab\\ \\equiv 1\\ (\\mathrm{mod}\\ n)\\)\u200b</li> <li>\u5219\u5b58\u5728 \\(y,k\\) \u6ee1\u8db3 \\((ab+ny)\\ \\mathrm{mod}\\ n=1\\)</li> <li>\u5219\u5b58\u5728 \\(k\\) \u6ee1\u8db3 \\(ab+ny-1=kn\\)</li> <li>\u5373 \\(ab + n(y-k)=1\\)</li> <li>\u6839\u636e\u5f15\u74062\uff0c\u6709 \\(\\mathrm{gcd}(a,n)\\leq 1\\) \uff0c\u663e\u7136\u53ea\u6709 \\(\\mathrm{gcd}(a,n)=1\\)</li> </ul>"},{"location":"0000-computer_science/0007-zero2rsa/#_7","title":"\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406","text":"<p>\u65b9\u7a0b\u7ec4</p> \\[ \\begin{equation} \\begin{cases} x\\ \\equiv a_1\\ (\\mathrm{mod}\\ m_1)\\newline x\\ \\equiv a_2\\ (\\mathrm{mod}\\ m_2)\\newline ...\\newline x\\ \\equiv a_n\\ (\\mathrm{mod}\\ m_n)\\newline \\end{cases} \\end{equation} \\] <p>\u5176\u4e2d\u5bf9\u4e8e\u4efb\u610f \\(i\\neq j\\) \u6709 \\(\\mathrm{gcd}(m_i,m_j)=1\\) \uff0c\u5bf9\u4e8e\u4efb\u610f \\(a_1,a_2,...,a_n\\) \u6709\u89e3\u3002</p> <p>\u8bc1\u660e\uff1a\u5982\u4e0b</p> <p>\u5b58\u5728\u6027</p> <ul> <li>\u4ee4 \\(M=m_1m_2,...m_n=\\prod\\limits_{i=1}^{n}m_i\\)\uff0c \\(M_i=M/m_i\\)</li> <li>\u663e\u7136\u6709 \\(\\mathrm{gcd}(M_i,m_i)=1\\) \uff0c\u6545\u5b58\u5728 \\(t_i\\) \u6ee1\u8db3 \\(M_it_i\\ \\equiv 1\\ (\\mathrm{mod}\\ m_i)\\)</li> <li>\u6545\u5bf9\u4e8e \\(x\\ \\equiv a_1\\ (\\mathrm{mod}\\ m_1)\\) \uff0c\u6709 \\(a_iM_it_i\\ \\equiv a_i\\ (\\mathrm{mod}\\ m_i)\\)</li> <li>\u6545\u53ef\u5f97 \\(x\\) \u7684\u4e00\u4e2a\u89e3 \\(x=\\sum\\limits_{i=1}^{n}a_iM_it_i\\)</li> </ul> <p>\u5b8c\u5907\u6027</p> <ul> <li>\u82e5 \\(x_1,x_2\\) \u90fd\u662f\u65b9\u7a0b\u7ec4\u7684\u89e3\uff0c\u90a3\u4e48\u5bf9\u4e8e\u4efb\u610f \\(i\\in \\lbrace 1,2,...,n \\rbrace\\) \uff0c\u6709 \\((x_1-x_2)\\ \\mathrm{mod}\\ m_i=0\\)</li> <li>\u6545 \\(x_1-x_2=kM\\)</li> <li>\u6240\u4ee5\u901a\u89e3\u4e3a \\({kM+}\\sum\\limits_{i=1}^{n}a_iM_it_i\\)</li> </ul>"},{"location":"0000-computer_science/0007-zero2rsa/#_8","title":"\u6b27\u62c9\u516c\u5f0f","text":""},{"location":"0000-computer_science/0007-zero2rsa/#_9","title":"\u7b80\u4ecb","text":"<ul> <li>\u51fd\u6570 \\(\\phi(n)\\) \u4e3a \\(\\lbrace 1,2,...,n \\rbrace\\) \u4e2d\u548c \\(n\\) \u4e92\u8d28\u7684\u6570\u7684\u6570\u91cf</li> <li>\u4f8b\u5982 \\(\\phi(8)=4\\) \uff0c\u56e0\u4e3a \\(\\mathrm{gcd}(\\lbrace 1,3,5,7 \\rbrace,4)=1\\)</li> </ul>"},{"location":"0000-computer_science/0007-zero2rsa/#_10","title":"\u6027\u8d28","text":"<p>\uff08\u6027\u8d281\uff09</p> <p>\u5bf9\u4e8e\u8d28\u6570 \\(n\\) \uff0c\u6709 \\(\\phi(n)=n-1\\)</p> <p>\uff08\u6027\u8d282\uff09</p> <p>\u82e5\u5b58\u5728\u8d28\u6570 \\(p\\) \u6ee1\u8db3 \\(n=p^k\\) \uff0c\u5219 \\(\\phi(n)=p^k-p^k/p=n(1-1/p)\\) \u3002\u601d\u8def\u4e3a \\(\\lbrace 1,2,...,n \\rbrace\\) \u4e2d\u9664\u53bb \\(p\\) \u7684\u500d\u6570</p> <p>\uff08\u6027\u8d283\uff09</p> <p>\u82e5 \\(\\mathrm{gcd}(m,n)=1\\) \uff0c\u5219 \\(\\phi(mn)=\\phi(m)\\phi(n)\\) \u200b\u3002\u8bc1\u660e\u5982\u4e0b\uff1a</p> <ul> <li>\u5bf9\u4e8e\u4efb\u610f \\(0 &lt; N &lt; mn\\) \uff0c\u6709 \\(N=k_1m+p=k_2n+q\\) \u3002\u5047\u8bbe \\(N\\) \u6ee1\u8db3 \\(\\mathrm{gcd}(N,mn)=1\\)</li> <li>\u663e\u7136\uff0c \\(\\mathrm{gcd}(N,m)=1\\) \uff0c\u6545 \\(\\mathrm{gcd}(k_1m+p,m)=1\\) \uff0c\u663e\u7136 \\(\\mathrm{gcd}(p,m)=1\\) \u3002\u540c\u7406 \\(\\mathrm{gcd}(q,n)\\) \u3002</li> <li>\u5bf9\u4e8e\u65b9\u7a0b\u7ec4</li> </ul> \\[ \\begin{equation} \\begin{cases} N\\ \\equiv p\\ (\\mathrm{mod}\\ m)\\newline N\\ \\equiv q\\ (\\mathrm{mod}\\ n) \\end{cases} \\end{equation} \\] <p>\u6839\u636e\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406\uff0c\u6709\u89e3 \\(N=kmn+t_ppn+t_qqm\\) \u3002</p> <p>\u6bcf\u6709\u4e00\u7ec4 \\((p,q)\\) \uff0c\u8be5\u65b9\u7a0b\u7ec4\u5c31\u6709\u4e00\u4e2a\u89e3\u3002\u6ce8\u610f \\(\\mathrm{gcd}(p,m)=1\\) ,\u4e14 \\(\\mathrm{gcd}(q,n)\\) \u3002</p> <p>\uff08\u6027\u8d284\uff09</p> <p>\u5bf9\u4e8e \\(n=\\prod\\limits_{i=1}^rp_i^{k_i}\\) \uff0c\u6709 \\(\\phi(n)=\\phi(\\prod\\limits_{i=1}^rp_i^{k_i})=\\prod\\limits_{i=1}^r\\phi(p_i^{k_i})=\\prod\\limits_{i=1}^r(n(1-1/p_i))=n^r\\prod\\limits_{i=1}^r(1-1/p_i)\\)</p>"},{"location":"0000-computer_science/0007-zero2rsa/#_11","title":"\u6b27\u62c9\u5b9a\u7406","text":""},{"location":"0000-computer_science/0007-zero2rsa/#_12","title":"\u7b80\u4ecb","text":"<p>\u82e5 \\(n,a\\) \u4e3a\u6b63\u6574\u6570\uff0c\u4e14 \\(\\mathrm{gcd}(n,a)=1\\) \u5219 \\(a^{\\phi(n)}\\ \\equiv 1\\ (\\mathrm{mod}\\ n)\\)\u200b</p>"},{"location":"0000-computer_science/0007-zero2rsa/#_13","title":"\u6b27\u62c9\u5b9a\u7406\u7684\u8bc1\u660e","text":"<p>\u8bbe \\(\\Phi(n)=\\lbrace c_1,c_2,...,c_{\\phi(n)} \\rbrace\\) \u4e3a\u5c0f\u4e8e \\(n\\) \u4e14\u4e0e \\(n\\) \u4e92\u8d28\u7684\u6570\u7684\u96c6\u5408\uff0c\u5373 \\(\\mathrm{gcd}(c_i,n)=1\\)\u3002</p> <p>\u82e5 \\(\\mathrm{gcd}(a,n)=1\\) \uff0c\u8003\u8651\u96c6\u5408 \\(\\Phi_a(n)=\\lbrace (ac_1)\\ \\mathrm{mod}\\ n,(ac_2)\\ \\mathrm{mod}\\ n,...,(ac_{\\phi(n)})\\ \\mathrm{mod}\\ n \\rbrace\\) \u3002\u6211\u4eec\u8bc1\u660e \\(\\Phi(n)=\\Phi_a(n)\\)</p> <p>\u5148\u8bc1\u660e \\(\\Phi_a(n)\\) \u4e2d\u6ca1\u6709\u91cd\u590d\u7684\u5143\u7d20\uff0c\u82e5 \\(ac_i\\ \\equiv ac_j\\ (\\mathrm{mod}\\ n)\\) ,\u5219 \\(c_i\\ \\equiv c_j\\ (\\mathrm{mod}\\ n)\\) \uff0c\u8fd9\u663e\u7136\u9519\u8bef\u3002</p> <p>\u518d\u8bc1\u660e \\(\\mathrm{gcd}(ac_i\\ \\mathrm{mod}\\ n, n)=1\\) \u3002\u8bbe \\(ac_i=k_in+r_i\\) \uff0c\u82e5 \\(\\mathrm{gcd}(r_i,n)=g\\) \uff0c\u5219 \\(ac_i=g(k_i(n/g)+(r_i/g))\\) \u3002\u7b49\u5f0f\u53f3\u4fa7\u662f \\(g\\) \u7684\u500d\u6570\uff0c\u800c\u5de6\u4fa7\u663e\u7136\u4e0d\u662f\uff08 \\(a\\) \u548c \\(c\\) \u90fd\u4e0e \\(n\\) \u4e92\u8d28\uff09</p> <p>\u6240\u4ee5\uff1a</p> \\[ \\prod\\limits_{i=1}^{\\phi(n)}c_i \\ \\equiv \\prod\\limits_{i=1}^{\\phi(n)}c_ia(\\ \\mathrm{mod}\\ n) \\] <p>\u5373</p> \\[ \\prod\\limits_{i=1}^{\\phi(n)}c_i \\ \\equiv a^{\\phi(n)}\\prod\\limits_{i=1}^{\\phi(n)}c_i(\\ \\mathrm{mod}\\ n) \\] <p>\u663e\u7136 \\(\\mathrm{gcd}(\\prod\\limits_{i=1}^{\\phi(n)}c_i,n)=1\\)</p> <p>\u6545</p> \\[ a^{\\phi(n)}\\ \\equiv 1\\ (\\mathrm{mod}\\ n) \\]"},{"location":"0000-computer_science/0007-zero2rsa/#rsa","title":"RSA\u7b97\u6cd5","text":""},{"location":"0000-computer_science/0007-zero2rsa/#_14","title":"\u7b97\u6cd5\u6d41\u7a0b","text":"<ol> <li>\u751f\u6210\u79d8\u94a5</li> <li>\u9009\u62e9\u8fde\u4e2a\u5927\u8d28\u6570 \\(p\\) \u548c \\(q\\) \uff0c\u8ba1\u7b97 \\(n=p * q\\) </li> <li>\u8ba1\u7b97 \\(\\phi(n)=(p-1)(q-1)\\) </li> <li>\u9009\u62e9\u6b63\u6574\u6570 \\(e\\) \u6ee1\u8db3 \\(1 &lt; e &lt; \\phi(n)\\) \uff0c\u4e14 \\(\\mathrm{gcd}(e,\\phi(n))=1\\)</li> <li>\u8ba1\u7b97 \\(e\\) \u5bf9 \\(\\phi(n)\\) \u7684\u6a21\u9006\u5143 \\(d\\) \uff0c\u5373 \\(ed\\ \\equiv 1\\ (\\mathrm{mod}\\ \\phi(n))\\)</li> <li>\u5f97\u5230\u516c\u94a5\u5bf9 \\((n,e)\\) \uff0c\u79c1\u94a5\u5bf9 \\((n, d)\\)</li> <li>\u52a0\u5bc6</li> <li>\u52a0\u5bc6\u7684\u6570\u4e3a \\(m\\) \uff0c\u6ee1\u8db3 \\(0\\leq m &lt; n\\)</li> <li>\u8ba1\u7b97 \\(c=m^e\\ \\mathrm{mod}\\ n\\) \uff0c\u5219 \\(c\\) \u5c31\u662f\u5bc6\u6587</li> <li>\u89e3\u5bc6</li> <li>\\(m=c^d\\ \\mathrm{mod}\\ n\\)</li> </ol>"},{"location":"0000-computer_science/0007-zero2rsa/#_15","title":"\u7b97\u6cd5\u8bc1\u660e","text":"<p>\u663e\u7136\uff0c\u6838\u5fc3\u70b9\u5728\u4e8e\u8bc1\u660e \\(m=c^d\\ \\mathrm{mod}\\ n\\)\u200b \u3002</p> <p>\u7b80\u7b54\u5316\u7b80\u53ef\u5f97\uff0c \\(c^d\\ \\mathrm{mod}\\ n=(m^e\\ \\mathrm{mod}\\ n)^d\\ \\mathrm{mod}\\ n=m^{ed}\\ \\mathrm{mod}\\ n\\)\u200b</p> <p>\u6839\u636e \\(ed\\ \\equiv 1\\ (\\mathrm{mod}\\ \\phi(n))\\) \uff0c\u53ef\u77e5\u5b58\u5728 \\(k\\) \u4f7f\u5f97 \\(ed=k\\phi(n)+1\\) \uff0c\u5e26\u5165 \\(m^{ed}\\ \\mathrm{mod}\\ n\\) \u5f97\uff0c</p> \\[ \\begin{align} m^{ed}\\ \\mathrm{mod}\\ n&amp;= m^{k\\phi(n)+1}\\ \\mathrm{mod}\\ n \\newline                        &amp;= ((m^{\\phi(n)} \\mathrm{mod}\\ n)^k*(m\\ \\mathrm{mod}\\ n))\\ \\mathrm{mod}\\ n \\newline                        &amp;= (m(m^{\\phi(n)} \\mathrm{mod}\\ n)^k) \\ \\mathrm{mod}\\ n \\end{align} \\]"},{"location":"0000-computer_science/0007-zero2rsa/#_16","title":"\u901a\u5e38\u60c5\u51b5","text":"<p>\u5f53 \\(\\mathrm{gcd}(m,n)=1\\) \u65f6\uff08\u5373 \\(m\\neq hp\\) \u4e14 \\(m\\neq hq\\) \u65f6\uff09\uff0c\u6839\u636e\u6b27\u62c9\u5b9a\u7406 \\(m^{\\phi(n)}\\ \\equiv 1\\ (\\mathrm{mod}\\ n)\\) \uff0c\u53ef\u77e5 \\(m^{\\phi(n)} \\mathrm{mod}\\ n=1\\)\u200b</p> <p>\u5219 \\(m^{ed}\\ \\mathrm{mod}\\ n = m\\ \\mathrm{mod}\\ n=m\\) </p>"},{"location":"0000-computer_science/0007-zero2rsa/#_17","title":"\u7279\u6b8a\u60c5\u51b5","text":"<p>\u5f53 \\(m=hp\\) \u65f6\uff0c\uff08 \\(m=hq\\) \u540c\u7406\uff09\u6709 \\(m^{\\phi(n)} \\mathrm{mod}\\ n = (hp)^{(p-1)(q-1)}\\mathrm{mod}\\ pq\\)</p> <p>\u800c\u56e0\u4e3a \\(q\\) \u662f\u8d28\u6570\uff0c\u6839\u636e\u8d39\u9a6c\u5c0f\u5b9a\u7406\uff0c\u6709 \\(((hp)^{k(p-1)})^{q-1}\\ \\equiv 1\\ (\\mathrm{mod}\\ q)\\) \u3002\u6545</p> \\[ \\begin{align} ((hp)^{k(p-1)})^{q-1}hp\\ &amp;\\equiv hp\\ (\\mathrm{mod}\\ q) \\newline (hp)^{k(p-1)(q-1)+1}\\ &amp;\\equiv hp\\ (\\mathrm{mod}\\ q) \\newline (hp)^{(cd)}\\ &amp;\\equiv hp\\ (\\mathrm{mod}\\ q) \\end{align} \\] <p>\u6545\u5b58\u5728 \\(t\\) \u6ee1\u8db3</p> \\[ (hp)^{ed}=tq+hp \\] <p>\u6ce8\u610f\uff0c\u7b49\u5f0f\u5de6\u4fa7\u662f \\(p\\) \u7684\u500d\u6570\uff0c\u800c \\(p\\) \u662f\u8d28\u6570\uff0c\u6545 \\(t\\) \u5fc5\u5b9a\u662f \\(p\\) \u7684\u500d\u6570\uff0c\u8bbe \\(t=t'p\\) \uff0c\u5219</p> \\[ \\begin{align} (hp)^{ed}&amp;=t'pq+hp=t'n+hp \\newline m^{ed}\\ &amp;\\equiv m\\ (\\mathrm{mod}\\ n) \\newline m^{ed-1} \\ &amp;\\equiv 1\\ (\\mathrm{mod}\\ n) \\newline m^{k\\phi(n)} \\ &amp;\\equiv 1\\ (\\mathrm{mod}\\ n) \\end{align} \\] <p>\u540c\u7406 \\(m^{ed}\\ \\mathrm{mod}\\ n = (m(m^{\\phi(n)} \\mathrm{mod}\\ n)^k) \\ \\mathrm{mod}\\ n = m\\ \\mathrm{mod}\\ n=m\\)</p>"},{"location":"0000-computer_science/0008-reversed_inode/","title":"Number of Reversed Inode","text":""},{"location":"0000-computer_science/0008-reversed_inode/#0x0-what-is-inode","title":"0x0 what is inode","text":"<p>From https://en.wikipedia.org/wiki/Inode</p> <p>The inode (index node) is a data structure in a Unix-style file system that describes a file-system object such as a file or a directory. Each inode stores the attributes and disk block locations of the object's data</p> <p>From https://www.redhat.com/sysadmin/inodes-linux-filesystem</p> <p>By definition, an inode is an index node. It serves as a unique identifier for a specific piece of metadata on a given filesystem. Each piece of metadata describes what we think of as a file. That's right, inodes operate on each filesystem, independent of the others.</p> <p>Once you create a file, directory and so on, an inode is consumed. So it\u2019s important to remain enough inodes.</p>"},{"location":"0000-computer_science/0008-reversed_inode/#0x1-how-many-inodes-are-there","title":"0x1 How many inodes are there?","text":"<p>The inode upper limit is determined once the filesystem is initialized.</p> <p>For ext4, there are two method to appoint the number</p> <ol> <li><code>bytes-per-inode</code> : </li> <li>This is the default method to determine the number of inodes. </li> <li>This option approves an method to help estimate the inodes you may need through the average file size. <code>mke2fs</code> creates an inode for every <code>bytes-per-inode</code> bytes of space on the disk. The larger the bytes-per-inode ratio, the fewer inodes will be created.</li> <li>The default value is 16k.<ol> <li>If you create too many 8k files, the inode will run out before the disk space. So the disk space is wasted</li> <li>If you create too many 32k files, the disk space will run out before the inode. So the inode is wasted</li> </ol> </li> <li><code>number-of-inodes</code> : Overrides the default calculation of the number of inodes that should be reserved for the filesystem.</li> </ol> <p>See https://wiki.archlinux.org/title/Ext4 for detail</p>"},{"location":"0000-computer_science/0009-cublasdgemmtutor/","title":"cublasDgemm","text":""},{"location":"0000-computer_science/0009-cublasdgemmtutor/#concept","title":"concept","text":"<p><code>cublasDgemm</code> is a convenient function in cublas to compute the product of two matrix, while letter 'D' in <code>cublasDgemm</code> means <code>double</code>.</p> <p>Before reading this post, basic cuda functions like <code>cudaMalloc</code> are what you are supposed to know.</p>"},{"location":"0000-computer_science/0009-cublasdgemmtutor/#basic-use","title":"basic use","text":"<p>Definition of this function <pre><code>cublasStatus_t cublasDgemm(cublasHandle_t handle,\n                           cublasOperation_t transa, cublasOperation_t transb,\n                           int m, int n, int k,\n                           const double *alpha,\n                           const double *A, int lda,\n                           const double *B, int ldb,\n                           const double *beta,\n                           double *C, int ldc)\n</code></pre> Basic information of parameters is show in this page. Simply put, $C = \\alpha A \\times B + \\beta C $ .But it may remains confused for fresher. Below is an simple example. <pre><code>/* A is matrix in gpu memory looks like\n * 1 2 3\n * 4 5 6\n * 7 8 9\n * and ptr_A is a pointer to A\n *\n * B is matrix in gpu memory looks like\n * 1 2\n * 3 4\n * 5 6\n * and ptr_A is a pointer to A\n *\n * While memory is one-dimensional while matrix is two-dimensional, I \n * suggeset that all matrix in gpu memory are stored in column major for \n * convevient use of cublas. In this case, A in memory is like \n * [1, 4, 7, 2, 5, 8, 3, 6, 9].\n * C is a matrix to store the product of A * B\n */\n\n//get handle and stat of this function\ncublasHandle_t handle;\ncublasStatus_t stat = cublasCreate(&amp;handle);\nif (stat != CUBLAS_STATUS_SUCCESS)\n{\n    printf(\"CUBLAS initialization failed\\n\");\n    return EXIT_FAILURE;\n}\n//setting alpha and cuda\ndouble alpha = 1.0, beta = 0.0;\nstat = cublasDgemm( handle, \n                    CUBLAS_OP_N,    // we use matrix A instead of A^T\n                    CUBLAS_OP_N,    // we use matrix B instead of B^T\n                    3,              // the row of A \n                    2,              // the col of B\n                    3,              // the row of B(ro col of A)\n                    &amp;alpha,\n                    devPtrA,\n                    3,              // the leading dimension of A\n                    devPtrB,\n                    3,              // the leading dimension of B\n                    &amp;beta,\n                    devPtrC,\n                    3);             // the leading dimension of C\n/*\n * if we want to compute C = A^T * B\n */\nstat = cublasDgemm( handle, \n                    CUBLAS_OP_T,    // we use matrix A^T instead of A\n                    CUBLAS_OP_N,    // we use matrix A instead of B^T\n                    3,              // the row of A^T\n                    2,              // the col of B\n                    3,              // the row of B(or col of A^T)\n                    &amp;alpha,\n                    devPtrA,\n                    3,              // the leading dimension of A^T. \n                                    // So whether or not A or A^T, the leading dimension \n                                    // of A or A^T is the row of A, decided when A is \n                                    // initialized in memory\n                    devPtrB,\n                    3,              // the leading dimension of B\n                    &amp;beta,\n                    devPtrC,\n                    3);             // the leading dimension of C\nif (stat != CUBLAS_STATUS_SUCCESS)\n{\n    printf(\"cublasSgemm failed\\n\");\n    return EXIT_FAILURE;\n}\n</code></pre> An obvious question is what is <code>leading dimension</code> for we have know the column and row of A and B, no more information is need to finish this computation.</p> <p>My understanding of leading dimension is the <code>offest</code> to get the element in next column at the same row. An implement to compute the product of submatrix. below is an example. <code>A</code> and <code>B</code> are the same matrix in the previous example.</p> <p>And what we want to compute is \\(A[0:1][0:1] \\times B[1:2][0:1]\\). <pre><code>stat = cublasDgemm( handle, \n                    CUBLAS_OP_N,    // we use matrix A[0:1][0:1] instead of A[0:1][0:1]^T\n                    CUBLAS_OP_N,    // we use matrix B[1:2][0:1] instead of B[1:2][0:1]^T\n                    2,              // the row of A[0:1][0:1]\n                    2,              // the col of B[1:2][0:1]\n                    2,              // the row of A[0:1][0:1](or col of B[1:2][0:1])\n                    &amp;alpha,\n                    devPtrA,        // pointer to A[0][0]\n                    3,              // the offset of A[0][0] to A[0][1] is 3 of double size\n                    devPtrB + 1,    // pointer to B[1][0]\n                    3,              // the offset of B[1][0] to B[1][1] is 3 of double size\n                    &amp;beta,\n                    devPtrC,\n                    2);             // the leading dimension of C\n</code></pre> So it's the use of leading dimension which makes matrix production more flexible</p>"},{"location":"0000-computer_science/0029-link-time-optimization/","title":"conception","text":"<p>Link Time Optimization (LTO, <code>-flto</code> option in compilation) is a technique that allows the compiler to perform optimizations at the linking stage, rather than just during the compilation of individual files. This can result in better performance and more efficient code.</p>"},{"location":"0000-computer_science/0029-link-time-optimization/#what-is-lto-link-time-optimization","title":"What is LTO (Link Time Optimization)?","text":"<ul> <li>Standard Compilation: Normally, when compiling a program, each source file (.c, .cpp) is compiled into an object file (.o), and then these object files are linked together to create the final executable. During this process, the compiler only optimizes code at the individual file level.</li> <li>LTO: With Link Time Optimization, the compiler retains intermediate representations of the code in the object files (instead of just machine code) and performs additional optimization during the linking phase. This allows the compiler to optimize the entire program as a whole, not just on a per-file basis.</li> </ul>"},{"location":"0000-computer_science/0029-link-time-optimization/#key-benefits","title":"Key Benefits","text":"<ul> <li>Cross-module optimization</li> <li>Smaller code size</li> <li>Better performance</li> </ul>"},{"location":"0000-computer_science/0029-link-time-optimization/#downsides","title":"Downsides","text":"<ul> <li>Longer build times</li> <li>Increased memory usage during compilation</li> </ul>"},{"location":"0000-computer_science/0029-link-time-optimization/#example","title":"Example","text":"<p>Take the code below as an example:</p> <pre><code>/* main.c ================== */\n#include \"utils.h\"\n\nint main() {\n    int a = 10;\n    int b = 20;\n    int result = add(a, b);  // Calling function from utils.c\n    return result;\n}\n/* main.c end ================== */\n\n\n\n/* utils.c ================== */\n#include \"utils.h\"\n\nint add(int x, int y) {\n    return x + y;\n}\n/* utils.c end ================== */\n\n\n\n/* utils.h */\nint add(int x, int y);\n/* utils.h end ================== */\n</code></pre>"},{"location":"0000-computer_science/0029-link-time-optimization/#without-lto","title":"without <code>lto</code>","text":"<ol> <li>Compilation of <code>main.c</code>, The compiler compiles the code in main.c but only knows that there\u2019s a function <code>add()</code> being used. It doesn't know what <code>add()</code> does so the compiler cannot inline the <code>add()</code> function or optimize the function call away.</li> <li>Compilation of <code>utils.c</code> . The compiler compiles utils.c, but since add() is not used in utils.c, the compiler cannot optimize it further</li> <li>Linking: The linker takes the compiled object files (main.o and utils.o) and links them together into an executable. At this stage, no optimization can happen to combine or inline the <code>add()</code> function into <code>main()</code> because the optimization was limited to each translation unit.</li> </ol>"},{"location":"0000-computer_science/0029-link-time-optimization/#with-lto","title":"With LTO","text":"<ol> <li>Compilation of main.c and utils.c with <code>-flto</code>: Instead of generating machine code, the compiler retains intermediate representations (IR) for both main.c and utils.c, postponing the final code generation until the linking phase.</li> <li>Linking with -flto: During linking, the compiler now has a global view of both main() and add(). It can see that add() is just a small, simple function (a single addition), and may decide to inline the add() function directly into main().</li> </ol>"},{"location":"0000-computer_science/0029-link-time-optimization/#validation","title":"validation","text":"<pre><code>gcc --version\ngcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nCopyright (C) 2021 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n</code></pre> <p>Compile without <code>flto</code>.  (<code>-O0</code> option seem to force the compilor too stupid) <pre><code>gcc main.c utils.c -O1\nobjdump -d a.out &gt; without_flto.asm\n</code></pre></p> <p>see the <code>without_flto.asm</code> file <pre><code>0000000000000714 &lt;main&gt;:\n 714:   a9bf7bfd    stp x29, x30, [sp, #-16]!\n 718:   910003fd    mov x29, sp\n 71c:   52800281    mov w1, #0x14                   // #20\n 720:   52800140    mov w0, #0xa                    // #10\n 724:   94000003    bl  730 &lt;add&gt;\n 728:   a8c17bfd    ldp x29, x30, [sp], #16\n 72c:   d65f03c0    ret\n\n0000000000000730 &lt;add&gt;:\n 730:   0b010000    add w0, w0, w1\n 734:   d65f03c0    ret\n</code></pre></p> <p>Compile with <code>flto</code>, the computation seem to be finished during compilation  <pre><code>gcc main.c utils.c -O1 -flto\nobjdump -d a.out &gt; with_flto.asm\n</code></pre></p> <pre><code>0000000000000714 &lt;main&gt;:\n 714:   528003c0    mov w0, #0x1e                   // #30\n 718:   d65f03c0    ret\n\n// No add() function completely\n</code></pre>"},{"location":"0000-computer_science/0030-intro-to-io-uring/","title":"Introduction To IO_URING","text":""},{"location":"0000-computer_science/0030-intro-to-io-uring/#related-blogs","title":"Related blogs","text":"<ul> <li>https://cloud.tencent.com/developer/article/2187655</li> <li>io_uring by example: Part 1 \u2013 Introduction \u2013 Unixism</li> </ul>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#intro-from-chatgpt","title":"Intro From chatgpt","text":"<p>io_uring is a Linux kernel feature introduced in version 5.1, designed to improve the performance and efficiency of asynchronous I/O operations. It aims to reduce the overhead associated with I/O system calls like read(), write(), and poll() by minimizing the number of context switches between user space and kernel space, which traditional I/O mechanisms (e.g., epoll and aio) suffer from. Here\u2019s a breakdown of how io_uring works and its key features:</p>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#1-how-io_uring-works","title":"1. How io_uring Works","text":"<p>At its core, io_uring is based on two ring buffers: a submission queue (SQ) and a completion queue (CQ). These queues are shared between user space and the kernel, allowing efficient communication without frequent system calls. Here\u2019s how it operates:</p> <ul> <li>Submission Queue (SQ): This is where user space places I/O requests (such as reads or writes) that it wants the kernel to execute.</li> <li>Completion Queue (CQ): After the kernel processes an I/O request, it places the result in this queue, where user space can check for completion.</li> </ul> <p>By sharing these queues between user space and the kernel, io_uring reduces the need for expensive system calls (such as epoll_wait()), as requests and completions can be submitted and polled in batches.</p>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#2-key-features-of-io_uring","title":"2. Key Features of io_uring","text":"<ul> <li>Low Latency: By minimizing context switches and avoiding the need to make multiple system calls for each operation, io_uring reduces I/O latency significantly compared to older asynchronous I/O methods.</li> <li>High Throughput: io_uring is designed to handle a large number of concurrent I/O requests efficiently, making it ideal for applications with high I/O workloads, such as databases, web servers, and high-performance networking services.</li> <li>Kernel Bypass: Instead of relying on system calls for every I/O request, user space can submit requests directly to the kernel through the submission queue, thus bypassing the traditional syscall overhead.</li> <li>Multishot Requests: io_uring supports multishot operations, allowing user space to issue a single request that results in multiple completions (e.g., for accept() or recv()), reducing the need to resubmit similar operations.</li> <li>Zero-Copy Support: io_uring supports zero-copy networking, reducing the overhead of copying data between user space and kernel space during network I/O operations.</li> </ul>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#3-use-cases","title":"3. Use Cases","text":"<ul> <li>High-performance Networking: io_uring is a good fit for applications like web servers and proxy servers that handle a large number of concurrent network connections and need efficient I/O.</li> <li>Databases: Databases can leverage io_uring to improve the performance of disk I/O operations, especially in environments where I/O performance is a bottleneck.</li> <li>File I/O in High-throughput Systems: File servers or systems requiring a high rate of disk operations, such as video streaming services, can use io_uring to optimize large-scale reads and writes.</li> </ul>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#4-advantages-over-previous-methods","title":"4. Advantages over Previous Methods","text":"<ul> <li>Compared to epoll io_uring provides a more efficient mechanism for handling asynchronous I/O compared to epoll. With epoll, a system call is required for each I/O operation, leading to higher context switching overhead.</li> <li>Compared to aio The traditional Linux asynchronous I/O (AIO) API is more limited and has some issues with performance and ease of use. io_uring offers a better interface and improved performance, especially for disk I/O.</li> </ul>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#5-example","title":"5. Example","text":"<pre><code>/*\n * sudo apt install liburing-dev\n * gcc test.c -luring\n */\n\n#include &lt;liburing.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;string.h&gt;\n#include &lt;unistd.h&gt;\n\nint main() {\n    struct io_uring ring;\n    struct io_uring_sqe *sqe;\n    struct io_uring_cqe *cqe;\n    char buffer[4096];\n\n    int fd = open(\"testfile.txt\", O_RDONLY);\n\n    // Initialize io_uring\n    io_uring_queue_init(8, &amp;ring, 0);\n\n    // Get the submission queue entry\n    sqe = io_uring_get_sqe(&amp;ring);\n\n    // Prepare a read operation\n    io_uring_prep_read(sqe, fd, buffer, sizeof(buffer), 0);\n\n    // Submit the I/O request\n    io_uring_submit(&amp;ring);\n\n    // Wait for the completion\n    io_uring_wait_cqe(&amp;ring, &amp;cqe);\n\n    // Check result\n    if (cqe-&gt;res &gt; 0) {\n        write(1, buffer, cqe-&gt;res); // Write to stdout\n    }\n\n    // Mark completion as seen\n    io_uring_cqe_seen(&amp;ring, cqe);\n\n    // Clean up\n    close(fd);\n    io_uring_queue_exit(&amp;ring);\n\n    return 0;\n}\n</code></pre>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#how-does-linux-kernel-know-the-request-in-sq","title":"How does linux kernel know the request in SQ","text":"<p>The Linux kernel knows that there is a new request in the Submission Queue (SQ) of io_uring through a combination of techniques</p>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#1-pollingbatching-without-immediate-notification","title":"1. Polling/Batching (Without Immediate Notification).","text":"<p>In this mode, the kernel checks the submission queue periodically, often in conjunction with other kernel operations.</p> <ol> <li>Polling Loop: The kernel, while executing other I/O or task scheduling, can periodically check the submission queue for new requests.</li> <li>Batch Submission: User-space applications can also batch multiple I/O operations before invoking a system call (<code>io_uring_submit()</code>) to notify the kernel that there are new requests to process.</li> </ol>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#2-system-call-notification-io_uring_enter","title":"2. System Call Notification (<code>io_uring_enter()</code>)","text":"<p>making a system call, specifically <code>io_uring_enter()</code> man page</p> <pre><code>#include &lt;liburing.h&gt;\nint io_uring_enter(unsigned int fd, unsigned int to_submit,\n                   unsigned int min_complete, unsigned int flags,\n                   sigset_t *sig);\nint io_uring_enter2(unsigned int fd, unsigned int to_submit,\n                    unsigned int min_complete, unsigned int flags,\n                    sigset_t *sig, size_t sz);\n</code></pre> <p>When the system call is made, the kernel starts processing the requests placed in the submission queue by the user space.</p>"},{"location":"0000-computer_science/0030-intro-to-io-uring/#3-submission-queue-polling-kernel-side-polling","title":"3. Submission Queue Polling (Kernel-side Polling)","text":"<p>In high-performance environments, where the application requires extremely low latency, submission queue polling can be enabled. This feature allows the kernel to continuously poll the submission queue for new I/O requests without requiring the user space to make a system call. This mode is often used for applications that need to minimize latency and can afford the CPU overhead of polling.</p> <p>SQPOLL Mode: In this mode, the kernel spawns a kernel thread that continuously polls the submission queue for new requests. This eliminates the need for system calls and greatly reduces the latency for request submissions, making it suitable for real-time or high-frequency I/O operations.</p> <ol> <li>To use SQPOLL mode, the user needs to set the <code>IORING_SETUP_SQPOLL</code> flag during <code>io_uring_setup()</code>, which enables kernel-side polling of the submission queue.</li> <li>This mode has the advantage of minimizing user-to-kernel transitions, but it can be CPU-intensive because the kernel is constantly polling for new requests.</li> </ol>"},{"location":"0010-paper_reading/0003-google-f1/","title":"Read Google F1","text":"","tags":["schema"]},{"location":"0010-paper_reading/0003-google-f1/#abstract","title":"Abstract","text":"<ul> <li>a protocol for schema evolution in a globally distributed database management system with shared data, stateless servers, and no global membership.<ul> <li>asynchronous</li> <li>all servers can access and update all data during a schema change</li> </ul> </li> </ul>","tags":["schema"]},{"location":"0010-paper_reading/0003-google-f1/#introduction","title":"INTRODUCTION","text":"<ul> <li>Schema evolution:  the ability to change a database\u2019s definition without the loss of data</li> <li>F1 is built on top of Spanner, a globally distributed KV data store</li> </ul>","tags":["schema"]},{"location":"0010-paper_reading/0003-google-f1/#main-feature","title":"Main feature","text":"<p>The main features of F1 that impact schema changes are:</p> <ul> <li>Massively distributed: </li> <li>An instance of F1 consists of hundreds of individual F1 servers</li> <li>Relational schema: </li> <li>Each F1 server has a copy of a relational schema that describes tables, columns, indexes, and constraints. </li> <li>Any modification to the schema requires a distributed schema change to update all servers</li> <li>Shared data storage:</li> <li>All F1 servers in all datacenters have access to all data stored in Spanner.</li> <li>Stateless servers:</li> <li>F1 servers must tolerate machine failures, preemption(\u53d6\u4ee3), and loss of access to network resources<ul> <li>clients may connect to any F1 server, even for different statements in the same transaction.</li> </ul> </li> <li>No global membership:</li> <li>no reliable mechanism for determining currently running F1 servers, and explicit global synchronization is not possible</li> </ul> <p></p> <p>several constraints on the schema change process:</p> <ul> <li>Full data availability: </li> <li>the availability of the data managed by F1 is paramount(\u81f3\u4e3a\u91cd\u8981\u7684)</li> <li>it is unacceptable to take even a portion of the database offline during a schema change (e.g., locking a column to build an index).</li> <li>Minimal performance impact:</li> <li>the F1 schema changes rapidly to support new features</li> <li>Asynchronous schema change</li> <li>In other words, different F1 servers may transition to using a new schema at different times</li> </ul> <p>These requirements influenced the design in several ways</p> <ul> <li>Since all data must be as available as possible, we do not restrict access to data undergoing reorganization.</li> <li>Because the schema change must have minimal impact on user transactions, we allow transactions to span an arbitrary number of schema changes, although we do not automatically rewrite queries to conform to the schema in use</li> <li>Applying schema changes asynchronously on individual F1 servers means that multiple versions of the schema may be in use simultaneously</li> </ul>","tags":["schema"]},{"location":"0010-paper_reading/0003-google-f1/#an-example","title":"An example","text":"<ul> <li>Consider a schema change from schema <code>S1</code> to schema <code>S2</code> that adds index <code>I</code> on table <code>R</code></li> <li>Assume two different servers, <code>M1</code> and <code>M2</code>, execute the following sequence of operations:</li> <li>Server <code>M2</code>, using schema <code>S2</code>, inserts a new row <code>r</code> to table <code>R</code>. Because <code>S2</code> contains index <code>I</code>, server <code>M2</code> also adds a new index entry corresponding to <code>r</code> to the key\u2013 value store.</li> <li>Server <code>M1</code>, using schema <code>S1</code>, deletes <code>r</code>. Because <code>S1</code> does not contain <code>I</code>, <code>M1</code> removes <code>r</code> from the key\u2013value store but fails to remove the corresponding index entry in <code>I</code>.</li> <li>The second delete leaves the database corrupt.</li> </ul> <p>We consider not only changes to the logical schema, such as the addition or removal of columns, but also changes to the physical schema like adding or removing secondary indexes. </p> <p>By ensuring that:</p> <ul> <li>no more than two schema versions are in use at any given time</li> <li>those schema versions have specific properties?</li> </ul> <p>enables distributed schema changes in a way that</p> <p>does not require global membership, implicit or explicit synchronization between nodes, or the need to retain old schema versions once a schema change is complete</p>","tags":["schema"]},{"location":"0010-paper_reading/0003-google-f1/#background","title":"BackGround","text":"<p>In this section, we:</p> <ul> <li>separate the interface provided by the key\u2013value store from its implementation</li> <li>show how we map traditional relational database features into this unique setting</li> </ul>","tags":["schema"]},{"location":"0010-paper_reading/0003-google-f1/#key-value-store","title":"Key-value store","text":"<ul> <li>F1 assumes the key\u2013value store supports three operations</li> <li>put: insert a value with a given key</li> <li>del: delete a value with a given key</li> <li>get: returns any stored values whose key matches a given prefix</li> <li> <p>Note that put and del reference exactly one key\u2013value pair, while get may return multiple key\u2013value pairs</p> </li> <li>Two more requirements<ul> <li>Commit timestamps: Every key\u2013value pair has a last-modified timestamp which is updated atomically by the key\u2013value store</li> <li>Atomic test-and-set support:  Multiple get and put operations can be executed atomically</li> </ul> </li> </ul>","tags":["schema"]},{"location":"0010-paper_reading/0003-google-f1/#relational-schema","title":"Relational schema","text":"<ul> <li>An F1 schema is a set of table definitions that enable F1 to interpret the database located in the key\u2013value store</li> <li>Each table definition has:</li> <li>a list of columns</li> <li>a list of secondary indexes</li> <li>a list of integrity constraints(foreign key or index uniqueness constraints)</li> <li>a list of optimistic locks.<ul> <li>required columns that cannot be read directly by client transactions</li> </ul> </li> <li>A subset of columns in a table forms the primary key of the table</li> <li>We call a column required if its value must be present in every row. All primary-key columns are implicitly required, while non-key columns may be either required or optional</li> </ul>","tags":["schema"]},{"location":"0010-paper_reading/0003-google-f1/#row-representation","title":"Row representation","text":"<ul> <li> <p>one pair for each non-primary-key column</p> </li> <li> <p>Each key logically includes</p> </li> <li>the name of the table,</li> <li>the primary key values of the containing row,</li> <li>the name of the column whose value is stored in the pair</li> <li>Although this appears to needlessly repeat all primary key values in the key for each column value, in practice, F1\u2019s physical storage format eliminates this redundancy</li> </ul> <p> </p> <ul> <li>A secondary index</li> <li>covers a non-empty subset of columns on a table</li> <li>is itself represented by a set of key\u2013value pairs in the key\u2013 value store</li> <li>Each row in the indexed table has an associated index key\u2013value pair<ul> <li>The key for this pair is formed by concatenating</li> <li>the table name</li> <li>the index name</li> <li>the row\u2019s indexed column values</li> <li>and the row\u2019s primary key values</li> </ul> </li> <li>We denote the index key for row \\(r\\) in index \\(I\\) as \\(k_r(I)\\)</li> <li>the special exists column doesn't have the associated value</li> </ul>","tags":["schema"]},{"location":"0010-paper_reading/0003-google-f1/#relational-operations","title":"Relational operations","text":"<p>F1 supports a set of standard relational operations: + \\(insert(R,vk_r,vc_r)\\) inserts row r to table R with primary key values \\(vk_r\\) and non-key column values \\(vc_r\\). Insert fails if a row with the same primary key values already exists in table R. + \\(delete (R, vk_r )\\) + \\(update(R,vk_r,vc_r)\\) + \\(query(\\vec{R},\\vec{C},P)\\) :returns a projection \\(\\vec{C}\\) of rows from tables in \\(\\vec{R}\\) that satisfy predicate \\(P\\) .</p>","tags":["schema"]},{"location":"0010-paper_reading/0011-roaring-bitmap/","title":"roaring bitmap","text":""},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x0-introduction","title":"0x0 Introduction","text":"<p>A bitmap, also known as a bit array or bitset, is a data structure that represents a fixed-size sequence of bits.  That is the value of the ith bit representing the existence of the the ith object. Bare bitmap can cost much memory according to the total substantial data size, even if we have stored little infomation. Roaring bitmap provide a new method to compress the bitmap structure.</p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x1-related-infomation","title":"0x1 Related Infomation:","text":"<ul> <li>blogs:</li> <li>(Very Important Introduction) [Blog of Vikram Oberoi]:A primer on Roaring bitmaps: what they are and how they work</li> <li>[blog of charlieroro] roaring bitmaps</li> <li>\u3010\u6728\u4e1c\u5c45\u58eb\u3011\uff1a\u4e0d\u6df1\u5165\u800c\u6d45\u51fa Roaring Bitmaps \u7684\u57fa\u672c\u539f\u7406</li> <li>paper </li> <li>Introduction: 0011-010-Better bitmap performance with Roaring bitmaps.pdf</li> <li>Opitmazition: 0011-011-Consistently faster and smaller compressed bitmaps with Roaring.pdf</li> </ul>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x2-introduction-to-roaring-bitmap","title":"0x2 Introduction TO Roaring Bitmap","text":""},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x21-two-types-of-containers","title":"0x21 two types of containers","text":"<p>We partition the range of 32-bit indexes ([0, n)) into chunks of \\(2^{16}\\) integers sharing the same 16 most significant digits. We use specialized containers to store their 16 least significant bits.</p> <p>(One chunk' size is up to 8KB, that is 4096 integers.)</p> <p>When a chunk contains no more than 4096 integers, we use a sorted array of packed 16-bit integers. When there are more than 4096 integers, we use a \\(2^{16}\\)\u200b-bit bitmap. Thus, we have two types of containers: an array container for sparse chunks and a bitmap container for dense chunks.</p> <p>Since the size of a chunk is up to 8KB, we may save much memoy if the cardinality is small. Don't worry about the memory allocator, it can deal with the small memory with local buffer. And I believe it's the most important meaning of two types of containers.</p> <p></p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x22-conversion-between-the-two-types-of-container","title":"0x22 conversion between the two types of container","text":"<p>timing</p> <ul> <li>When removing an integer, a bitmap container might become an array container if its cardinality reaches 4096.</li> <li>When adding an integer, an array container might become a bitmap container when its cardinality exceeds 4096.</li> </ul> <p>method</p> <ul> <li>When this happens, a new container is created with the updated data while the old container is discarded.</li> <li>Converting an array container to a bitmap container is done by creating a new bitmap container initialized with zeros, and setting the corresponding bits.</li> <li>To convert a bitmap container to an array container, we extract the location of the set bits using an optimized algorithm</li> </ul> <p></p> <p></p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x23-index-array","title":"0x23 index array","text":"<p>To check for the presence of a 32-bit integer x, we first seek the container corresponding to \\(x/2^{16}\\) using binary search. If a bitmap container is found, we access the (x mod \\(2^{16}\\))th bit. If an array container is found, we use a binary search again</p> <p>The containers are stored in a dynamic array with the shared 16 most-significant bits: this serves as a first-level index. The array keeps the containers sorted by the 16 most-significant bits.</p> <p></p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x3-set-operations","title":"0x3 set operations","text":"<p>There are </p> <ul> <li>Two basic opertions: union (bitwise OR) and intersection (bitwise AND); </li> <li>And three container type combinations: bitmap vs bitmap, array vs array annd bitmap vs array</li> </ul>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x31-bitmap-vs-bitmap","title":"0x31 bitmap vs bitmap","text":"<p>union operation(the result must be a bitmap container) :</p> <p> It might seem like computing bitwise ORs and computing the cardinality of the result</p> <p>would be significantly slower than merely computing the bitwise ORs. However, four factors mitigate this potential problem</p> <ol> <li>[built in cpu instructions]: popular processors (Intel, AMD, ARM) have fast instructions to compute the number of ones in a word. Intel and AMD\u2019s popcnt instruction has a throughput as high as one    operation per CPU cycle.</li> <li>[Java Opitimization]: Recent Java implementations translate a call to Long.bitCount into such fast    instructions.</li> <li>[superscalar]: Popular processors are superscalar: they can execute several operations at once. Thus, while we retrieve the next data elements, compute their bitwise OR and store it in memory, the processor can apply the popcnt instruction on the last result and increment the cardinality counter accordingly.</li> <li>[enough L1 cache]: For inexpensive data processing operations, the processor may not run at full capacity due to cache misses.</li> </ol> <p>intersection operation:</p> <p>For computing intersections, we use a less direct route. First, we compute the cardinality of the result, using 1024 bitwise AND instructions. If the cardinality is larger than 4096, then we proceed as with the union, writing the result of bitwise ANDs to a new bitmap container. Otherwise, we create a new array container. We extract the set bits from the bitwise ANDs on the fly. See chapter \"0x22\" for detail</p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x32-bitmap-vs-array","title":"0x32 bitmap vs array","text":"<ul> <li>intersection(the result must be an array container)\uff1awe iterate over the sorted dynamic array, and verify the existence of each 16-bit integer in the bitmap container. The result is written out to an array container</li> <li>Unions(the result must be a bit map container)\uff1awe create a copy of the bitmap and simply iterate over the array, setting the corresponding bits</li> </ul>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x33-array-vs-array","title":"0x33 Array vs Array","text":"<ul> <li>For unions: </li> <li>if the sum of the cardinalities is no more than 4096(the result must be an array container): we use a merge algorithm between the two arrays</li> <li>otherwise: Otherwise, we set the bits corresponding to both arrays in a bitmap container. We then compute the cardinality using fast instructions. If the cardinality is no more than 4096, we convert the bitmap container to an array containe.</li> <li>intersection(the result must be an array container): </li> <li>if the two arrays have cardinalities that differ by less than a factor of 64: merge</li> <li>otherwise: galloping intersection</li> </ul> <p>Galloping is superior to a simple merge when one array (\\(r\\)) is much smaller than other one (\\(f\\)) because it can skip many comparisons. Starting from the beginning of both arrays, we pick the next available integer \\(r_i\\) from the small array \\(r\\) and seek an integer at least as large \\(f_j\\) in the large array \\(f\\) , looking first at the next value, then looking at a value twice as far, and so on. Then, we use binary search to advance in the second list to the first value larger or equal to \\(r_i\\) .</p> <p>Galloping(exponential search) Introduction</p> <p>The initial value of <code>bound</code> can alway advance in each search.</p> <pre><code>// Returns the position of key in the array arr of length size.\ntemplate &lt;typename T&gt;\nint exponential_search(T arr[], int size, T key)\n{\n    if (size == 0) {\n        return NOT_FOUND;\n    }\n\n    int bound = 1;\n    while (bound &lt; size &amp;&amp; arr[bound] &lt; key) {\n        bound *= 2;\n    }\n\n    return binary_search(arr, key, bound/2, min(bound + 1, size));\n}\n</code></pre>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x34-in-place-operations","title":"0x34 in place operations","text":"<ul> <li>When computing the union between two bitmap containers, we can modify one of the two bitmap containers instead of generating a new bitmap container. Similarly, for the intersection between two bitmap containers, we can modify one of the two containers if the cardinality of the result exceeds 4096</li> <li>When computing the union between an array and a bitmap container, we can write the result to the bitmap container, by iterating over the values of the array container and setting the corresponding bits in the bitmap container. We can update the cardinality each time by checking whether the word value has been modified.</li> </ul>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x4-the-run-type-container","title":"0x4 The \"run\" type container","text":""},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x41-to-introduction-to-run","title":"0x41  To introduction to \"run\"","text":"<p>The original Roaring has a limitation in some scenarios because it does not compress long runs of values. Indeed, given a bitset made of a few long runs (e.g., all integers in [10, 1000]), Roaring\u2014as presented so far\u2014can only offer suboptimal compression. If we consider the case of a bitmap made of all integers in [10, 1000], Roaring without support for runs would use 8 kB, whereas a few bytes ought to suffice.</p> <ol> <li>Such unnecessarily large bitmaps can stress memory bandwidth.</li> <li>computing the intersection of two bitmaps representing the ranges [10, 1000] and [500, 10000] can be done in a few cycles when using RLE-compressed bitmaps. But the original Roaring would require intersecting two bitmap containers and possibly thousands of cycles. See chapter \"0xF1\" for detail.</li> </ol> <p>To solve this problem, we decided to add a third type of container to Roaring, one that is ideally suited to coding data made of runs of consecutive values. The new container is conceptually simple: given a run (e.g., [10, 1000]), we store the starting point (10) and its length minus one (990). By packing the starting points and the lengths in pairs, using 16 bits each, we preserve the ability to support fast random access by binary search through the coded runs</p> <p>The run container, is made of a packed array of pairs of 16-bit integers. The first value of each pair represents a starting value, whereas the second value is the length of a run. For example, we would store the values 11, 12, 13, 14, 15 as the pair 11, 4 where 4 means that beyond 11 itself, there are 4 contiguous values that follow. </p> <p>In addition to this packed array, we need to maintain the number of runs stored in the packed array. Like the array container, the run container is stored in a dynamic array. During serialization, we write out the number of runs, followed by the corresponding packed array.</p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x42-decide-the-best-container","title":"0x42 Decide The Best Container","text":"<p>To decide the best container type, we are motivated to minimize storage. In serialized form, a run container uses 2 + 4r bytes(16-bit integer is 2 bytes and we need a pair; plus the number of runs) given r runs, a bitmap container always uses 8192 bytes and an array container uses 2c + 2 bytes, where c is the cardinality. Therefore, we apply the following rules:</p> <ul> <li>All array containers are such that they use no more space than they would as a bitmap container: they contain no more than 4096 values.</li> <li>Bitmap containers use less space than they would as array containers: they contain more than 4096 values.</li> <li>A run container is only allowed to exist if it is smaller than either the array container or the bitmap container that could equivalently store the same values. </li> <li>If the run container has cardinality greater than 4096 values, then the number of runs must be no more than \\(\\lceil(8192 \u2212 2)/4\\rceil = 2047\\)  runs. (Or it must be converted to a bitmap container)</li> <li>If the run container has cardinality no more than 4096, then the number of runs must be less than half the cardinality. (Or it must be converted to an array container)</li> </ul> <p>**So, the critical step in deciding whether an array or bitmap container should be converted to a run container is to count the number of runs of consecutive numbers it contains. **</p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x43-compute-the-number-of-runs","title":"0x43 Compute The Number Of Runs","text":"<p>For array containers, we count this number by iterating through the 16-bit integers and comparing them two by two in a straightforward manner. Because array containers have at most 4096 integers, this computation is expected to be fast.</p> <p>For bitmap containers, the below algorithm shows how to compute the number of runs. </p> <p></p> <p>We can illustrate the core operation of the algorithm using a single 32-bit word containing 6 runs of consecutive ones:</p> <p></p> <ul> <li>We can verify that \\(\\mathrm{bitCount}((C_i \\ll 1)\\ \\mathrm{ANDNOT}\\ C_i) = 6\\), that is, we have effectively computed the number of runs.  (\\(a\\ \\mathrm{ANDNOT}\\ b\\)is true iff a=1 and b=0)</li> <li>In the case where a run continues up to the left-most bit, and does not continue in the next word, it does not get counted, but we add another term ((\\(C_i \\gg 63\\)) ANDNOT \\(C_i+1\\) when using 64-bit words) to check for this case.</li> </ul> <p>Nevertheless, the computation may be expensive\u2014exceeding the cost of computing the union or intersection between two bitmap containers. Thus, instead of always computing the number of runs exactly, we rely on the observation that no bitmap container with more than 2047 runs should be converted. As soon as we can produce a lower bound exceeding 2047 on the number of runs, we can stop. An exact computation of the number of runs is important only when our lower bound is less than 2048. In short: estimate the lower bound count of runs first, and only do the precise computation if the lower bound is less than 2048.</p> <p>There are several method to implement the heuristic algorithm, and see the paper for details.</p> <p></p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x44-logical-operations","title":"0x44 Logical operations","text":"<p>There are many necessary logical operations, but we present primarily the union and intersection.</p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0x441-bitmap-vs-bitmap","title":"0x441 Bitmap vs Bitmap:","text":""},{"location":"0010-paper_reading/0011-roaring-bitmap/#0xf-appendix","title":"0xF appendix","text":""},{"location":"0010-paper_reading/0011-roaring-bitmap/#0xf1-rle-based-compressed-bitmaps","title":"0xF1 RLE-based compressed bitmaps","text":"<p>There are many RLE-based compression formats. </p>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0xf11-introduction-to-wah","title":"0xF11 Introduction To WAH","text":"<p>For example, WAH organizes the data in literal and fill words. </p> <ul> <li>Literal words contain a mix of W \u2212 1 zeros and ones (e.g., \\(01011 \u00b7 \u00b7 \u00b7 01\\)) where W denotes the word size in bits: typically W = 32 or W = 64. </li> <li>Fill words are made of just W \u2212 1 ones or just W \u2212 1 zeros (i.e., \\(11 \u00b7 \u00b7 \u00b7 11\\) or \\(00 \u00b7 \u00b7 \u00b7 00\\)). WAH compresses sequences of consecutive identical fill words</li> </ul> <p>The most significant bit of each word distinguishes between fill and literal words</p> <ul> <li>When it is set to one, the remaining W \u22121 bits store the W \u22121 bits of a literal word.</li> <li>When it is set to zero, the second most significant bit indicates the bit value whereas the remaining bits are used to store the number of consecutive identical fill words (the run length)</li> </ul>"},{"location":"0010-paper_reading/0011-roaring-bitmap/#0xf12-introduction-to-concise","title":"0xF12 Introduction To Concise","text":"<p>Concise is a variation that reduces the memory usage when the bitmap is _moderately sparse. _Instead of storing the run length using \\(W \u2212 2\\) bits, Concise uses only \\(W \u2212 2 \u2212 \\lceil log2(W )\\rceil\\) bits to indicate a run length \\(r\\), reserving \\(\\lceil log2(W )\\rceil\\) bits to store a value \\(p\\). When \\(p\\) is non-zero, we decode \\(r\\) fill words, plus a single \\(W \u2212 1\\) bit word with its \\(p^{th}\\) bit flipped.</p> <p>Below is an example: </p>"},{"location":"0010-paper_reading/0012-mesi/","title":"MESI AND MEMORY_BARRIER: paper reading","text":"<ul> <li>paper </li> <li>Introduction: Memory Barriers: a Hardware View for Software Hackers</li> </ul>"},{"location":"0010-paper_reading/0012-mesi/#0x0-why-we-need-memory-barrier","title":"0x0 why we need memory barrier","text":"<p>In short, because reordering memory references allows much better performance, and so memory barriers are needed to force ordering in things like synchronization primitives whose correct operation depends on ordered memory references.</p>"},{"location":"0010-paper_reading/0012-mesi/#0x1-cache-structure","title":"0x1 Cache Structure","text":""},{"location":"0010-paper_reading/0012-mesi/#0x11-some-cases-of-cache-missnot-important","title":"0x11 some cases of cache miss(not important)","text":"<p>The cache miss means that the CPU will have to wait (or be \u201cstalled\u201d) for hundreds of cycles while the item is fetched from memory.</p> <ul> <li>capacity miss: After some time, the CPU\u2019s cache will fill, and sub- sequent misses will likely need to eject an item from the cache in order to make room for the newly fetched item</li> <li> <p>associativity miss: occur in set-associative caches.</p> <p>An \"associativity cache miss\" refers to a specific type of cache miss that can occur in set-associative caches. </p> <p>In a set-associative cache, the cache memory is divided into sets, and each set contains multiple cache lines (or cache blocks). When the CPU needs to access data in memory, it first checks the cache to see if the data is present. The cache lookup is done by first identifying the set that the data would be stored in, and then searching through the multiple cache lines within that set to see if the data is present. </p> <p>An associativity cache miss occurs when the data the CPU needs is not found in any of the cache lines within the identified set. This means the CPU has to go to main memory to fetch the data, which is slower than finding it in the cache. </p> <p>The number of cache lines per set is called the \"associativity\" of the cache. Caches with higher associativity (more cache lines per set) generally have lower associativity cache miss rates, but they are also more complex and expensive to implement. The goal is to find the right balance of associativity to minimize cache misses without making the cache design overly complex.</p> <ul> <li>write miss: Before a given CPU writes to that data item, it must first cause it to be removed, or \u201cinvalidated\u201d, from other CPUs\u2019 caches. Once this invalidation has completed, the CPU may safely modify the data item. If the data item was present in this CPU\u2019s cache, but was read- only, this process is termed a \u201cwrite miss\u201d.</li> </ul> </li> </ul> <p>cache structure: one cache address can store two(or more?) sets of data.</p> <p></p>"},{"location":"0010-paper_reading/0012-mesi/#0x2-cache-coherence-protocols","title":"0x2 Cache-Coherence Protocols","text":""},{"location":"0010-paper_reading/0012-mesi/#0x21-four-state-mesi-states","title":"0x21 Four state: MESI States","text":"<p>The four types of states represent the state of a cache line in one cpu.</p> <p>Here, we use \u201cI\u201d to represent the cpu.</p> <ul> <li>modified:<ul> <li>I have changed the value in private cache and not written it back to memory.</li> <li>Others  can\u2019t access the memory until change their states(signal me).</li> </ul> </li> <li>exclusive:<ul> <li>I haven\u2019t changed the value in private cache. (But may change it later, transfer to modified state)</li> <li>Others can\u2019t access the memory until change their states(signal me).</li> </ul> </li> <li>shared<ul> <li>Others can read the memory without consulting me.</li> </ul> </li> <li>invalid:<ul> <li>the cache line holds no data.</li> </ul> </li> </ul>"},{"location":"0010-paper_reading/0012-mesi/#0x22-messages-between-the-cpusand-memory-mesi-protocol-messages","title":"0x22 Messages between the cpus(and memory): MESI Protocol Messages","text":"<ul> <li>Read: a request for reading  a line</li> <li>Read Response: The line data for a previous read. Either of memory or other cpu.</li> <li>Invalidate: invalidate the line in all other cpus</li> <li>Invalidate Acknowledge: successful response to a previous Invalidate message</li> <li>Read Invalidate: a atomic combination of \u201cread\u201d and \u201cinvalidate\u201d. Requires both a \u201cread response\u201d and a set of \u201cin- validate acknowledge\u201d messages in reply.</li> <li>Writeback: write a line to memory</li> </ul>"},{"location":"0010-paper_reading/0012-mesi/#0x23-state-machine-mesi-state-diagram","title":"0x23 State Machine: MESI State Diagram","text":"<p>Transitions are explained below:</p> <ul> <li>(a): write back to memory</li> <li>(b): modify the data in cache</li> <li>(c): I haven\u2019t written back to memory but another cpu requests it (and will change it). So I return the value in cache and invalidate the private one without writing back to memory</li> <li>(d): I want to change a cache, so I emit a \u201cinvalidate\u201d to other cpus. Now all others have acknowledge me, so I read and change my private cache.</li> <li>(e): Similar to \u201c(d)\u201d, but don\u2019t need to read in memory.</li> <li>(f): Similar to (c), I haven\u2019t written back to memory but another cpu requests it (but will not change it), so I return my private value.</li> <li>(g): Similar to (f)</li> <li>(h): similar to \u201c(d)\u201d, but don\u2019t modify it now</li> <li>(i): similar to \u201c(c)\u201d, but don\u2019t need to return my private value since that in memory is still the newest.</li> <li>(j): Similar to \u201c(d)\u201d</li> <li>(k): read in memory( or other cpu)</li> <li>(l): receive a \u201cinvalidate\u201d message</li> </ul> <p>Examples are in the paper.</p>"},{"location":"0010-paper_reading/0012-mesi/#0x3-optimize-1-stores-result-in-unnecessary-stalls","title":"0x3 Optimize 1: Stores Result in Unnecessary Stalls","text":"<p>Consider to modify a cache that isn\u2019t in modified or exclusive state.</p> <p></p> <ul> <li>Problem: there is no real reason to force CPU 0 to stall for so long \u2014 after all, regardless of what data happens to be in the cache line that CPU 1 sends it, CPU 0 is going to unconditionally overwrite it.</li> <li>Solution: Add \u201cstore buffers\u201d between each CPU and its cache<ul> <li>CPU0 write to its store buffer immediately</li> <li>When CPU0 is acknowledged, the data will be moved from the store buffer to the cache line</li> </ul> </li> </ul>"},{"location":"0010-paper_reading/0012-mesi/#0x31-store-forwarding-problem","title":"0x31: Store Forwarding problem","text":"<p>Thinking of the program below:</p> <ul> <li>CPU0 has value b</li> <li>CPU1 has value a = 0 in exclusive mode</li> </ul> <pre><code>a = 1;\nb = a + 1;\nassert(b == 2);\n</code></pre> <p>step1: cpu0 invalidate cpu1 with \u201ca\u201d , change private cache line to 1, and write it to store buffer.</p> <p>step2: cpu0 receive the value \u201ca\u201d from cpu1. The value is 0, and it\u2019s stored in private cache.(Note that the value in the store buffer is 1)</p> <p>step3: cpu0 executes \u201cb = a + 1\u201d, load \u201ca\u201d from cache, and its value is 0</p> <p>step4: cpu0 store the value of \u201cb\u201d to cache, whose value is 1</p> <p>step5: cpu0 move the value of \u201ca\u201d from store buffer(1) to cache(0)</p> <p>step6: CPU0 executes assert(b==2), which fails.</p> <p>The problem is that we have two copies of \u201ca\u201d, one in the cache and the other in the store buffer.</p> <p>The hardware guys took pity and implemented \u201cstore forwarding\u201d, where each CPU refers to (or \u201csnoops\u201d) its store buffer as well as its cache when performing loads</p> <p>In other words, a given CPU\u2019s stores are directly forwarded to its subsequent loads, without hav- ing to pass through the cache.</p> <p></p>"},{"location":"0010-paper_reading/0012-mesi/#0x32-store-buffers-and-memory-barriers","title":"0x32 Store Buffers and Memory Barriers","text":"<p>Think of the program below</p> <pre><code>void foo(void)\n{\n  a=1;\n  b=1;\n}\n\nvoid bar(void) {\n  while (b == 0) continue;\n  assert(a == 1);\n}\n</code></pre> <ul> <li>cpu0 executes foo<ul> <li>own \u201cb\u201d</li> </ul> </li> <li>cpu1 executes bar<ul> <li>own \u201ca\u201d</li> </ul> </li> </ul> <p></p> <p>The problem is that, cpu1 reads \u201ca\u201d before being acknowledged that other cpus have changed it. Although CPU0 can continue to execute before writing it to stored buffer, but CPU1 doesn\u2019t know that.</p> <p>The hardware designers cannot help directly here, since the CPUs have no idea which variables are related, let alone how they might be related</p> <p>Therefore, the hardware designers provide memory-barrier instructions to allow the software to tell the CPU about such relations. The program fragment must be updated to contain the memory barrier:</p> <pre><code>void foo(void)\n{\n  a=1;\n  smp_mb();\n  b=1;\n}\n\nvoid bar(void)\n{\n  while (b == 0) continue;\n  assert(a == 1);\n}\n</code></pre> <p>The memory barrier <code>smp_mb()</code> will cause the CPU to flush its store buffer before applying subsequent stores to their cache lines. The CPU could either </p> <ul> <li>simply stall until the store buffer was empty before proceeding, or</li> <li>it could only use the store buffer to hold subsequent stores until all of the prior entries in the store buffer had been applied.<ul> <li>This is to prevent other cpus from getting the subsequent value before getting the prior entries</li> </ul> </li> </ul> <p>So that, CPU0 will</p> <ul> <li>wait for the \u201cinvalidate acknowledge\u201d message of \u201ca\u201d before executing \u201cb=1;\u201d</li> </ul> <p>or </p> <ul> <li>(1)while executing <code>smp_mb</code> ,marks all current store-buffer entries (namely, the a=1)</li> <li>(2) while executing \u201cb=1\u201d, only stores it store buffer.</li> <li>(3) wait \u201cinvalidate acknowledge\u201d of \u201ca\u201d</li> <li>(4) store the value of b in stored buffer and send a \u201cinvalidate\u201d message</li> </ul>"},{"location":"0010-paper_reading/0012-mesi/#0x4-optimize-2-store-sequences-result-in-unnecessary-stalls","title":"0x4 Optimize 2: Store Sequences Result in Unnecessary Stalls","text":"<ol> <li>Once the stored buffer is full or a memory barrier is encountered, the CPU must once again wait for invalidations to complete in order to drain its store buffer before it can continue executing</li> <li>invalidate acknowledge messages can take so long: they must ensure that the corre- sponding cache line is actually invalidated, and this invalidation can be delayed if the cache is busy, for example, if the CPU is intensively loading and storing data, all of which resides in the cache.</li> </ol> <p>However, the CPU need not actually invalidate the cache line before sending the acknowledgement.</p>"},{"location":"0010-paper_reading/0012-mesi/#0x42-invalidate-queues-and-invalidate-acknowledge","title":"0x42 Invalidate Queues and Invalidate Acknowledge","text":"<p>A CPU with an invalidate queue may acknowledge an invalidate message as soon as it is placed in the queue, instead of having to wait until the corresponding line is actually invalidated.</p>"},{"location":"0010-paper_reading/0012-mesi/#0x43-invalidate-queues-and-memory-barriers","title":"0x43 Invalidate Queues and Memory Barriers","text":"<p>Thinking of the following code:</p> <pre><code>void foo(void)\n{\n  a=1;\n  smp_mb();\n  b=1;\n}\n\nvoid bar(void)\n{\n  while (b == 0) continue;\n  assert(a == 1);\n}\n</code></pre> <ul> <li>CPU0:<ul> <li>execute foo</li> <li>a is shared state</li> <li>b is exclusive</li> </ul> </li> <li>CPU1:<ul> <li>execute bar</li> </ul> </li> </ul> <p></p> <ul> <li>Once again, the CPU designers cannot do much about this situation</li> <li>However, the memory-barrier instructions can interact with the invalidate queue.</li> </ul> <p>When a given CPU executes a memory barrier, it marks all the entries currently in its invalidate queue, and forces any subsequent load to wait until all marked entries have been applied to the CPU\u2019s cache.</p> <pre><code>void foo(void)\n{\n  a=1;\n  smp_mb();\n  b=1;\n}\n\nvoid bar(void)\n{\n  while (b == 0) continue;\n  smp_mb();\n  assert(a == 1);\n}\n</code></pre> <p>So that, CPU0 will</p> <ul> <li>(1) executes the <code>smp_mb()</code>, marking the entry in its invalidate queue.</li> <li>(2) start executing the assert(a==1), but a is in the invalidate queue, CPU 1 must stall this load until that entry in the invalidate queue has been applied.</li> </ul>"},{"location":"0010-paper_reading/0012-mesi/#0x5-summary-read-and-write-memory-barriers","title":"0x5 Summary: Read and Write Memory Barriers","text":"<p>In the previous section, memory barriers were used to mark entries in both the store buffer and the inval- idate queue. But in our code fragment, foo() had no reason to do anything with the invalidate queue, and bar() similarly had no reason to do anything with the store queue.</p> <p>Many CPU architectures therefore provide weaker memory-barrier instructions that do only one or the other of these two.</p> <ul> <li>read memory barrier:</li> <li>marks only the invalidate queue</li> <li>forces any subsequent load to wait until all marked entries have been applied from the invalidate queue</li> <li>write memory barrier:</li> <li>marks only the store buffer.</li> <li>only use the store buffer to hold subsequent stores until all of the prior entries in the store buffer had been applied. </li> </ul> <pre><code>void foo(void)\n{\n  a=1;\n  smp_wmb();\n  b=1;\n}\n\nvoid bar(void)\n{\n  while (b == 0) continue;\n  smp_rmb();\n  assert(a == 1);\n}\n</code></pre>"},{"location":"0010-paper_reading/0026-20years-database/","title":"What happened in the last two decades","text":""},{"location":"0010-paper_reading/0026-20years-database/#1-intro","title":"1 intro","text":"<p>RM(relational model) with an extendable type system has dominated all comers.</p> <ol> <li>We structure our commentary into the following areas:</li> <li>MapReduce Systems</li> <li>Key-value Stores</li> <li>Document Databases</li> <li>Column Family/Wide-Column</li> <li>Text Search Engines</li> <li>Array Databases</li> <li>Vector Databases</li> <li>Graph Databases</li> <li>Advancements in DBMS architectures that address modern applications and hardware</li> <li>Columnar Systems</li> <li>Cloud Databases</li> <li>Data Lakes/Lakehouses</li> <li>NewSQL Systems</li> <li>Hardware Accelerators</li> <li>Blockchain Databases</li> </ol>"},{"location":"0010-paper_reading/0026-20years-database/#2-data-models-query-languages","title":"2 Data Models &amp; Query Languages","text":""},{"location":"0010-paper_reading/0026-20years-database/#2-1-mapreduce-systemsmr","title":"2-1 MapReduce Systems(MR)","text":"<p>It is constructed as a \"point solution\" for processing its periodic crawl of the internet. In database terms, Map is a user-defined function (UDF) that performs computation and/or filtering while Reduce is a GROUP BY operation.</p> <p>To a first approximation, MR runs a single query:</p> <pre><code>SELECT map() FROM crawl_table GROUP BY reduce()\n</code></pre> <ul> <li>origin:</li> <li>Google\u2019s MR approach did not prescribe a specific data model or query language. Rather, it was up to the Map and Reduce functions written in a procedural MR program to parse and decipher the contents of data files.</li> <li>Yahoo! developed an open-source version of MR in 2005, called Hadoop. It ran on top of a distributed file system HDFS that was a clone of the Google File System</li> <li>controversy between MR and DBMS</li> <li>Google argued that with careful engineering, a MR system will beat DBMSs, and a user does not have to load data with a schema before running queries on it. Thus, MR is better for \"one shot\" tasks, such as text processing and ETL operations.</li> <li>The DBMS community argued that MR incurs performance problems due to its design that existing parallel DBMSs already solved. (What's the performance problem?)<ul> <li>The use of higher-level languages (SQL) operating over partitioned tables would be better.</li> </ul> </li> <li>two changes (BUT WHY?):</li> <li>Many enterprises found that Hadoop has little interest and evelopers found it difficult to fit their applications.</li> <li>Google announced that they were moving their crawl processing from MR to BigTable<ul> <li>Google needed to interactively update its crawl database in real time but MR was a batch system.</li> </ul> </li> <li>end:</li> <li>Cloudera rebranded(\u91cd\u547d\u540d) Hadoop to mean the whole stack (application, Hadoop, HDFS). In a further sleight-of-hand, Cloudera built a RDBMS, Impala, on top of HDFS but not using Hadoop.</li> <li>Hadoop died about a decade ago,</li> <li>At present, HDFS has lost its luster(\u5149\u6cfd), as enterprises realize that there are better distributed storage alternatives</li> <li>Meanwhile, distributed RDBMSs are thriving, especially in the cloud.</li> </ul> <p>Some aspects of MR system implementations related to scalability, elasticity, and fault tolerance are carried over into distributed RDBMSs. MR also brought about the revival of shared-disk architectures with disaggregated storage, subsequently giving rise to open-source file formats and data lakes</p>"},{"location":"0010-paper_reading/0026-20years-database/#22-keyvalue-stores","title":"2.2 Key/Value Stores","text":"<p>It represents the following binary relation:</p> <pre><code>(key,value)\n</code></pre> <p>It is up to the application to maintain the schema and parse the value into its corresponding parts. Most KV DBMSs only provide get/set/delete operations on a single value.</p> <p>In the 2000s, several new Internet companies built their own shared-nothing, distributed KV stores for narrowly focused applications, like caching and storing session data. For caching:</p> <ul> <li><code>Memcached</code> is the most well-known example of this approach.</li> <li>Memcached github page</li> <li>It seems like an old repo</li> <li><code>Redis</code> markets itself as a Memcached replacement, offering a more robust query API with checkpointing support.</li> <li>Redis github page</li> <li>popular</li> <li>For more persistent application data, Amazon created the Dynamo KV store in 2007</li> <li>Amazon DynamoDB WebSite</li> <li>It seems not open.</li> </ul> <p>Key/value stores provide a quick \"out-of-the-box\" way for developers to store data. If an application requires multiple fields in a record, then KV stores are probably a bad idea. Not only must the application parse record fields, but also there are no secondary indexes to retrieve other fields by value.</p> <p>To deal with these issues, several systems began as a KV store and then morphed(\u53d8\u79cd) into a more feature-rich record store. Such systems replace the opaque value with a semi-structured value, such as a JSON document.</p> <p>One new architecture trend from the last 20 years is using embedded KV stores as the underlying storage manager for full-featured DBMSs: * MySQL was the first DBMS to expose an API that allowed developers to replace its default KV storage manager. * This API enabled Meta to build RocksDB to replace InnoDB for its massive fleet of MySQL databases. * Similarly, MongoDB discarded their ill-fated MMAP-based storage manager in favor of WiredTiger\u2019s KV store in 2014</p>"},{"location":"0010-paper_reading/0026-20years-database/#23-document-databases","title":"2.3 Document Databases","text":"<p>The document data model represents a database as a collection of record objects. Each document contains a hierarchy of field/value pairs, where each field is identified by a name and a field\u2019s value can be either a scalar type, an array of values, or another document.</p> <p>An json example:</p> <pre><code>{ \"name\": \"First Last\",\n  \"orders\": [ { \"id\": 123, \"items\": [...] },\n              { \"id\": 456, \"items\": [...] }, ] }\n</code></pre> <p>This has given rise to data formats like SGML and XML, and json becomes the standard in web-based applications</p> <p>There were two marketing messages for such systems that resonated(\u5171\u9e23) with developers.</p> <ol> <li>SQL and joins are slow, and one should use a \"faster\" lower-level, record-at-a- time interface.</li> <li>ACID transactions are unnecessary for modern applications, so the DBMS should only provide weaker notion of it</li> </ol> <p>There are dozens of such systems, of which MongoDB is the most popular.</p> <p>two benefits for Document DBMSs or object-oriented DBMSs 1. Storing data as documents removes the impedance mismatch between how application OO code interacts with data and how relational databases store them. 2. Denormalizing entries into nested structures is better for performance because it removes the need to dispatch multiple queries to retrieve data related to a given object</p> <p>The problems with denormalization/prejoining is an old topic that dates back to the 1970s 1. If the join is not one-to-many, then there will be duplicated data 2. prejoins are not necessarily faster than joins 3. there is no data independence</p> <p>Adding SQL and ACID to a NoSQL DBMS lowers their intellectual distance from RDBMSs. The main differences between them seems to be JSON support and the fact that NoSQL vendors allow \"schema later\" databases. But the SQL standard added a JSON data type and operations in 2016 [165, 178]. And as RDBMSs continue to improve their \"first five minutes\" experience for developers, we believe that the two kinds of systems will soon be effectively identical.</p>"},{"location":"0010-paper_reading/0026-20years-database/#24-column-family-databases","title":"2.4 Column-Family Databases","text":"<p>It is a reduction of the document data model that only supports one level of nesting instead of arbitrary nesting; it is relation-like, but each record can have optional attributes, and cells can contain an array of values. <pre><code>User1000 \u2192 { \"name\": \"Alice\", \"accounts\": [ 123, 456 ],\n             \"email\": \"xxx@xxx.edu\" }\nUser1001 \u2192 { \"name\": \"Bob\",\n             \"email\": [ \"yyy@yyy.org\", \"zzz@zzz.com\" ]\n</code></pre></p>"},{"location":"0010-paper_reading/0026-20years-database/#25-text-search-engines","title":"2.5 Text Search Engines","text":"<ul> <li>Text search engines, by tokenizing documents into a \u201cbag of words\u201d and then building full-text indexes, on those tokens to support queries on their contents.</li> <li>The leading text search systems today include Elastic-search and Solr , which both use Lucene as their internal search library.</li> <li>https://github.com/elastic/elasticsearch</li> <li>https://github.com/apache/solr</li> <li>https://github.com/apache/lucene</li> <li>These systems offer good support for storing and indexing text data but offer none-to-limited transaction capabilities.</li> <li>All the leading RDBMSs support full-text search indexes, including Oracle, Microsoft SQL Server, MySQL , and PostgreSQL.</li> <li>Text data is inherently unstructured, bug a DBMS seeks to extract structure (i.e., meta-data, indexes) from text to avoid \u201cneedle in the haystack\u201d sequential searches.</li> <li>Three ways to manage text data in application:</li> <li>(1): one can run multiple systems, such as Elastic- search for text and a RDBMS for operational workloads. This approach:<ul> <li>Allows one to run \"best of breed\" systems</li> <li>but requires additional ETL(Extract, transform, and load) plumbing to push data from the operational DBMS to the text DBMS</li> <li>rewrite applications to route queries to the right DBMSs based on their needs.</li> </ul> </li> <li>(2): one can run a RDBMS with good text-search integration capabilities but with divergent APIs in SQL. This issue is often overcome by application frameworks that hide this complexity</li> <li>(3): use a polystore system Home | bigdawg (mit.edu) that masks the system differences via middleware that exposes a unified interface</li> </ul>"},{"location":"0010-paper_reading/0026-20years-database/#26-array-databases","title":"2.6 Array Databases","text":"<p>We use the term \u201carray\u201d to mean all variants of vectors, matrices and tensors (three or more dimensions). For example, scientific surveys for geographic regions usually represent data as a multi-dimensional array that stores sensor measurements using location/time-based coordinates: <pre><code>(latitude, longitude, time, [vector-of-values])\n</code></pre></p> <p>Array data does not always align to a regular integer grid, for example, geospatial data is often split into irregular shapes. An application can map such grids to integer coordinates via metadata describing this mapping. Hence, most applications maintain array and non-array data together in a single database.</p> <p>Querying array data in arbitrary dimensions presents unique challenges, since the DBMS stores multi-dimensional array data on a linear physical storage medium like a disk.</p>"},{"location":"0010-paper_reading/0026-20years-database/#27-vector-databases","title":"2.7 Vector Databases","text":"<p>Store single-dimension embeddings generated from AI tools.</p> <p>For example, one could convert each Wikipedia article into an embedding using Google BERT and store them in a vector database along with additional article meta-data:</p> <pre><code>(title, date, author, [embedding-vector])\n</code></pre> <p>The key difference between vector and array DBMSs is their query patterns. Vector DBMS are designed for similarity searches that find records whose vectors have the shortest distance to a given input vector in a high-dimensional space. Unlike array DBMSs, applications do not use vector DBMSs to search for matches at an offset in a vector nor extract slices across multiple vectors.</p> <p>Vector DBMSs build indexes to accelerate approximate nearest neighbor (ANN) searches . One compelling feature of vector DBMSs is that they provide better integration with AI tools: These systems natively support transforming a record\u2019s data into an embedding upon insertion using these tools and then uses the same transformation to convert a query\u2019s input arguments into an embedding to perform the ANN search;</p> <p>There are two likely explanations for the quick proliferation(\u6269\u6563) of vector indexes: 1. Similarity search via embeddings is such a compelling use case that every DBMS vendor rushed out their version and announced it immediately 2. The engineering effort to introduce a new index data structure</p>"},{"location":"0010-paper_reading/0026-20years-database/#28-graph-databases","title":"2.8 Graph Databases","text":"<ul> <li>Many applications use knowledge graphs to model semi-structured information</li> <li>Social media applications inherently contain graph-oriented relationships (\u201clikes\u201d, \u201cfriend-of\u201d).</li> </ul> <p>Relational design tools provide users with an entity-relationship (ER) model of their database. An ER diagram is a graph; thus, this paradigm has clear use cases.</p> <p>The two most prevalent approaches to represent graphs are 1. the resource description framework (RDF) (aka triplestores)     1. model a directed graph with labeled edges 2. property graphs:     1. DBMS maintains a directed multi-graph structure that supports key/value labels for nodes and edges.</p> <p>usages: - operational / OLTP workloads:     - traditional DBMS: adds a friend link in the database by updating a single record, presumably in a transactional manner     - Neo4j is the most popular graph DBMS for OLTP applications. It supports edges using pointers (as in CODASYL ) but it does not cluster nodes with their \u201cparent\u201d or \u201coffspring\u201d         - Such an architecture is advantageous for traversing long edge chains since it will do pointer chasing, whereas a RDBMS has to do this via joins. - analytics: which seeks to derive information from the graph.     - finding which user has the most friends under 30 years old.</p> <p>Unlike queries in relational analytics that are characterized by chains of joins, queries for graph analytics contain operations like shortest path, cut set, or clique determination . This argues for a computing fabric that allows developers to write their own algorithms using an abstraction that hides the underlying system topology.</p> <p>Regardless of whether a graph DBMS targets OLTP or OLAP workloads, the key challenge these systems have to overcome is that it is possible to simulate a graph as a collection of tables: <pre><code>Node (node_id, node_data)\nEdge (node_id_1, node_id_2, edge_data)\n</code></pre> This means that RDBMSs are always an option to support graphs. But \u201cvanilla\u201d SQL is not expressive enough for graph queries and thus require multiple client-server roundtrips for traversal operations.</p> <p>Some RDBMSs, including MSSQL and Oracle, provide built-in SQL extensions that make storing and querying graph data easier. Other DBMSs use a transla- tion layer on top of relations to support graph-oriented APIs.</p> <p>More recently, SQL:2023 introduced property graph queries (SQL/PGQ) for defining and traversing graphs in a RDBMS </p> <p>There have been several performance studies showing that graph simulation on RDBMSs outperform graph DBMSs. More recent work showed how SQL/PGQ in DuckDB outperforms a leading graph DBMS by up to 10.</p>"},{"location":"0010-paper_reading/0026-20years-database/#29-summary","title":"2.9 Summary","text":"<ul> <li>MapReduce Systems: They died years ago and are, at best, a legacy technology at present.</li> <li>Key-value Stores: Many have either matured into RM systems or are only used for specific problems. These can generally be equaled or beaten by modern high-performance RDBMSs.</li> <li>Document Databases: Such NoSQL systems are on a collision course with RDBMSs. The differences between the two kinds of systems have diminished over time and should become nearly indistinguishable in the future.</li> <li>Column-Family Systems: These remain a niche market. Without Google, this paper would not be talking about this category.</li> <li>Text Search Engines: These systems are used for text fields in a polystore architecture.</li> <li>Array Databases : Scientific applications will continue to ignore RDBMSs in favor of bespoke(\u5b9a\u5236) array systems</li> <li>Vector Databases : They are single-purpose DBMSs with indexes to accelerate nearest-neighbor search. RM DBMSs should soon provide native support for these data structures and search methods using their extendable type system that will render such specialized databases unnecessary.</li> <li>Graph Databases: OLTP graph applications will be largely served by RDBMSs. In addition, analytic graph applications have unique requirements that are best done in main memory with specialized data structures. RDBMSs will provide graph-centric APIs on top of SQL or via extensions. We do not expect specialized graph DBMSs to be a large market.</li> </ul>"},{"location":"0010-paper_reading/0026-20years-database/#3-system-architectures","title":"3 system Architectures","text":""},{"location":"0010-paper_reading/0026-20years-database/#31-columnar-systems","title":"3.1 Columnar Systems","text":"<p>Data warehouse (OLAP) applications have common properties that are distinct from OLTP workloads: 1. They are historical in nature 2. Organizations retain everything as long as they can afford the storage \u2014 think terabytes to petabytes. 3. Queries typically only access a small subset of attributes from tables and are ad-hoc in nature.</p> <p>Organizing the DBMS\u2019s storage by columns instead of rows has several benefits 1. Compressing columnar data is more effective than row-based data because there is a single value type in a data block often many repeated bytes. 2. A Volcano-style engine executes operators once per row. In contrast, a column-oriented engine has an inner loop that processes a whole column using vectorized instructions 3. Row stores have a large header for each record (e.g., 20 bytes) to track nulls and versioning meta-data, whereas column stores have minimal storage overhead per record.</p>"},{"location":"0010-paper_reading/0026-20years-database/#32-cloud-databases","title":"3.2 Cloud Databases","text":"<p>Initial cloud DBMS offerings repackaged on-prem systems into managed VMs with direct-attached storage. But over the last 20 years, networking bandwidth has increased much faster than disk bandwidth, making network attached storage (NAS) attractive as an alternative to attached storage. This has caused a profound rethinking of DBMS architectures for the cloud.</p> <p>All major cloud vendors offer NAS via object stores. Beyond better economics compared to direct-attached storage, object stores have several advantages that compensate for the cost of the added network link 1. because the compute nodes are disconnected from the storage nodes, a system can provide per-query elasticity;     1. The DBMS can add new compute nodes dynamically without having to reshuffle(\u91cd\u65b0\u7ec4\u7ec7) data.     2. It also allows the DBMS to use different hardware for its storage nodes than compute nodes. 2. the system can reassign compute nodes to other tasks if a DBMS is underutilized. 3. On the other hand, in a shared-nothing DBMS, a node must always be online to handle incoming query requests. 4. Pushing down computation into the storage nodes is possible</p> <p>https://www.snowflake.com/en/</p> <p>From a business perspective, open-source DBMSs face the danger of becoming too popular and being monetized by the major cloud providers.</p>"},{"location":"0010-paper_reading/0026-20years-database/#data-lakes-lakehouses","title":"Data Lakes / Lakehouses","text":"<p>From monolithic(\u5355\u673a\u7684), dedicated(\u4e13\u7528\u7684) data warehouses for OLAP workloads and towards data lakes backed by object stores. Vendors viewed their DBMSs as the \u201cgatekeepers\u201d for all things related to data in an organization.</p> <p>With a data lake architecture, applications upload files to a distributed object store, bypassing the traditional route through the DBMS. Users then execute queries and processing pipelines on these accumulated files using a lakehouse (a portmanteau(\u591a\u7528\u9014\u7684) of data warehouse and data lake) execution engine</p> <p>Instead of using DBMS-specific proprietary file formats or inefficient text-based files (e.g., CSV, JSON), applications write data to data lakes using open-source, disk-resident file formats. The two most popular formats are Twitter/Cloudera\u2019s Parquet and Meta\u2019s ORC</p> <p>At first glance, a data lake seems like a terrible idea for an organization: allowing any application to write arbitrary files into a centralized repository without any governance is a recipe for integrity, discovery, and versioning problems</p> <p>Data lakes introduce new challenges to query optimization. DBMSs have always struggled with acquiring precise statistics on data, leading to poor query plan choices [154]. However, a data lake system may completely lack statistics on newly ingested data files.</p> <p>All the major cloud vendors now offer some variation of a managed data lake service. Since data lake systems backed by object stores are much cheaper per gigabyte than proprietary data warehouses, the legacy OLAP vendors (e.g., Teradata, Vertica) have extended their DBMSs to support reading data from object stores in re- sponse to this pricing pressure.</p>"},{"location":"0010-paper_reading/0026-20years-database/#34-newsql-systems","title":"3.4 NewSQL Systems","text":"<p>NewSQL systems arrived in the early 2010s seeking to provide the scalability of NoSQL systems for OLTP workloads while still supporting SQL.</p> <p>There were two main groups of NewSQL systems: 1. in-memory DBMSs, including H-Store, SingleStore, Hekaton, HyPer 2. disk-oriented, distributed DBMSs like NuoDB and Clustrix</p> <p>There has yet to be a dramatic uptake in NewSQL DBMS adoption. The reason for this lackluster(\u4e4f\u5584\u8db3\u9648) interest is that existing DBMSs were good enough for the time, which means organizations are unwilling to take on the costs and risk of migrating existing applications to newer technologies.</p> <p>The aftermath of NewSQL is a new crop(\u6536\u6210) of distributed, transactional SQL RDBMSs. These include TiDB, CockroachDB, and YugabyteDB.</p> <p>The major NoSQL vendors also added transactions to their systems in the last decade despite previously strong claims that they were unnecessary.</p>"},{"location":"0010-paper_reading/0026-20years-database/#35-hardware-accelerators","title":"3.5 Hardware Accelerators","text":"<p>specialized hardware designed for a DBMS should easily outperform a conventional CPU.</p> <p>Instead of building custom hardware for DBMSs, the last 20 years have been about using commodity(\u5546\u54c1) hardware (FPGAs, GPUs) to accelerate queries.This is an enticing(\u6709\u65b0\u5f15\u529b\u7684) idea: a vendor can get the benefits of a DBMS accelerator without the cost of fabricating the hardware</p> <p>Creating custom hardware just for a DBMS is not cost-effective for most companies. The reason why there are more GPU DBMSs than FPGA systems is because there are existing support libraries available for GPUs.</p> <p>The only place that custom hardware accelerators will succeed is for the large cloud vendors. They can justify the $50\u2013100m R&amp;D(research and development) cost of custom hardware at their massive scale. Amazon did this already with their Redshift AQUA accelerators. Google BigQuery has custom components for in-memory shuffles.</p>"},{"location":"0010-paper_reading/0026-20years-database/#36-blockchain-databases","title":"3.6 Blockchain Databases","text":"<p>These are decentralized log-structured databases (i.e., ledger) that maintain incremental checksums using some variation of Merkle trees. These incremental checksums are how a blockchain ensures that the database\u2019s log records are immutable: applications use these checksums to verify that previous database updates have not been altered.</p> <p>The ideal use case for blockchain databases is peer-to-peer applications where one cannot trust anybody. There is no centralized authority that controls the ordering of updates to the database. Thus, blockchain implementations use a BFT(Byzantine Fault Tolerant) commit protocol to determine which transaction to apply to the database next.</p> <p>At the present time, cryptocurrencies (Bitcoin) are the only use case for blockchains. In addition, there have been attempts to build a usable DBMS on top of blockchains.</p> <p>We are required to place trust in several entities in today\u2019s society. When one sells a house, they trust the title company to manage the transaction. The only applications without real-world trust are dark web interactions. Legitimate businesses are unwilling to pay the performance price (about five orders of magnitude(\u6570\u91cf\u7ea7)) to use a blockchain DBMS. If organizations trust each other, they can run a shared distributed DBMS more efficiently without wasting time with blockchains.</p> <p>Blockchain proponents make additional meaningless claims of achieving data resiliency through replication in a peer-to-peer environment. No sensible company would rely on random participants on the Internet as the backup solution for mission-critical databases.</p>"},{"location":"0010-paper_reading/0026-20years-database/#37-summary","title":"3.7 Summary","text":"<ul> <li>Columnar Systems: The change to columnar storage revolutionized OLAP DBMS architectures.</li> <li>Cloud Databases: The cloud has upended(\u98a0\u8986) the conventional wisdom on how to build scalable DBMSs.</li> <li>Data Lakes / Lakehouses: Cloud-based object storage using open-source formats will be the OLAP DBMS archetype for the next ten years.</li> <li>NewSQL Systems: They leverage new ideas but have yet to have the same impact as columnar and cloud DBMSs.  It has led to new distributed DBMSs that support stronger ACID semantics as a counter to NoSQL\u2019s weaker BASE guarantees.</li> <li>Hardware Accelerators: We do not see a use case for specialized hardware outside of the major cloud vendors, though start-ups will continue to try.</li> <li>Blockchain Databases: An inefficient technology looking for an application. History has shown this is the wrong way to approach systems development.</li> </ul>"},{"location":"0010-paper_reading/0026-20years-database/#4-parting-comments","title":"4 Parting Comments","text":"<ul> <li>Never underestimate the value of good marketing for bad products. Inferior DBMS products have succeeded via strong marketing despite the existence of better options available at the time:<ul> <li>Oracle did this in the 1980s,</li> <li>MySQL did this in the 2000s, and</li> <li>MongoDB did this in the 2010s. </li> <li>These systems got enough traction early on to buy them time to fix the engineering debt they accumulated earlier.</li> </ul> </li> <li>Beware of DBMSs from large non-DBMS vendors<ul> <li>This trend to avoid \u201cnot invented here\u201d software is partly because many companies\u2019 promotion path favors engineers who make new internal systems, even if existing tools are sufficient.</li> </ul> </li> <li>Do not ignore the out-of-box experience<ul> <li>Most SQL systems require one first to create a database and then define their tables before they can load data. This is why data scientists use Python notebooks to analyze data files quickly. Every DBMS should, therefore, make it easy to perform in situ processing of local and cloud-storage files. DuckDB\u2019s rising popularity is partly due to its ability to do this well.</li> </ul> </li> <li>Developers need to query their database directly.<ul> <li>Most OLTP applications created in the last 20 years primarily interact with databases via an abstraction layer, such as an endpoint API</li> <li>ORMs(object-relational mapper) are a vital tool for rapid prototyping. But they often sacrifice the ability to push logic into the DBMS in exchange for interoperability with multiple DBMSs.</li> </ul> </li> <li>The impact of AI/ML on DBMSs will be significant.<ul> <li>There is a resurgence in using natural languages (NLs) to query databases due to advancements in LLMs at converting NL to query code</li> <li>Nobody will write OLTP applications using an NL, as most generate queries using ORMs. For OLAP databases, NL could prove helpful in constructing the initial queries for exploratory(\u63a2\u7d22\u6027\u7684) analysis. However, these queries should be exposed to a dashboard-like refinement tool since English and other NLs are rife with ambiguities and impreciseness.</li> <li>Lastly, there is a considerable amount of recent research on using AI/ML to optimize the DBMSs. Although such ML-assisted optimizations are powerful tools to improve the performance of DBMSs, it does not obviate the need for high-quality systems engineering.</li> </ul> </li> </ul>"},{"location":"0010-paper_reading/0026-20years-database/#5-conclusion","title":"5 Conclusion","text":"<ul> <li>There is tremendous value in exploring new ideas and concepts for DBMSs. The database re- search community and marketplace are more robust be- cause of it. However, we do not expect these new data models to supplant the RM.</li> <li>We contend that the database community should strive for a POSIX-like standard of DBMS internals to accelerate interoperability.</li> </ul>"},{"location":"0010-paper_reading/0026-20years-database/#related-paper","title":"Related Paper","text":"<ul> <li>amazon-dynamo-sosp2007</li> <li>whatgoesaround-sigmodrec2024</li> </ul>"},{"location":"0010-paper_reading/0027-constant_recovery/","title":"constant recovery with undo","text":""},{"location":"0010-paper_reading/0027-constant_recovery/#0x0-backgroud","title":"0x0 backgroud","text":"<p>Even though ARIES simplifies the recovery process and allows it to be generic for all transactional operations, recovering the database to a consistent state requires undoing all operations performed by uncommitted transactions which makes the cost of recovery proportional to the work performed by these transactions. This significantly impacts database availability since recovering a long running transaction can take several hours.</p> <p>This paper describes the overall design of \u201cConstant Time Recovery\u201d (CTR) </p> <p>Recovering the database to a consistent state requires undoing all operations performed by uncommitted transactions, and recovering a long running transaction can take several hours</p>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x1-background-on-sql-server","title":"0x1 BACKGROUND ON SQL SERVER","text":""},{"location":"0010-paper_reading/0027-constant_recovery/#0x11-databaserecovery","title":"0x11 DatabaseRecovery","text":"<p>Following ARIES, the SQL Server recovery process has three distinct phases. Figure 2 demonstrates these phases and the portion of the log they process.</p> <p></p> <p>(The oldest transaction can run across many checkpoints)</p> <ul> <li>analysis: identifys:</li> <li>any transactions that must be rolled back</li> <li>LSN of the oldest dirty page in the system<ul> <li>Checkpoint process captured all active transactions and the oldest dirty page LSN at the time of the checkpoint, so analysis can start from that</li> </ul> </li> <li>redo: bringing the database back to the state it was at the time of the failure:</li> <li>Since Analysis has recomputed the Oldest Dirty Page LSN, Redo should only process the log from this point.<ul> <li>Only applies the operation if the Page LSN is lower</li> </ul> </li> <li>Processes the log starting from the beginning of the oldest active transaction.<ul> <li>This allows recovery to reacquire all the locks held by active transactions and make the database available at the end of Redo for improved availability</li> </ul> </li> <li>undo: rolling back any transactions that were active at the time of the failure.</li> <li>As Redo has reacquired the locks required by these transactions, the Undo process can be performed while the database is available and user queries will be blocked only if they attempt to access the data modified by the transactions pending undo.</li> <li>Undoing these operations is also logged using Compensation Log Records (CLR) to guarantee that the database is recoverable even after a failure in the middle of the Undo process</li> </ul>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x12-multi-versionconcurrencycontrol","title":"0x12 Multi-versionConcurrencyControl","text":"<p>Versioning is performed at the row level: for every user data update, SQL Server updates the row in-place in the data page and pushes the old version of the row to an append-only version store, linking the current row version to the previous version</p> <p>The versions are linked to each other using their physical locator</p> <p></p> <p>Given that these versions are only used for the purposes of SI, the version store doesn\u2019t need to be preserved across restarts and is stored in SQL Server\u2019s \u201cTempDB\u201d, a system database that is recycled every time the SQL Server process restarts. This allows for efficient version generation, as these operations are not logged.</p>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x2-constanttimerecovery","title":"0x2 CONSTANTTIMERECOVERY","text":""},{"location":"0010-paper_reading/0027-constant_recovery/#0x21-overview","title":"0x21 Overview","text":"<ul> <li>Database recovery in constant time, regardless of the user workload and transaction sizes.</li> <li>Transaction rollback in constant time regardless of the transaction size.</li> <li>Continuous transaction log truncation, even in the presence of long running transactions.</li> </ul> <p>CTR achieves these by separating transactional operations into three distinct categories and handling their recovery using the most appropriate mechanism.</p>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x22-three-transactional-operations-categories","title":"0x22 three transactional operations categories","text":""},{"location":"0010-paper_reading/0027-constant_recovery/#0x221-data-modifications","title":"0x221 Data Modifications","text":"<p>All data modifications are versioned, storing the earlier versions of each row in the version store that is now redesigned to be persistent and recoverable</p> <p>\uff08\u7b11\u6b7b\u6211\u4e86\uff0c\u521a\u521a\u8fd8\u5728\u611f\u53f9 version store \u65e0\u9700\u8bb0\u5f55\uff0c\u91cd\u542f\u5373\u5220\u591a\u4e48\u65b9\u4fbf\uff09</p> <p>When a transaction rolls back, it is simply marked as \u201caborted\u201d, indicating that any new transactions should ignore the versions generated by this transaction and access the earlier committed versions</p> <p>During database recovery</p> <ul> <li>Analysis identifies the state of every transaction</li> <li>Redo recovers the row and the version store content as of the time of the failure.</li> <li>Undo marks the uncommitted transactions as aborted making all updates by these   transactions invisible.<ul> <li>This allows Undo to complete in constant time, regardless of the transaction sizes.</li> <li>\uff08\u4ecd\u7136\u548c aborted xact count \u76f8\u5173\uff0c\u4f46\u76f8\u6bd4\u4e8e modified row count\uff0c\u51e0\u4e4e\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\uff09</li> </ul> </li> </ul>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x222-system-operations","title":"0x222 System Operations","text":"<p>System operations refer to internal operations the DBMS uses to maintain its internal data structures, such as space allocation and deallocation, B-Tree page splits, etc.</p> <ul> <li>difficulty:</li> <li>These operations cannot be easily versioned</li> <li>Additionally, these operations are usually tied to user data modifications and can be a significant percentage of the operations performed by a long-running transaction.<ul> <li>For example, a large data load allocates a large number of pages</li> </ul> </li> <li>Solution:</li> <li>These operations are always performed by short-lived, system transactions that update the internal data structures and immediately commit</li> <li>When a failure occurs, these operations will not be undone, but the allocated space and other updated data structures will be lazily reclaimed and fixed up in the background.</li> </ul>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x223-logical-and-other-non-versioned-operations","title":"0x223 Logical and Other Non-versioned Operations","text":"<p>This last category refers to operations that cannot be versioned because they are either:</p> <ul> <li>logical: such as</li> <li>lock acquisition operations that indicate that a certain lock must be acquired during recovery</li> <li>cache invalidation operations that are responsible for invalidating in-memory caches when a transaction rolls back</li> <li>they are modifying data structures that need to be accessed during start up</li> <li>must maintain a very specific format that does not allow versioning     CTR leverages an additional log stream, SLog, that allows tracking only the relevant operations and not having to process the full transaction log for the corresponding transactions.</li> </ul>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x23-persistent-version-store","title":"0x23 Persistent Version Store","text":"<p>Persistent Version Store (PVS) allows row versions to be recoverable by storing them in the user database and logging them in the transaction log as regular user data.</p> <ul> <li>Hence, at the end of Redo all versions are fully recovered and can be accessed by user transactions</li> </ul>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x231-in-row-version-store","title":"0x231 In-row Version Store","text":"<p>Since in most cases the difference between the two versions is small (for example when only a few columns are updated), we can simply store the diff between the two versions</p> <ul> <li>Even though computing and reapplying the diff requires additional CPU cycles, the cost of generating an off-row version, by accessing another page and logging the version as a separate operation, is significantly higher \uff08\u518d\u8bfb\u53e6\u4e00\u4e2a\u9875\u4ee3\u4ef7\u66f4\u5927\uff09</li> </ul> <p>![[attachments/Pasted image 20240714101730.png]]</p> <p>\uff08 diff \u600e\u4e48\u5b58\u50a8\u5462\uff1f\u5b9a\u957f\u7684 id \u5b57\u6bb5\u53ef\u80fd\u4e0d\u591f\uff01\uff09</p> <p>Despite its benefits in most common cases, in-row versioning can negatively impact the performance of the system if it significantly increases the size of rows in the data pages. This is particularly problematic for B-Trees as it can lead to page splits. \uff08diff \u4f1a\u5360\u7528\u5927\u91cf\u7a7a\u95f4\uff0c\u5f15\u8d77 page \u6570\u91cf\u81a8\u80c0\uff0cB\u6811\u5206\u88c2\u4ee3\u4ef7\u9ad8 \uff09</p>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x232-off-row-version-store","title":"0x232 Off-row Version Store","text":"<p>It is implemented as an internal table that has no indexes since all version accesses are based on the version\u2019s physical locator (Page Id, Slot Id) \uff08\u7eaf heap\uff0c\u65e0\u7d22\u5f15\uff09</p> <p>Each version of user data is stored as a separate row in this table, having some columns for persisting version metadata and a generic binary column that contains the full version content, regardless of the schema of the user table this version belongs to. \uff08\u5b58\u5168\u91cf\u6570\u636e\uff0c\u800c\u4e0d\u4ec5\u662f diff)</p> <p>By leveraging regular logging, off-row PVS is recovered using the traditional recovery mechanisms</p>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x23-logical-revert","title":"0x23 Logical Revert","text":""},{"location":"0010-paper_reading/0027-constant_recovery/#0x231-overview","title":"0x231 overview","text":"<p>CTR leverages the PVS to instantly roll back data modifications.</p> <p>When a query accesses a row, it first checks the state (active, committed or aborted) of the transaction that generated the latest version.</p> <ul> <li>If the transaction is active or has been committed: visibility depends on the query isolation level. \uff08 \u4e8b\u52a1\u63d0\u4ea4\uff0c\u5219\u770b\u7b2c\u4e00\u4e2a version \uff09</li> <li>but if the transaction is aborted, this version is definitely not visible and the query traverses the version chain to identify the version that belongs to a committed transaction and is visible. \uff08 \u4e8b\u52a1\u56de\u6eda\uff0c\u5219\u904d\u5386 version chain \uff09</li> </ul> <p>Additionally, if a new transaction updates a row with an aborted version, it must first revert the effects of the aborted transaction before proceeding with the update. \uff08 \u505a\u5b8c redo \u540e\uff0cthe latest version \u53ef\u80fd\u662f abort \u72b6\u6001\uff0c\u771f\u6b63\u6709\u6548\u7684 version \u5728 version chain \u4e2d\uff0c\u6240\u4ee5\u9700\u8981\u4fee\u590d the latest version \uff09</p> <p>CTR implements two different mechanisms for reverting the updates performed by aborted transactions:</p> <p>Logical Revert is the process of bringing the committed version of a row back to the main row in the data page,</p> <ul> <li>so that all queries can access it directly and versions in the version store are no longer required</li> <li>This process compares the state of the aborted and committed versions and performs the required compensating operation</li> <li>the revert operations are not versioned</li> <li>Since these transactions only revert a row at a time, they are guaranteed to be short-lived and don\u2019t affect recovery time.</li> <li>Logical Revert is used by a background cleanup process to eliminate all updates performed by aborted transactions and eventually remove the aborted transactions from the system.   ![[attachments/Pasted image 20240714110353.png]]</li> </ul> <p>overwrite the aborted version with the new version it is generating</p> <ul> <li>This process minimizes the overhead for these operations and allows them to be almost as fast as if there was no aborted version.   ![[attachments/Pasted image 20240714110439.png]]</li> </ul> <p>In CTR, the database is fully available, releasing all locks, while row versions are lazily cleaned up in the background.</p>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x232-transaction-state-management","title":"0x232 Transaction State Management","text":"<p>For SI, visibility depends on the commit timestamp of the transaction that generated the version. Since SQL Server does not allow snapshot transactions to span server restarts, the commit timestamps can be stored in memory and need not be recovered. CTR, however, requires tracking the state of aborted transactions until all their versions have been logically reverted and are no longer accessible.</p> <p>CTR stores the aborted transaction information in the \u201cAborted Transaction Map\u201d (ATM)</p> <p>Restore ATM after crash:</p> <ul> <li>When a transaction aborts, before releasing any locks, it will add its Transaction Id to the ATM and generate an \u201cABORT\u201d log record indicating that it was aborted. \uff08\u4ea7\u751f ATM \u4fe1\u606f\uff09</li> <li>When a checkpoint occurs, the full content of the ATM is serialized into the transaction log as part of the checkpoint information. \uff08 checkpoint \u6574\u7406 ATM \u4fe1\u606f \uff09</li> <li>Since Analysis starts processing the log from the Checkpoint Begin LSN of the last successful checkpoint, or earlier, it will process this information regarding the aborted transactions and reconstruct the ATM. \uff08 analysis \u6839\u636e checkpoint \u91cd\u5efa ATM \uff09</li> <li>Any transactions that aborted after the last checkpoint will not be included in the checkpoint, but Analysis will process their ABORT log records and add them to the map \uff08 analysis \u5206\u6790 checkpoint \u540e\u9762\u4e8b\u52a1\u7684 ABORT log\uff0c\u5e76\u5199\u5165 ATM \uff09</li> </ul> <p>Following this process, Analysis can reconstruct the ATM as of the time of the failure, so that it is available when the database becomes available at the end of Redo.</p> <p>Once all versions generated by an aborted transaction have been reverted, the transaction is no longer interesting for recovery and can be removed from the ATM.</p> <p>Removing a transaction is also a logged operation, using a \u201cFORGET\u201d log record, to guarantee that the content of the ATM is recovered correctly. \uff08Removing from ATM \u4e5f\u8981\u65b0\u52a0\u65e5\u5fd7\uff1f\u8fd9\u4e5f\u592a\u590d\u6742\u4e86\u3002\u3002\u3002\u3002\uff09</p>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x233-short-transaction-optimization","title":"0x233 Short Transaction Optimization","text":"<p>Maintaining the Aborted Transaction Map and forcing queries to visit additional versions incur a performance penalty, short OLTP transactions as they would significantly increase the size of the ATM</p> <p>When a transaction attempts to roll back, we evaluate the number of operations it performed and the amount of log it generated and qualify it as \u201cshort\u201d if these don\u2019t exceed certain thresholds.</p> <p>Short transactions will not go through the CTR rollback process, but use traditional undo, so that they are immediately removed from the system. \uff08 \u592a\u591a\u77ed\u4e8b\u52a1\u5bfc\u81f4 ATM \u81a8\u80c0\uff0c\u89e3\u51b3\u65b9\u6848\u4e3a\u6df7\u7528 CTR \u548c undo\uff1f\u8fd9\u4e48\u590d\u6742\u4e48\uff1f \uff09</p>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x24-non-versioned-operations","title":"0x24 Non-versioned Operations","text":"<p>A variety of operations that cannot be versioned because they are:</p> <ul> <li>Logical: such as</li> <li>acquiring coarse-grained locks</li> <li>invalidating various caches when a transaction rolls back</li> <li>accumulating row and page statistics</li> <li>Updating system metadata in data structures</li> <li>Updating critical system metadata required for starting up the database, before recovery can reconstruct versioning information, such as updates to the \u201cboot page\u201d, a special page that contains the core information required for initialization.\uff08 \uff1f\u8fd9\u4e9b\u4e1c\u897f\u8fd8\u80fd\u505a\u6210page\uff1f\uff0c\u8fd8\u6709\u7248\u672c\u7ba1\u7406\uff1f\u8fd9\u5c31\u662f\u5546\u4e1a\u6570\u636e\u4e48\uff1f \uff09</li> </ul> <p>To handle these operations while guaranteeing recovery in constant time, we are leveraging two different mechanisms:</p>"},{"location":"0010-paper_reading/0027-constant_recovery/#0x241-slog-a-secondary-log-stream","title":"0x241 SLog: A Secondary Log Stream","text":"<p>SLog is a secondary log stream designed to only track non-versioned operations that must be redone or undone using information from the corresponding log records.</p> <p>For example, when altering the data type of a column in a large table, the transaction will have to update millions of rows, but SLog will only contain a handful log records, for acquiring the exclusive lock and invalidating metadata caches.</p>"},{"location":"0013-postgresql/0013-build_from_source/","title":"Build PostgreSQL From Source","text":""},{"location":"0013-postgresql/0013-build_from_source/#download-through-git","title":"Download through git","text":"<p>See official docs for detail. Below is a simple example:</p> <pre><code>export user=dev\nexport src_dir=postgresql\n\nexport build_dir=/home/${user}/build\nexport data_dir=/home/${user}/data\n\nexport superuser=postgres\nexport defaultdb=test\n\n${build_dir}/bin/pg_ctl -D ${data_dir} stop\nrm -rf ${build_dir}\nrm -rf ${data}\n\ncd ~ #start from home/${user}\ngit clone https://git.postgresql.org/git/postgresql.git\ncd ${src_dir}\ngit clean -xdf # may be too dangerous\n\n# delete for add some configures accordingly\nexport CFLAGS='-O0 -pipe -Wall -g3'\nexport CXXFLAGS=$CFLAGS\n./configure \\\n    --prefix=${build_dir} \\\n    --enable-cassert \\\n    --with-tcl \\\n    --with-perl \\\n    --with-python \\\n    --enable-debug \\\n    --without-icu \\\n    --with-openssl \\\n    CC=/usr/bin/gcc \\\n\nmake -j8 &amp;&amp; make install\nmake -C contrib install\n${build_dir}/bin/initdb --username=${superuser} --pgdata=${data_dir}\n${build_dir}/bin/pg_ctl -D ${data_dir} -l ${data_dir}/logfile start\n${build_dir}/bin/psql -U${superuser} postgres -c \"create database ${defaultdb};\"\necho \"----------------- all finished -----------------------\"\necho \"use ************** \"\necho \"[ ${build_dir}/bin/psql -U${superuser} ${defaultdb} ] \"\necho \"to connect postgresql\"\ncd ..\n</code></pre> <p>\u200d</p>"},{"location":"0013-postgresql/0014-column-schema-change/","title":"Column Schema Change","text":"<p>In PostgreSQL, the adding and dropping a column is an instant ddl(This name seems only to be used in mysql, but I like it). In this article, I try to explain the implement of that.</p> <p>The reference:</p> <ul> <li>https://www.postgresql.org/docs/current/sql-altertable.html</li> <li></li> </ul>"},{"location":"0013-postgresql/0014-column-schema-change/#basic-concepts","title":"Basic Concepts","text":""},{"location":"0013-postgresql/0014-column-schema-change/#instant-ddl","title":"instant ddl","text":"<p>For a table with \\(n\\) tuples, if a ddl post can be performed in time \\(O(1)\\) ,we call this ddl instant. So to implement an instant ddl, the data organization must remain unchanged. Instead, only the schema information can be changed, along withthe method to used to interpret the table's binary data according to the schema.</p> <p>In this scenario, pg only changes the <code>pg_attribute</code> catalog, which records the attributes[#todo is this OK] of each relations.</p>"},{"location":"0013-postgresql/0014-column-schema-change/#heap-page-representation","title":"heap page representation","text":"<p>Before illustrate the situation where interpreting the binary data with two different schemas, we figure out the way to organize the heap pages.</p> <p></p>"},{"location":"0013-postgresql/0015-every_data_pg/","title":"Everyday PostgreSQL","text":""},{"location":"0013-postgresql/0015-every_data_pg/#0x01-8","title":"0x01-8\u7ea7\u9501\u7684\u4e0d\u5bf9\u79f0\u6027","text":"<p><code>2024-08-17 00:14:26 +0800</code></p> <p>\u7528\u4e8e\u521b\u5efa\u7d22\u5f15\u7684 <code>SHARE LOCK</code>\uff0c\u867d\u7136\u548c\u4fee\u6539\u65f6\u9700\u8981\u7684 <code>ROW EXCL</code> \u9501\u51b2\u7a81\uff0c\u5374\u4e0d\u548c\u81ea\u5df1\u51b2\u7a81\u3002\u867d\u7136\u521b\u5efa\u7d22\u5f15\u65f6\u4e0d\u80fd\u63d2\u5165\u6570\u636e\uff0c\u4f46\u662f\u53ef\u4ee5\u521b\u5efa\u5176\u4ed6\u7d22\u5f15\u3002 <code>SHARE</code> \u8fd9\u4e2a\u540d\u5b57\u975e\u5e38\u8d34\u5207\u3002</p> <p></p> <p>\u6ce8\u610f\uff1acreate index \u53ef\u4ee5\u4e8b\u52a1\u5757\u4e2d\u6267\u884c</p> <pre><code>test=# begin transaction;\nBEGIN\ntest=*# insert into test values (1);\nINSERT 0 1\ntest=*# create index on test (a);\nCREATE INDEX\ntest=*# commit;\nCOMMIT\n</code></pre> <p>\u800c\u4e3a\u4e86\u4e0d\u963b\u585e\u8bfb\u5199\uff0c\u6301\u6709 <code>SHARE UPDATE EXCL</code> \u9501\u7684\u884c\u4e3a\uff0c \u4f8b\u5982 <code>vacuum</code> ,  <code>create index concurrent</code> \uff0c\u5927\u90fd\u4e0d\u80fd\u5728\u4e8b\u52a1\u5757\u4e2d\u8fdb\u884c\u3002\u539f\u56e0\u53ef\u80fd\u662f\u8fd9\u4e9b\u64cd\u4f5c\u9700\u8981\u611f\u77e5\u5176\u4ed6\u6b63\u5728\u6267\u884c\u7684\u4e8b\u52a1\u7684\u72b6\u6001(status of running processes)\uff0c\u5176\u884c\u4e3a\u8d85\u51fa\u4e86\u4e00\u822c\u610f\u4e49\u4e0a MVCC \u7684\u3002</p>"},{"location":"0013-postgresql/0016-hashjoin/","title":"hash join","text":""},{"location":"0013-postgresql/0016-hashjoin/#high-level-view","title":"high level view","text":"<p>See Queries in PostgreSQL: 6. Hashing</p>"},{"location":"0013-postgresql/0016-hashjoin/#one-pass-hash-join","title":"One-pass hash join","text":"<p>Note that join in PostgreSql, we scan the right relation first, which means that the right relation is the \"inner relation\" and the left relation is the outer one. </p>"},{"location":"0013-postgresql/0016-hashjoin/#two-pass-hash-join","title":"Two-pass hash join","text":"<p>Since we can't allocate as much memory as we want, instead of building a hash table of the entire table, PG split the tables to several <code>batches</code> where all tuples have the same hash value flag.</p> <p>Batches are splited by hash value. Use several bits in hash value as a flag so we can put the tuples into different batches.</p> <p>There is a simple optimization that we can build the hash table in the first batch while scanning the inner table, and match the pair while scanning the outer table.</p>"},{"location":"0013-postgresql/0016-hashjoin/#parallel-one-pass-hash-join","title":"parallel one-pass hash join","text":"<p>With parallel workers, we can</p> <ul> <li>scan inner table and build shared hash table parallelly</li> <li>scan outer table parallelly</li> </ul> <p>Although in most cases, the neck of tp system is disk io, but parallel workers can still advance the speed efficiently. Because:</p> <ul> <li>In single process situation, the disk IO is synchronous\uff0cwhich means CPU is in idle while waiting IO. So, in the parallel case, CPU can be utilized more sufficiently.</li> <li>OS may has the technique to load the disk's content in advance, which is perdicularly useful in sequence scan. So multi-workers can read data file content more efficiently.</li> <li>In hash join, the compute of hash value may cost more CPU resource than normal TP operation.</li> </ul>"},{"location":"0013-postgresql/0016-hashjoin/#parallel-two-pass-hash-join","title":"parallel two-pass hash join","text":"<p>Same as the basic two-pass hash join, parallel workers build batches parallelly, both in reading from inner/outer tuple and writing data to tmp file. Since no worker can obtain a whole batch's data in the first scan, the technique described above can be used here.</p>"},{"location":"0013-postgresql/0016-hashjoin/#low-level-complement","title":"Low level complement","text":""},{"location":"0013-postgresql/0016-hashjoin/#single-process","title":"Single process","text":""},{"location":"0013-postgresql/0016-hashjoin/#inner-join","title":"inner join","text":"<p>What is inner join</p> <p>This is the simplest join method in hash join. So we introduce a simple hash join state machine here. (See <code>ExecHashJoinImpl</code> for detail )</p> <pre><code>START WITH:\n    state ==&gt; HJ_BUILD_HASHTABLE\n\ncase HJ_BUILD_HASHTABLE:\n    state ==&gt; HJ_NEED_NEW_OUTER\n\ncase HJ_NEED_NEW_OUTER:\n    ### generate a new outer tuple\n    state ==&gt; HJ_NEED_NEW_BATCH ### No more tuple in this batch.\n          ==&gt; HJ_SCAN_BUCKET;   ### Find a outer tuple. Can this one matches a\n                                    inner one?\n\ncase HJ_SCAN_BUCKET:\n    ### Scan the selected hash bucket for matches to current outer\n    state ==&gt; HJ_NEED_NEW_OUTER ### Whether we can find a match or not, we\n                                    always generate a new outer tuple.\n\ncase HJ_NEED_NEW_BATCH:\n    ### Try to advance to next batch\n    state ==&gt; HJ_NEED_NEW_OUTER;\n          ==&gt; FINISH\n</code></pre>"},{"location":"0013-postgresql/0016-hashjoin/#right-join","title":"right join","text":"<p>To complete right join, we can just emit each outer tuple even if there's no matched innner tuple.</p> <pre><code>case HJ_SCAN_BUCKET:\n    state ==&gt; HJ_FILL_OUTER_TUPLE  ### Can not find a match. Is it a left join?\n          ==&gt; HJ_NEED_NEW_OUTER\n\ncase HJ_FILL_OUTER_TUPLE:\n    state ==&gt; HJ_NEED_NEW_OUTER;    ### Whether emit the outer tuple with\n                                        null-filled left tuple or not, we always\n                                        generate a new outer tuple.\n</code></pre>"},{"location":"0013-postgresql/0016-hashjoin/#left-join","title":"left join","text":"<p>To complete this, we must remember whether a inner tuple has been matched. So <pre><code>case HJ_NEED_NEW_OUTER:\n    state ==&gt; HJ_FILL_INNER_TUPLES  ### This batch has been finished, see if\n                                        there are unmatched inner tuples.\n          ==&gt; HJ_NEED_NEW_BATCH\n          ==&gt; HJ_SCAN_BUCKET\n\ncase HJ_FILL_INNER_TUPLES:\n    state ==&gt; HJ_NEED_NEW_BATCH     ### No more unmatched inner tuples, so start\n                                        the next batch\n          ==&gt; HJ_FILL_INNER_TUPLES  ### return an unmatched inner tuple.\n</code></pre></p>"},{"location":"0013-postgresql/0016-hashjoin/#summary","title":"summary","text":"<p>Until now, we can generate a full state machine in non-parallel mode <pre><code>START WITH:\n    state ==&gt; HJ_BUILD_HASHTABLE\n\ncase HJ_BUILD_HASHTABLE:\n    state ==&gt; HJ_NEED_NEW_OUTER\n\ncase HJ_NEED_NEW_OUTER:\n    ### generate a new outer tuple\n    state ==&gt; HJ_FILL_INNER_TUPLES  ### This batch has been finished, see if\n                                        there are unmatched inner tuples.\n          ==&gt; HJ_NEED_NEW_BATCH ### No more tuple in this batch.\n          ==&gt; HJ_SCAN_BUCKET;   ### Find a outer tuple. Can this one matches a\n                                    inner one?\n\ncase HJ_SCAN_BUCKET:\n    ### Scan the selected hash bucket for matches to current outer\n    state ==&gt; HJ_FILL_OUTER_TUPLE  ### Can not find a match. Is it a left join?\n          ==&gt; HJ_NEED_NEW_OUTER ### Whether we can find a match or not, we\n                                    always generate a new outer tuple.\n\ncase HJ_NEED_NEW_BATCH:\n    ### Try to advance to next batch\n    state ==&gt; HJ_NEED_NEW_OUTER;\n          ==&gt; FINISH\n</code></pre></p>"},{"location":"0013-postgresql/0016-hashjoin/#parallel-hash","title":"parallel hash","text":"<p>Note that <code>BarrierArriveAndWait</code> will increase current phase. So each phase's status is not be assigned directly but self-increased.</p> <p>Let introduce the state machine first <pre><code>START WITH:\ncase HJ_BUILD_HASHTABLE:\n    ### If multi-batch, we need to hash the outer relation up front.\n    ExecParallelHashJoinPartitionOuter(node);\n    state ==&gt; HJ_NEED_NEW_BATCH ### Select a batch to work on.\n\ncase HJ_NEED_NEW_OUTER:\n    ExecParallelHashJoinOuterGetTuple\n        sts_parallel_scan_next\n\ncase HJ_NEED_NEW_BATCH:\n    ExecParallelHashJoinNewBatch()\n        switch PHJ_BATCH_STATE\n            case PHJ_BATCH_ELECT:\n                ### One backend allocates the hash table\n                ExecParallelHashTableAlloc\n                ### Fall through\n            case PHJ_BATCH_ALLOCATE:\n                ### Wait for allocation to complete and Fall through\n            case PHJ_BATCH_LOAD:\n                ### Start (or join in) loading tuples and Fall through.\n            case PHJ_BATCH_PROBE:\n                ### This batch is ready to probe\n                ExecParallelHashTableSetCurrentBatch\n                return true;\n            case PHJ_BATCH_SCAN:\n                ### detach and go around again\n            case PHJ_BATCH_FREE:\n    state ==&gt; HJ_NEED_NEW_OUTER\n</code></pre></p> <pre><code>    PHJ_BUILD_ELECT ==&gt; PHJ_BUILD_ALLOCATE\n</code></pre> <pre><code>ExecParallelHashJoinNewBatch\n</code></pre>"},{"location":"0013-postgresql/0016-hashjoin/#code-level-detail","title":"Code level Detail","text":""},{"location":"0013-postgresql/0016-hashjoin/#utility","title":"utility","text":"<ul> <li><code>ExecHashGetBucketAndBatch</code> : hash value to bucket number and batch number</li> </ul> <pre><code>ExecHashGetBucketAndBatch(HashJoinTable hashtable,\n                          uint32 hashvalue,\n                          int *bucketno,\n                          int *batchno)\n{\n    uint32      nbuckets = (uint32) hashtable-&gt;nbuckets;\n    uint32      nbatch = (uint32) hashtable-&gt;nbatch;\n\n    if (nbatch &gt; 1)\n    {\n        *bucketno = hashvalue &amp; (nbuckets - 1); ### tricky way as MOD\n        *batchno = pg_rotate_right32(hashvalue,\n                                     hashtable-&gt;log2_nbuckets) &amp; (nbatch - 1);\n        ### rotate hashvalue and MOD nbatch\n    }\n    else\n    {\n        *bucketno = hashvalue &amp; (nbuckets - 1);\n        *batchno = 0;\n    }\n}\n</code></pre> <ul> <li><code>ExecHashTableInsert</code> : insert hash value</li> </ul> <pre><code>ExecHashTableInsert\n    ExecHashGetBucketAndBatch(hashtable, hashvalue,\n                              &amp;bucketno, &amp;batchno);\n    if (batchno == hashtable-&gt;curbatch) ### put into hash table\n        hashTuple = (HashJoinTuple) dense_alloc\n        hashtable-&gt;spaceUsed += hashTupleSize;\n\n        ### For single batch, we may increase the nbucket\n        if (hashtable-&gt;nbatch == 1)\n            if (ntuples &gt; (hashtable-&gt;nbuckets_optimal * NTUP_PER_BUCKET) &amp;&amp; xxx)\n                hashtable-&gt;nbuckets_optimal *= 2;\n                hashtable-&gt;log2_nbuckets_optimal += 1;\n\n        ### For multi-batches, we may increase the batches\n        if (hashtable-&gt;spaceUsed +\n            hashtable-&gt;nbuckets_optimal * sizeof(HashJoinTuple) +\n            &gt; hashtable-&gt;spaceAllowed)\n            ExecHashIncreaseNumBatches()\n    else    ### put the tuple into a temp file for later batches\n        ExecHashJoinSaveTuple()\n</code></pre> <ul> <li><code>ExecHashIncreaseNumBatches</code> : increase batches</li> </ul> <pre><code>ExecHashIncreaseNumBatches\n    nbatch = oldnbatch * 2; ### double nbatches\n\n    ### init/update batchfiles\n    if (hashtable-&gt;innerBatchFile == NULL)\n        hashtable-&gt;innerBatchFile = palloc0_array(BufFile *, nbatch);\n        hashtable-&gt;outerBatchFile = palloc0_array(BufFile *, nbatch);\n        PrepareTempTablespaces();\n    else\n        hashtable-&gt;innerBatchFile = repalloc0_array()\n        hashtable-&gt;outerBatchFile\n\n    ### resize nbuckets?\n    if (hashtable-&gt;nbuckets_optimal != hashtable-&gt;nbuckets)\n        hashtable-&gt;nbuckets = hashtable-&gt;nbuckets_optimal;\n        hashtable-&gt;log2_nbuckets = hashtable-&gt;log2_nbuckets_optimal;\n        hashtable-&gt;buckets.unshared = repalloc_array()\n\n    ### scan through allchunks\n    while (oldchunks != NULL)\n        nextchunk = oldchunks-&gt;next.unshared\n\n        ### scan through all tuples in the chunk\n        idx = 0\n        while (idx &lt; oldchunks-&gt;used)\n            HashJoinTuple hashTuple = (HashJoinTuple) (HASH_CHUNK_DATA(oldchunks) + idx);\n            ...\n\n            ### where should the tuple go?\n            ExecHashGetBucketAndBatch(hashtable, hashTuple-&gt;hashvalue,\n                                      &amp;bucketno, &amp;batchno);\n            if (batchno == curbatch)\n                ### keep the tuple but copy it into the new chunk\n                copyTuple = (HashJoinTuple) dense_alloc(hashtable, hashTupleSize);\n                hashtable-&gt;buckets.unshared[bucketno] = copyTuple;\n            else\n                ### dump it out\n                ExecHashJoinSaveTuple()\n            idx += MAXALIGN(hashTupleSize);\n\n        pfree(oldchunks);\n        oldchunks = nextchunk;\n</code></pre> <ul> <li><code>ExecHashJoinSaveTuple</code> : save a tuple to a batch file.</li> </ul> <pre><code>    BufFileWrite(file, &amp;hashvalue, sizeof(uint32));\n    BufFileWrite(file, tuple, tuple-&gt;t_len);    ### len is record in \n                                                    MinimalTupleData structure\n</code></pre>"},{"location":"0013-postgresql/0016-hashjoin/#single-worker","title":"single worker","text":""},{"location":"0013-postgresql/0016-hashjoin/#build-state","title":"build state","text":"<p><pre><code>MultiExecProcNode\n    MultiExecPrivateHash\n        for (;;)\n            slot = ExecProcNode(outerNode);\n            if (ExecHashGetHashValue())\n                bucketNumber = ExecHashGetSkewBucket\n                if (bucketNumber != INVALID_SKEW_BUCKET_NO) ###  skew tuple\n                    ExecHashSkewTableInsert\n                else\n                    ExecHashTableInsert ### normal tuple\n            hashtable-&gt;totalTuples += 1;\n</code></pre> xxx</p>"},{"location":"0013-postgresql/0017-pgvector/","title":"PGVECTOR AND VECTOR DATABASE","text":""},{"location":"0013-postgresql/0017-pgvector/#_1","title":"\u5e8f\u8a00","text":"<p><code>pgvector</code>\u662f\u4e00\u4e2a\u5411\u91cf\u641c\u7d22\uff08\u6839\u636e\u8fd1\u4f3c\u5ea6\uff09\u7684\u63d2\u4ef6\uff0c\u7528\u6765\u52a0\u901fAKNN\uff08approximate nearest neighbor\uff09\u3002 <code>PASE</code>\u4e2d\u63d0\u5230\uff0c\u5411\u91cfANN\u7b97\u6cd5\u5305\u62ec4\u7c7b 1. tree-based algorithms     1. KD-Tree     2. RTree 2. quantization-based algorithms     1. IVFFlat     2. IVFADC     3. IMI 3. graph based algorithms     1. HNSW     2. NSG     3. SSG 4. hash-base algorithms     1. LSH     <code>pgvector</code> \u5305\u62ec\u4e24\u4e2a\u7b97\u6cd5\uff0c<code>IVFFlat</code> \u548c <code>HNSW</code>\uff0c\u540e\u7eed\u5185\u5bb9\u5c06\u4ee5\u8fd9\u4e24\u4e2a\u7b97\u6cd5\u7684\u5185\u5bb9\u53ca\u5176\u5b9e\u73b0\u5c55\u5f00\u3002</p>"},{"location":"0013-postgresql/0017-pgvector/#ivfflat","title":"IVFFlat","text":""},{"location":"0013-postgresql/0017-pgvector/#_2","title":"\u6982\u89c8","text":"<p>IVFFlat \u7b97\u6cd5\u4e3b\u8981\u5305\u62ec\u4ee5\u4e0b\u51e0\u4e2a\u6b65\u9aa4 + \u7d22\u5f15\u6784\u5efa\u9636\u6bb5     + \u4f7f\u7528 <code>KMeans</code> \u5c06\u6570\u636e\u96c6\u5212\u5206\u6210\u591a\u4e2a\u7c07(cluster) + \u67e5\u8be2\u9636\u6bb5     + \u901a\u8fc7\u6bcf\u4e2a\u7c07\u7684\u4e2d\u5fc3\u70b9\uff08\u5411\u91cf\u662f\u9ad8\u7ef4\u7684\u70b9\uff09\u83b7\u53d6N\u4e2a\u6700\u8fd1\u7684\u7c07     + \u904d\u5386\u8fd9N\u4e2a\u7c07\u7684\u6240\u6709\u70b9\uff0c\u4ece\u4e2d\u627e\u5230\u6700\u8fd1\u7684K\u4e2a\u70b9</p>"},{"location":"0013-postgresql/0017-pgvector/#_3","title":"\u7b97\u6cd5\u4ecb\u7ecd","text":""},{"location":"0013-postgresql/0017-pgvector/#kmeans","title":"\u57fa\u7840\u7b97\u6cd5kmeans","text":"<p>reference k-means clustering - Wikipedia \u7b97\u6cd5\u76ee\u6807\uff1a\u9009\u53d6K\u4e2a\u4e2d\u5fc3\u70b9\uff0c\u4f7f\u5f97\u6570\u636e\u96c6\u4e2d\u7684\u6240\u6709\u70b9\u5230\u5176\u6700\u8fd1\u7684\u4e2d\u5fc3\u70b9\u201c\u8ddd\u79bb\u201d\u4e4b\u548c\u6700\u8fd1\uff0c\u4ee5\u5e73\u65b9\u548c\u8ddd\u79bb\u4e3a\u4f8b\uff1a</p> <p>Given a set of observations \\((x_1, x_2, \\dots, x_n)\\), where each observation is a \\(d\\)-dimensional real vector, k-means clustering aims to partition the \\(n\\) observations into \\(k\\) (\\(\\leq n\\)) sets \\(S = {S_1, S_2, \\dot, S_k}\\) so as to minimize the within-cluster sum of squares (WCSS). Formally, the objective is to find:  \u7b97\u6cd5\u8fc7\u7a0b\uff1a \u6211\u4eec\u53ef\u4ee5\u5f88\u5bb9\u6613\u7684\u8bc1\u660e\u76ee\u6807\u51fd\u6570\u662f\u5173\u4e8e\\(S\\)\u7684\u51f8\u51fd\u6570 Given an initial set of \\(k\\) means \\(m_1^{1}, \\dots , m_k^{(1)}\\) (see below), the algorithm proceeds by alternating between two steps:</p> <ol> <li> <p>Assignment step: Assign each observation to the cluster with the nearest mean: </p> <p>where each \\(x_p\\)is assigned to exactly one \\(S^{t}\\), even if it could be assigned to two or more of them. 2. Update step: Recalculate means (centroids) for observations assigned to each cluster.</p> </li> </ol> <p>\u6839\u636e\u4e09\u89d2\u4e0d\u7b49\u5f0f\u53ef\u4ee5\u63a8\u51fa 1. Let <code>x</code> be a point and let <code>b</code> and <code>c</code> be centers. If \\(d(b, c) &gt; 2d(x,b)\\), then \\(d(x,c) \\geq d(x,b)\\) 2. Let <code>x</code> be a point and let <code>b</code> and <code>c</code> be centers, then \\(d(x,c) \\geq \\mathrm{max} \\{0,d(x,b)-d(b,c)\\}\\) </p> <p>\u6839\u636e\u4e0a\u8ff0\u5b9a\u7406\uff0c\u5728Kmeans\u8fed\u4ee3\u671f\u95f4\uff0c\u7ef4\u62a4\u4e00\u4e9b\u72b6\u6001\uff0c\u5373\u53ef\u51cf\u5c11\u8ba1\u7b97\u91cf \u8fc7\u7a0b\u5982</p> <p>\u4f7f\u7528\u4e09\u89d2\u4e0d\u7b49\u5f0f\u4f18\u5316Kmeans</p>"},{"location":"0013-postgresql/0017-pgvector/#kmeans_1","title":"kmeans \u4f18\u5316\u7bc7","text":"<p>\u4e0a\u8ff0\u7b97\u6cd5\u867d\u7136\u7b80\u6d01\uff0c\u4f46\u8ba1\u7b97\u4e0a\u590d\u6742\u5ea6\u9ad8\u3002\u5728pgvector\u7684IVFFlat\u5b9e\u73b0\u4e2d\uff0c\u4f7f\u7528\u4e86\u4e00\u4e9b\u4f18\u5316\u7b97\u6cd5\uff0c\u4e3b\u8981\u662f\u5982\u4e0b\u4e24\u7bc7\u8bba\u6587\uff1a * Using Triangle Inequality: \u4f7f\u7528\u4e09\u89d2\u4e0d\u7b49\u5f0f\u51cf\u5c11\u4e24\u70b9\u95f4\u8ddd\u79bb\u7684\u8ba1\u7b97\u6b21\u6570 * KMeans++ :\u4f7f\u7528\u968f\u673a\u70b9\u7684\u9009\u53d6\u6280\u5de7\u6765\u63d0\u9ad8\u6536\u655b\u901f\u5ea6\u548c\u51c6\u786e\u7387 Using the Triangle Inequality to Accelerate k-Means (aaai.org) kMeansPP-soda.pdf (stanford.edu)</p>"},{"location":"0013-postgresql/0017-pgvector/#using-triangle-inequality","title":"Using Triangle Inequality","text":"<p>\u601d\u8def\uff1a 1. \u5728\u9ad8\u7ef4\u5411\u91cf\u4e2d\uff0c\u8ba1\u7b97\u4e00\u6b21\u4e24\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u7684\u4ee3\u4ef7\u8f83\u9ad8\u3002 2. \u6839\u636e\u4e00\u4e9b\u6734\u7d20\u7684\u601d\u60f3\uff0c\u5047\u5982\u4f7f\u7528\u7684\u8ddd\u79bb\u51fd\u6570\u6ee1\u8db3\u4e09\u89d2\u4e0d\u7b49\u5f0f\\(d(a,b) \\leq d(a,c) + d(b,c)\\)\uff0c\u90a3\u4e48\u5728\u4e00\u6b21<code>kmeams</code>\u8fed\u4ee3\u4e2d\uff0c\u5982\u679c\u70b9 <code>x</code> \u8ddd\u5176\u4e2d\u5fc3\u70b9 <code>c(x)</code> \u7684\u8ddd\u79bb\u5f88\u8fd1\uff0c\u800c <code>c(x)</code> \u8ddd\u53e6\u4e00\u4e2a\u4e2d\u5fc3\u70b9 <code>c(y)</code> \u7684\u8ddd\u79bb\u5f88\u8fdc\uff0c\u90a3\u4e48<code>c(y)</code>\u5fc5\u7136\u4e0d\u662f<code>x</code> \u7684\u4e2d\u5fc3\u70b9\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u907f\u514d\u4e00\u6b21\u8ba1\u7b97\u3002</p>"},{"location":"0013-postgresql/0017-pgvector/#kmeans_2","title":"KMeans++","text":"<p>\u8bba\u6587\u4e2d\u7684\u6570\u5b66\u5206\u6790\u5f88\u591a\uff0c\u5176\u4e3b\u8981\u76ee\u7684\u4e3a\uff1a\u901a\u8fc7\u5728\u521d\u59cb\u5316\u7684\u65f6\u5019\u9009\u53d6\u6070\u5f53\u7684\u4e2d\u5fc3\u70b9\uff0c\u51cf\u5c11\u8fed\u4ee3\u6b21\u6570\u3002\u65b9\u6cd5\u4e3a\uff1a \u5047\u8bbe\u5411\u91cf\u7684\u5168\u96c6\u4e3a\\(X=\\{x_1,x_2,\\dots,x_n\\}\\subset \\mathbb{R}^d\\)  ,\\(D(x)\\) \u8868\u793a\u70b9 \\(x\\) \u5230\u5176\u5f53\u524d\u4e2d\u5fc3\u70b9\u7684\u8ddd\u79bb</p> <ol> <li>\u4ece\\(X\\) \u4e2d\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u70b9\\(c_1\\) </li> <li>\u4ee5\\(\\frac{D(x')}{\\sum_{x\\in X}D(x)}\\) \u7684\u6982\u7387\u9009\u62e9\\(x'\\)\u4e3a\\(c_i\\)</li> <li>\u91cd\u590d\u4e0a\u4e00\u6b65\u76f4\u5230\u6211\u4eec\u9009\u62e9\u4e86 \\(k\\) \u4e2a\u4e2d\u5fc3\u70b9\uff0c</li> <li>\u4f7f\u7528\u6807\u51c6\u7684k-means\u7b97\u6cd5\u8fdb\u884c\u540e\u7eed\u5904\u7406</li> </ol>"},{"location":"0013-postgresql/0017-pgvector/#_4","title":"\u5b9e\u73b0\u4ecb\u7ecd","text":""},{"location":"0013-postgresql/0017-pgvector/#page-representation","title":"page representation","text":""},{"location":"0013-postgresql/0017-pgvector/#key-functions","title":"Key functions","text":""},{"location":"0013-postgresql/0017-pgvector/#index-build","title":"index build","text":"<p>\u7d22\u5f15\u6784\u5efa\u5206\u4e3a\u4ee5\u4e0b\u51e0\u4e2a\u6b65\u9aa4</p> <ol> <li>\u8ba1\u7b97\u4e2d\u5fc3\u70b9</li> <li>\u6784\u5efa\u5143\u4fe1\u606f\u9875\uff08'meta page'\uff09</li> <li>\u6784\u5efa\u4e2d\u5fc3\u70b9\u9875\uff08'centerid pages'\uff09</li> <li>\u6784\u5efa\u6570\u636e\u9875\uff08'data pages'\uff09</li> </ol> <pre><code>ivfflatbuild\n    BuildIndex\n        InitBuildState\n        ComputeCenters\n        CreateMetaPage\n        CreateListPages\n        CreateEntryPages\n        FreeBuildState\n</code></pre>"},{"location":"0013-postgresql/0017-pgvector/#_5","title":"\u8ba1\u7b97\u4e2d\u5fc3\u70b9","text":"<ol> <li>\u5b9e\u73b0\u4e0a\uff0c\u6ca1\u6709\u626b\u63cf\u6240\u6709\u7684\u884c\u4ee5\u8ba1\u7b97\u4e2d\u5fc3\u70b9\uff0c\u800c\u662f\u201c\u91c7\u6837\u201d\u4e00\u4e9b<code>block</code>\u3002<ol> <li>\u4f1a\u9009\u62e9\\(ncenter \\times 50\\) \u4f5c\u4e3a\u91c7\u6837<code>block</code>\u7684\u6570\u91cf</li> <li></li> </ol> </li> </ol> <pre><code>ComputeCenters\n    SampleRows\n        /* The number of target samples is the number of centers times 50 */\n        numSamples = buildstate-&gt;lists * 50;\n        buildstate-&gt;samples = VectorArrayInit(numSamples, buildstate-&gt;dimensions);\n        BlockSampler_Init\n            &gt; provides algorithm for block level sampling of a relation as discussed on\n              pgsql-hackers 2004-04-02 (subject \"Large DB\")\n              Since we know the total number of blocks in advance, we can use the straightforward\n              Algorithm S from Knuth 3.4.2, rather than Vitter's algorithm.\n        reservoir_init_selection_state\n        while (BlockSampler_HasMore(&amp;buildstate-&gt;bs))\n        table_index_build_range_scan: callback=SampleCallback\n    IvfflatKmeans # Do as kmeans algrithm\n        if (samples-&gt;length &lt;= centers-&gt;maxlen)\n            QuickCenters(index, samples, centers);\n        else\n            ElkanKmeans(index, samples, centers);\n\nSampleCallback\n    AddSample\n        if (samples-&gt;length &lt; targsamples)\n            VectorArraySet\n        else\n            if (buildstate-&gt;rowstoskip &lt; 0)\n                rowstoskip = reservoir_get_next_S #skip some future samples\n            else\n                k = sampler_random_fract\n                VectorArraySet  # replace a old with this one randomly\n</code></pre>"},{"location":"0013-postgresql/0017-pgvector/#_6","title":"\u6784\u5efa\u5143\u4fe1\u606f\u9875","text":"<pre><code>CreateMetaPage # info about meta information\n    IvfflatNewBuffer\n    IvfflatInitRegisterPage\n    IvfflatCommitBuffer\n</code></pre>"},{"location":"0013-postgresql/0017-pgvector/#_7","title":"\u6784\u5efa\u4e2d\u5fc3\u70b9\u9875","text":"<p>\u5f53\u4e00\u4e2a\u9875\u7684\u5269\u4f59\u7a7a\u95f4\u4e0d\u591f\u65f6\uff0c\u4f7f\u7528\u5b57\u6bb5<code>nextblkno</code>\u6307\u5411\u4e0b\u4e00\u4e2a\u9875 <pre><code>typedef struct IvfflatPageOpaqueData\n{\n    BlockNumber nextblkno;\n    uint16      unused;\n    uint16      page_id;        /* for identification of IVFFlat indexes */\n}           IvfflatPageOpaqueData;\n\n\nCreateListPages # info about center infomation\n    foreach sampled vector\n        if (PageGetFreeSpace &lt; listSize) # we need more free space to store the vector \n            IvfflatAppendPage\n                newbuf = IvfflatNewBuffer\n                newpage = GenericXLogRegisterBuffer\n                IvfflatPageGetOpaque\n                old_page-&gt;next = this_page\n                IvfflatInitPage\n        PageAddItem # copy this point to the page\n</code></pre></p>"},{"location":"0013-postgresql/0017-pgvector/#_8","title":"\u6784\u5efa\u6570\u636e\u9875","text":"<pre><code>CreateEntryPages # omit parallel optimization here\n    AssignTuples # Scan table for tuples to index\n    tuplesort_performsort\n    InsertTuples\n        for (int i = 0; i &lt; buildstate-&gt;centers-&gt;length; i++)\n            buf = IvfflatNewBuffer(index, forkNum); # add new page for each data page list\n            startPage = BufferGetBlockNumber(buf);  # the first page number\n            foreach tuple in this list:\n                if (PageGetFreeSpace(page) &lt; itemsz) # append page\n                    IvfflatAppendPage(index, &amp;buf, &amp;page, &amp;state, forkNum);\n                PageAddItem()\n            IvfflatUpdateList(); # update the first page record of the center page\n</code></pre>"},{"location":"0013-postgresql/0017-pgvector/#index-scan","title":"index scan","text":""},{"location":"0013-postgresql/0017-pgvector/#begin-scan","title":"begin scan","text":"<pre><code>ivfflatbeginscan\n    IvfflatGetMetaPageInfo(index, &amp;lists, &amp;dimensions);  # Get lists and dimensions from metapage\n</code></pre>"},{"location":"0013-postgresql/0017-pgvector/#get-tupele","title":"get tupele","text":"<pre><code>ivfflatgettuple\n    if (first) # try to get the first tuple\n        GetScanLists # find 'probe' centers that are closest\n            while (BlockNumberIsValid(nextblkno)) # search all list pages\n                if (distance &lt; maxDistance) # omit probe here for easier understanding\n                    scanlist = (IvfflatScanList *) pairingheap_remove_first(so-&gt;listQueue);\n                    pairingheap_add(so-&gt;listQueue, &amp;scanlist-&gt;ph_node);\n                    maxDistance = ((IvfflatScanList *) pairingheap_first(so-&gt;listQueue))-&gt;distance;\n        GetScanItems # find closest items in the above centers\n            while (!pairingheap_is_empty(so-&gt;listQueue)) # for each center\n                while (BlockNumberIsValid(searchPage)) # for each block in the data list\n                    foreach (tuple)\n                        tuplesort_puttupleslot\n</code></pre>"},{"location":"0013-postgresql/0017-pgvector/#hnsw","title":"HNSW","text":""},{"location":"0013-postgresql/0017-pgvector/#_9","title":"\u6982\u89c8","text":"<p>HNSW \u7b97\u6cd5\u4e3b\u8981\u5305\u62ec\u4ee5\u4e0b\u51e0\u4e2a\u6b65\u9aa4 * \u7d22\u5f15\u6784\u5efa     * \u6784\u5efa\u5c42\u7ea7\u90bb\u8fd1\u56fe         * \u6bcf\u4e00\u5c42\u90fd\u662f\u90bb\u8fd1\u56fe \u2014\u2014 \u6bcf\u4e2a\u70b9\u90fd\u8bb0\u5f55\u5b83\u6700\u8fd1\u7684\u51e0\u4e2a\u70b9         * \u9ad8\u4e00\u5c42\u7684\u56fe\u662f\u4f4e\u4e00\u5c42\u56fe\u7684\u7f29\u7565\u56fe \u2014\u2014 \u53ea\u6709\u4f4e\u4e00\u5c42\u56fe\u7684\u90e8\u5206\u70b9 \u2014\u2014\uff0c\u6700\u4f4e\u4e00\u5c42\u7684\u56fe\u6709\u5168\u90e8\u70b9\u7684\u4fe1\u606f\u3002 * \u67e5\u8be2\u9636\u6bb5\uff0c\u5bf9\u4e8e\u76ee\u6807\u70b9\\(p\\)     * \u5bf9\u4e8e\u6bcf\u4e00\u5c42\u56fe\uff1a         * \u7ef4\u62a4\u4e00\u4e2a\u56fe\u4e2d\u8ddd\u70b9\\(p\\)\u6700\u8fd1\u7684\u70b9\u96c6\u5408\\(S\\)\uff0c\u4f9d\u6b21\u4ece\u5019\u9009\u70b9\u96c6\u5408\\(C\\)\u4e2d\u9009\u53d6\u4e00\u4e2a\u5143\u7d20\\(c\\)\uff1a\u5982\u679c\\(c\\)\u7684\u90bb\u5c45\\(neighbor(c)\\)\u6bd4\\(S\\)\u4e2d\u8ddd\\(p\\)\u6700\u8fdc\u7684\u70b9\\(s\\)\u8ddd\\(p\\)\u66f4\u8fd1\uff0c\u5373\\(d(neighbor(c), p) &lt; d(s,c)\\) \uff0c\u5219\u7528\\(neighbor(c)\\)\u66ff\u6362\u96c6\u5408\\(S\\)\u4e2d\u7684\u70b9\\(s\\)\uff0c\u5e76\u5c06\\(s\\)\u52a0\u5165\u5230\u5019\u9009\u96c6\u5408\\(C\\)\u4e2d\u3002\u91cd\u590d\u4ee5\u4e0a\u6b65\u9aa4\u76f4\u5230\\(|c| = 0\\)      * \u4ece\u9ad8\u5c42\u56fe\u5411\u5e95\u5c42\u56fe\u641c\u7d22\uff0c\u4f7f\u7528\u9ad8\u5c42\u56fe\u7684\u7ed3\u679c\\(S\\)\u4f5c\u4e3a\u4f4e\u5c42\u56fe\\(S\\)\u548c\\(C\\)\u7684\u521d\u59cb\u503c\u3002</p> <p></p>"},{"location":"0013-postgresql/0017-pgvector/#_10","title":"\u7b97\u6cd5\u4ecb\u7ecd","text":"<p>\u4e00\u4e0b\u987a\u5e8f\u53ea\u662f\u4e3a\u4e86\u4fbf\u4e8e\u7406\u89e3\uff0c\u4e0d\u4ee3\u8868\u8bba\u6587\u53d1\u5e03\u987a\u5e8f\u3002\u66f4\u591a\u7ec6\u8282\u53ef\u53c2\u8003\u8bba\u6587\u3002</p>"},{"location":"0013-postgresql/0017-pgvector/#nsw-hnsw","title":"NSW \u2014\u2014 HNSW\u7684\u8d77\u6e90?","text":"<p>NSW\u53ef\u4ee5\u89c6\u4e3a\u90bb\u8fd1\u56fe\uff0c\u6bcf\u4e2a\u70b9\u7ef4\u62a4\u81f3\u591a\\(K\\)\u4e2a\u8ddd\u79bb\u5176\u6700\u8fd1\u7684\u70b9\uff0c\u6b64\u65f6HNSW\u9000\u5316\u4e3a\u53ea\u6709\u4e00\u5c42\u7684\u7279\u6b8a\u60c5\u51b5\u3002</p>"},{"location":"0013-postgresql/0017-pgvector/#nsw","title":"NSW\u7684\u6784\u5efa","text":"<p>\u6784\u5efaNSW\u7684\u7b97\u6cd5\u5982\u4e0b\uff08\u6b64\u5904\u5ffd\u7565\u8fb9\u89d2\u60c5\u51b5\u4ee5\u65b9\u4fbf\u7406\u89e3 <pre><code>INPUT: a set of points S\nOUTPUT: graph G\nBUILD_LAYER(S)\n\nG = []\n# Insert each point into the graph\nFOREACH point IN S:           ---------- INSERT_POINT(graph, point)\n    neighbors[] = select_one_random(G)\n    candidate[] = neighbors[]\n    visited_points[] = neighbors[]\n\n    # Code in this WHILE loop is to find the neighbors of the point\n    # in current graph\n    WHILE (!candidate.empty())\n        nearest_candidate = candidate.pop_nearest(point)\n        furthest_neighbor = neighbors.get_furthest(point)\n\n        # no candidate can b closer\n        IF (distant(nearest_candidate, point) &gt;\n            distant(furthest_neighbor, point))\n            break;\n\n        # This candidate is great, but what about its neighbors?\n        FOREACH candidate_neighbor in nearest_candidate.neighbors()\n            IF (visited_points.has(candidate_neighbor))\n                continue\n            visited_points.append(candidate_neighbor)\n\n            # the furthest one can be changed\n            furthest_neighbor = neighbors.get_furthest(point)\n\n            # The neighbor of this candidate is also great, its neighbors\n            # can also be candidates\n            IF (distant(candidate_neighbor, point) &lt;\n                distant(furthest_neighbor, point))\n                candidate.append(candidate_neighbor)\n                neighbors.append(candidate_neighbor)\n                IF (neighbors.size() &gt; MAX_NEIGHBORS)\n                    neighbors.pop_furthest(point)\n\n    # Now we have found the neighbors, add a bidirection connections\n    # between the each neighbor and the point\n    FOREACH this_neighbor in neighbors\n        add_bidirection_direction(this_neighbor, point)\n\n        # Since the neighbor has one more connection, we may need\n        # to shrink. This is a point to optimize. Read paper for detail.\n        IF this_neighbor.neighbors().size() &gt; MAX_NEIGHBORS\n            this_neighbor.drop_longest_connection()\n\n# All points have been added\nRETURN G\n</code></pre></p>"},{"location":"0013-postgresql/0017-pgvector/#nsw_1","title":"NSW\u7684\u641c\u7d22","text":"<pre><code>OUTPUT: graph G, point P\nRETURN K nearest neighbors\nSEARCH_LAYER(G, p, K)\n\ncandidates = select_one_random(G)\nvisited_points = candidates\n\n# LOOP until we have K stable points\nWHILE TRUE\n    candidates_old = candidates\n\n    FOREACH candidate in candidates\n        FOREACH neighbor in candidate.neighbors()\n            if (visited_points.has(neighbor))\n                continue\n            visited_points.add(neighbor)\n\n            furthest_candidate = candidates.get_furthest(point)\n            IF (distant(neighbor, P) &lt; distant(furthest_candidate, P) ||\n                candidates.size() &lt; K)\n                candidates.add(neighbor)\n            IF (candidates.size() &gt; K)\n                candidates.pop_furthest(P)\n\n    IF candidates_old == candidates\n        BREAK\n\nRETURN candidates\n</code></pre>"},{"location":"0013-postgresql/0017-pgvector/#hnsw-nsw","title":"HNSW \u2014\u2014 NSW\u7684\u8fdb\u5316","text":"<p>\u663e\u7136\uff0c\u4e0a\u8ff0\u8fc7\u7a0b\u6700\u5927\u7684\u95ee\u9898\u4e4b\u4e00\u4e3a\uff1a 1. \u5bf9\u4e8e\u56fe\u7684\u6784\u5efa\uff1a\u6bcf\u65b0\u52a0\u5165\u4e00\u4e2a\u70b9\uff0c\u90fd\u9700\u8981\u4ece\u4e00\u4e2a\u968f\u673a\u70b9\u5f00\u59cb\u641c\u7d22\u5b83\u7684\u90bb\u5c45\u3002 2. \u5bf9\u4e8e\u56fe\u7684\u641c\u7d22\uff1a\u9700\u8981\u4ece\u4e00\u4e2a\u968f\u673a\u70b9\u5f00\u59cb\u641c\u7d22\u3002 \u4ee5\u4e0a\u4e24\u70b9\u5bfc\u81f4\uff0cNSW\u7b97\u6cd5\u641c\u7d22\u4e86\u5f88\u591a\u65e0\u7528\u7684\u70b9\u3002 H(hierarchy)NSW \u4e3a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4eceNSW\u56fe\uff08layer=0\uff09\u4e2d\u9009\u51fa\u90e8\u5206\u70b9\uff0c\u518d\u6784\u5efa\u4e00\u4e2a\u7f29\u7565\u7684NSW\u56fe\uff08layer=1\uff09\u3002\u5728\u641c\u7d22\u7684\u65f6\u5019\uff0c\u53ea\u9700\u8981\u4ecelayer=1\u7684\u56fe\u4e2d\u641c\u7d22\u51fa\u4e00\u4e2a\u7c97\u7565\u7ed3\u679c\uff0c\u5c06\u8be5\u7ed3\u679c\u7528\u4e8elayer=0\u641c\u7d22\u8fc7\u7a0b\u4e2d\u7684\u521d\u59cb\u5316\uff0c\u5373\u53ef\u5927\u91cf\u51cf\u5c11\u65e0\u7528\u7684\u641c\u7d22\u3002\u540c\u7406\uff0c\u5c42\u6570\u4e5f\u4e0d\u4e00\u5b9a\u53ea\u67092\u5c42\uff0c\u53ef\u4ee5\u6709\u66f4\u591a\u3002 \uff08\u8fd9\u4e2a\u601d\u60f3\u5728\u79d1\u7814\u4e2d\u4f3c\u4e4e\u7ecf\u5e38\u4f7f\u7528:\u5148\u5f97\u51fa\u4e00\u4e2a\u7c97\u7565\u7684\u7ed3\u679c\uff0c\u518d\u8fdb\u4e00\u6b65\u7cbe\u7ec6\u5316\uff09</p> <p>\u4e3a\u4e86\u6784\u5efa\u4e00\u4e2a\u8fd9\u6837\u7684\u56fe\uff0c\u6211\u4eec\u5728\u63d2\u5165\u4e00\u4e2a\u70b9\u65f6\u3002 <pre><code>INPUT: point P, a series of NSW graph G[]\n\ncur_layer = -ln(unif(0, 1)) * MAX_LAYER\n\n# for layer upper than current layer, just get a candidate\nFOR l from MAX_LAYER to cur_layer + 1\n    closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_point)\n\n# insert into each layer from top to bottom of the below layers\nFOR l from cur_layer to 0\n    closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_points)\n    INSERT_POINT(graph, P, neighbors = closest_points)\n</code></pre></p> <p>\u540c\u7406\u5728\u641c\u7d22\u65f6 <pre><code>INPUT: point P, a series of NSW graph G[]\n\ncur_layer = P.layer\n\n# for layer upper than current layer, just get a candidate\nFOR l from MAX_LAYER to cur_layer + 1\n    closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_point)\n\n# for layer leq than current layer, just get a candidate\nFOR l from cur_layer to 0\n    closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_point)\n\nreturn closest_points\n</code></pre></p>"},{"location":"0013-postgresql/0017-pgvector/#pgvector","title":"PGVECTOR\u4e2d\u7684\u7b97\u6cd5\u5b9e\u73b0","text":""},{"location":"0013-postgresql/0017-pgvector/#insert","title":"INSERT","text":"<p> <pre><code>/*\n * Algorithm 1 from paper: update graph by inserting an element\n * Parms:\n * @element: element to insert\n * @entryPoint: the initial entry point\n * @index?\n * @procinfo\n * @collation\n * @m: same as \"M\" in algo(number of established connections)\n */\nHnswInsertElement(HnswElement element, HnswElement entryPoint,\n                  Relation index, FmgrInfo *procinfo, Oid collation,\n                  int m, int efConstruction, bool existing)\n    level = element-&gt;level;\n    q = PointerGetDatum(element-&gt;vec)\n\n    # fill entry point list with the initial one\n    ep = list_make1(HnswEntryCandidate(entryPoint,))\n\n    # for layers upper than the element's level\n    for (int lc = entryLevel; lc &gt;= level + 1; lc--)\n        # only get the nearest element now\n        w = HnswSearchLayer()\n        ep = w;\n\n    # for the below layers\n    for (int lc = level; lc &gt;= 0; lc)\n        # search for top efConstruction nearest ones\n        w = HnswSearchLayer(efConstruction)\n\n        lw = w\n\n        # get neighbors\n        neighbors = SelectNeighbors(lw, lm, lc, procinfo, collation, NULL);\n\n        # add connection\n        # Is this different from paper?\n        #  bidirectional vs single directional\n        #  shrink directions or not shrink\n        AddConnections()\n            foreach(lc2, neighbors)\n                a-&gt;items[a-&gt;length++] = *((HnswCandidate *) lfirst(lc2));\n</code></pre></p>"},{"location":"0013-postgresql/0017-pgvector/#search-layer","title":"search layer","text":"<p> <pre><code>/*\n * Algorithm 2 from paper: search this layer with specifiyed enter points to\n * return \"ef\" closest neighbors\n * Parms:\n *  @q: same as algo\n *  @ep: enter points\n *  @ef: count of closest neighbors\n *  @lc: layer number\n *  @index:\n *  @procinfo:\n *  @collation:\n *  @inserting:\n *  @skipElement:\n */\nList *\nHnswSearchLayer(Datum q, List *ep, int ef, int lc, Relation index,\n                FmgrInfo *procinfo, Oid collation, int m, bool inserting,\n                HnswElement skipElement)\n    v = NULL.                 # visited points\n    C = NULL                  # set of candidates, nearer first\n    W = NULL                  # dynamic found nearest neighbors\n\n    # for each candidate in enter points\n    foreach(lc2, ep)\n        hc = (HnswCandidate *) lfirst(lc2); # HNSW candidates\n        v.add(hc)\n        C.add(hc)\n        W.add(hc)\n\n    # loop until no more candidates\n    while (!C.empty())\n        c = C.pop_nearest()\n\n        # for each neighbor \"e\" in the nearest candicate \"c\"\n        neighborhood = &amp;c-&gt;element-&gt;neighbors[lc];\n        for (int i = 0; i &lt; neighborhood-&gt;length; i++)\n            # neighbor e\n            HnswCandidate *e = &amp;neighborhood-&gt;items[i];\n            v.add(e)\n            DO # continue if visited\n\n            # f is the furthest element in dynamic neighbors\n            f = W.furthest()\n\n            # find a good neighbor who is closer to q than the worst one in W\n            if (DISTANT(e, q) &lt; DISTANT(f, q) || wlen &lt; ef)\n                ec = e\n                # neighbor of ec can also be the candidates\n                C.add(ec)\n                # add ec to W to promote the lower bound\n                W.add(ec)\n\n                # clean W if it's too large\n                if (skipElement == NULL ||\n                    list_length(e-&gt;element-&gt;heaptids) != 0)\n                    wlen++;\n                    /* No need to decrement wlen */\n                    if (wlen &gt; ef)\n                        W.pop_furthest\n    return W\n</code></pre></p>"},{"location":"0013-postgresql/0017-pgvector/#pairing-heap","title":"pairing heap","text":"<p>\u914d\u5bf9\u5806 - OI Wiki (oi-wiki.org) * insert(\\(\\mathrm{log}n\\)) * random_select(\\(\\mathrm{log} n\\)) select_min(\\(\\mathrm{log} n\\))  * delete_min(\\(\\mathrm{log} n\\))</p>"},{"location":"0013-postgresql/0017-pgvector/#select-neighbors","title":"select neighbors","text":"<pre><code>/*\n * Algorithm 4: select neighbors starting with specified candidates\n * PARAMS:\n *  @c : candidates\n *  @m : number of neighbors to return\n *  @lc: layer number\n *  @\n *\n * NOTES:\n *  extendCandidates = false\n *  keepPrunedConnections = true\n *  pruned\n */\nstatic List *\nSelectNeighbors(List *c, int m, int lc, FmgrInfo *procinfo, Oid collation,\n                HnswCandidate * *pruned)\n    r = NULL    # results---returning neighbors \n    w = c       # working candidates\n    wd = NULL;  # discarded candidates;\n\n    # Since we don't extend candidates, if the starting candidates isn't enought\n    # just return.\n    if (list_length(w) &lt;= m)\n        return w\n\n    # loop untils no more working candidate or enought neighbors\n    while (length(w) &gt; 0 &amp;&amp; length(r) &lt; m)\n        *e = llast(w); # get the nearest candidates\n        closer = CheckElementCloser(e, r, lc, procinfo, collation);\n        if(closer)\n            r.append(e)\n        else\n            wd.append(e)\n\n    # loop until discarded candidates are empty or enough neighbors\n    while (!wd.empty() &amp;&amp; length(r) &lt; m)\n        r.append(wd.pop_nearest())\n\n    prune = wd.nearest()\n    return r\n</code></pre>"},{"location":"0013-postgresql/0017-pgvector/#data-structure","title":"data structure","text":"<pre><code>typedef struct HnswElementData\n{\n    List       *heaptids;\n    uint8       level;\n    uint8       deleted;\n    HnswNeighborArray *neighbors;\n    BlockNumber blkno;\n    OffsetNumber offno;\n    OffsetNumber neighborOffno;\n    BlockNumber neighborPage;\n    Vector     *vec;\n}           HnswElementData;\n\ntypedef struct HnswCandidate\n{\n    HnswElement element;\n    float       distance;\n}           HnswCandidate;\n\ntypedef struct HnswNeighborArray\n{\n    int         length;\n    HnswCandidate *items;\n}           HnswNeighborArray;\n</code></pre>"},{"location":"0013-postgresql/0017-pgvector/#_11","title":"\u5e95\u5c42\u5b9e\u73b0\u4e2d\u7684\u95ee\u9898","text":"<ol> <li>\u8bba\u6587\u4e2d\u7684\u56fe\u662f\u53cc\u5411\u8fde\u63a5\uff0c\u800cpgvector\u5b9e\u73b0\u7684\u662f\u5355\u5411\u8fde\u63a5</li> <li>pgvector\u4e2d\u63d2\u5165\u65b0\u5411\u91cf\u65f6\uff0c\u6ca1\u6709\u66f4\u65b0\u5176\u90bb\u5c45\u7684\u8fde\u63a5\u3002\uff08\u8fd9\u4e48\u4f4e\u7ea7\u7684\u95ee\u9898\u6709\u5f85\u9a8c\u8bc1\uff09</li> </ol>"},{"location":"0013-postgresql/0017-pgvector/#page-representation_1","title":"page representation","text":""},{"location":"0013-postgresql/0017-pgvector/#vector-database","title":"vector database \u8c03\u7814","text":""},{"location":"0013-postgresql/0017-pgvector/#qdrant","title":"qdrant","text":"<p>Vector databases are optimized for storing and querying these high-dimensional vectors efficiently, and they often using specialized data structures and indexing techniques such as Hierarchical Navigable Small World (HNSW) \u2013 which is used to implement Approximate Nearest Neighbors \u2013 and Product Quantization, among others.</p> <p></p>"},{"location":"0013-postgresql/0017-pgvector/#_12","title":"\u7b97\u6cd5\u4e0e\u5b58\u50a8","text":"<p>qdrant\u4f7f\u7528 <code>hnsw</code> \u7b97\u6cd5</p> <p>A key feature of Qdrant is the effective combination of vector and traditional indexes. It is essential to have this because for vector search to work effectively with filters, having vector index only is not enough. In simpler terms, a vector index speeds up vector search, and payload indexes speed up filtering.</p> <p>payload \u7d22\u5f15\u4ec5\u7528\u4e8e\u8fc7\u6ee4\uff0c\u6211\u4eec\u5173\u6ce8\u5411\u91cf\u7d22\u5f15\u90e8\u5206</p> <p>Qdrant currently only uses HNSW as a vector index.</p> <p>All data within one collection is divided into segments. Each segment has its independent vector and payload storage as well as indexes.</p>"},{"location":"0013-postgresql/0017-pgvector/#_13","title":"\u9644\u5f55","text":""},{"location":"0013-postgresql/0017-pgvector/#trianlge-inequality-kmeans","title":"trianlge-inequality-Kmeans","text":"<ul> <li>\u7ef4\u62a4\u7684\u72b6\u6001\uff1a<ul> <li>lower bound \\(l(x,c)\\) of \\(d(x,c)\\) for each point \\(x\\) and center \\(c\\)<ul> <li>each time \\(d(x,c)\\) is computed, set \\(l(x,c)=d(x,c)\\)</li> </ul> </li> <li>\\(c(x)= \\mathrm{argmin}_cd(x,c)\\) get its center for each point \\(x\\)</li> <li>upper bound \\(u(x)\\) of \\(d(x,c)\\) for each point \\(x\\), indicating the upper bound of \\(x\\) to its center</li> <li>\\(r(x)\\) is a <code>boolean</code> value indicate whether \\(u(x, c)\\) is out of date</li> </ul> </li> <li>\u8fc7\u7a0b\uff1a <ul> <li>initialization<ul> <li>compute \\(d(x,c)\\) for each point \\(x\\) and each center \\(c\\), which means \\(l(x,c)\\) is computed too</li> <li>\\(u(x)=\\mathrm{min}_c(d,c)\\) for each point \\(x\\)</li> </ul> </li> <li>repeate until convergence:<ol> <li>For each pair of centers \\(c\\) and \\(c'\\) , compute \\(d(c,c')\\), this is to compute \\(s(c)=1/2\\min_{c'\\neq c}d(c,c')\\) . So we get the distance to the nearest center of each center</li> <li>identify all point \\(x\\) such that \\(u(x) \\le s(c(x))\\) .If the point is so near to its center, its center can't be changed in this iteration. See lemma 1</li> <li>For each remaining point \\(x\\) and centers \\(c\\) such that<ol> <li>\\(c\\neq c(x)\\)  (not the current center) and</li> <li>\\(u(x)&gt;l(x,c)\\) (upper bound to current center greater than lower bound of this center) and</li> <li>\\(u(x)&gt;\\frac{1}{2}d(c(x),c)\\)(upper bound to current center greater than half of the two centers distant, See lemma 1) iterm <code>2</code> and <code>3</code> means \\(u(x)\\) may be too big </li> <li>DO:<ol> <li>If \\(r(x)\\) , compute\\(d(x, c(x))\\) and set \\(r(x)=false\\), else \\(d(x,c(x))=u(x)\\)</li> <li>if \\(u(x)&gt;l(x,c)\\) and \\(u(x)&gt;\\frac{1}{2}d(c(x),c)\\) then (same as the above) <ol> <li>compute \\(d(x,c)\\), if \\(d(x,c) &lt; d(x,c(x))\\) then assign \\(c(x)=c\\) (update center)</li> </ol> </li> </ol> </li> </ol> </li> <li>For each center \\(c\\) , let \\(m(c)\\) be the new mean point</li> <li>For each point \\(x\\) and center \\(c\\), assign \\(l(x,c)=\\max\\{l(x,c)-d(c,m(c))\\}\\) (update lower bound by lemma 2) </li> <li>For each point x, assign \\(u(x)=u(x) + d(m(c(x)),c(x))\\) (update lower bound by lemma 2 ) and \\(r(x)=true\\)</li> <li>Replace each center \\(c\\) by \\(m(c)\\)</li> </ol> </li> </ul> </li> </ul>"},{"location":"0013-postgresql/0017-pgvector/#knuths-algorithm-s","title":"\u91c7\u6837\u7b97\u6cd5 Knuth's algorithm S","text":"<ul> <li>\u7b97\u6cd5\u63cf\u8ff0\uff1a Select \\(n\\) items from a set of \\(M\\) iems with equal probility for \\(M \\geq n\\) </li> <li>\u5b9e\u73b0</li> </ul> <pre><code>samples = set[0:n-1]\nfor i in (n, M)\n    with prob = n/i:\n        samples[random()%n] = set[i]\n</code></pre> <p>\u53c2\u8003\u6587\u6863 Knuth's algorithm S - Rosetta Code \u3002</p> <p>\u793e\u533a\u8ba8\u8bba [PostgreSQL: Re: GENERAL] Large DB</p>"},{"location":"0013-postgresql/0017-pgvector/#_14","title":"\u540e\u8bb0","text":"<ul> <li>pg\u5b98\u65b9\u7684\u65b0\u95fb\uff1aPostgreSQL: pgvector 0.5.0 Released! \u3002pgvector\u5728\u793e\u533a\u7684\u70ed\u5ea6\u4e0d\u5c0f</li> </ul>"},{"location":"0013-postgresql/0018-sequence_type/","title":"sequence type","text":""},{"location":"0013-postgresql/0018-sequence_type/#background","title":"background","text":"<p>From official documents:</p> <p>9.17. Sequence Manipulation Functions</p> <p>CREATE SEQUENCE</p> <ul> <li>Sequence objects are special single-row tables created with CREATE SEQUENCE.</li> <li>Sequence objects are commonly used to generate unique identifiers for rows of a table. The sequence functions, provide simple, multiuser-safe methods for obtaining successive sequence values from sequence objects.</li> </ul>"},{"location":"0013-postgresql/0018-sequence_type/#main-function","title":"Main function","text":"<p>There is no much concerns about these functions</p> <ul> <li> <p><code>nextval</code></p> <ul> <li>Advances the sequence object to its next value and returns that value</li> </ul> </li> <li> <p><code>setval</code></p> <ul> <li> <p>Some examples</p> SELECT setval('myseq', 42); Next nextval will return 43 SELECT setval('myseq', 42, true); Same as above SELECT setval('myseq', 42, false); Next nextval will return 42 </li> </ul> </li> <li> <p><code>currval</code></p> <ul> <li>Returns the value most recently obtained by <code>nextval</code> for this sequence in the current session</li> </ul> </li> <li> <p><code>lastval</code></p> <ul> <li>Returns the value most recently returned by <code>nextval</code> in the current session. This function is identical to <code>currval</code>, except that instead of taking the sequence name as an argument it refers to whichever sequence <code>nextval</code> was most recently applied to in the current session.</li> </ul> </li> </ul> <p>** There is a caution: ** </p> <p>There is no rollback of the <code>sequence</code> type. Official document is post below:</p> <p>To avoid blocking concurrent transactions that obtain numbers from the same sequence, the value obtained by <code>nextval</code> is not reclaimed for re-use if the calling transaction later aborts. This means that transaction aborts or database crashes can result in gaps in the sequence of assigned values. That can happen without a transaction abort, too. For example an <code>INSERT</code> with an <code>ON CONFLICT</code> clause will compute the to-be-inserted tuple, including doing any required <code>nextval</code> calls, before detecting any conflict that would cause it to follow the <code>ON CONFLICT</code> rule instead. Thus, PostgreSQL sequence objects cannot be used to obtain \u201cgapless\u201d\uff08\u65e0\u7f1d\u7684\uff09 sequences.</p>"},{"location":"0013-postgresql/0018-sequence_type/#most-important","title":"Most important","text":"<p>All things above doesn\u2019t worth a post, but the replication hack of this type does. Considering a master-standby example, the <code>currval</code>\u00a0in standby is always bigger than the master's. And once the value in master advances and the new value doesn't precede the standby's one, the <code>currval</code>\u00a0in standby would't advanced immediately. This is a greate skill to reduce the wal records.</p>"},{"location":"0013-postgresql/0019-ssl-in-PG/","title":"SSL in PG","text":""},{"location":"0013-postgresql/0019-ssl-in-PG/#overview","title":"Overview","text":"<p>In application level, \u201dPostgreSQL\u201c has native supports for using SSL connections. This requires that OpenSSL is installed on both client and server systems and that support in PostgreSQL is enabled at build time.</p> <p>With SSL, we can:</p> <ol> <li>Encrypted data on Internet transmission</li> <li>Allow client to authorize the server(PostgreSQL), which can protect the client from connecting to the attacker\u2019s server</li> <li>Allow server to authorize the client, which can stop the attacker from connecting to the database even if password leak.</li> </ol>"},{"location":"0013-postgresql/0019-ssl-in-PG/#just-encrypt-internet-transmission","title":"Just encrypt internet transmission","text":""},{"location":"0013-postgresql/0019-ssl-in-PG/#build-binary-from-source","title":"build binary from source","text":"<p>just configure with <code>-with-openssl</code>  option.  You may need to install <code>ssl-dev</code> tools first</p> <pre><code>sudo apt-get install libssl-dev\n</code></pre> <p>Below is a building example:</p> <pre><code>export build_dir=/home/dev/build\nexport data_dir=/home/dev/data\nexport superuser=postgres\nexport defaultdb=test\n\n${build_dir}/bin/pg_ctl -D ${data_dir} stop\nrm -rf build\nrm -rf data\n\ncd postgresql\ngit clean -xdf\n./configure \\\n    --prefix=${build_dir} \\\n    --enable-debug \\\n    --enable-cassert \\\n    --with-tcl \\\n    --with-perl \\\n    --with-python \\\n    --enable-debug \\\n    --without-icu \\\n    --with-openssl \\\n    CC=/usr/bin/gcc \\\n    CFLAGS='-O0 -pipe -Wall -g3'\n\n# export CLFAGS=\"-O0 -Wall -g3\"\n# export CPPLFAGS=\"-O0 -Wall -g3\"\n\nmake -j8 &amp;&amp; make install\nmake -C contrib install\n${build_dir}/bin/initdb --username=${superuser} --pgdata=${data_dir}\n${build_dir}/bin/pg_ctl -D ${data_dir} -l ${data_dir}/logfile start\n${build_dir}/bin/psql -U${superuser} postgres -c \"create database ${defaultdb};\"\necho \"----------------- all finished -----------------------\"\necho \"use ************** \"\necho \"[ ${build_dir}/bin/psql -U${superuser} ${defaultdb} ] \"\necho \"to connect postgresql\"\ncd ..\n</code></pre>"},{"location":"0013-postgresql/0019-ssl-in-PG/#configure-ssl-on-server","title":"Configure ssl on server","text":""},{"location":"0013-postgresql/0019-ssl-in-PG/#prepare-a-certification","title":"prepare a certification","text":"<p>use <code>openssl</code> command to generate one. The <code>127.0.0.1</code> means that the certification only protects localhost connections</p> <pre><code># generate root certification\nopenssl req -new -x509 -days 3650 -nodes \\\n  -out ca.crt -keyout ca.key -subj \"/CN=root-server-ca\"\n\n# generate csr and key\nopenssl req -new -nodes -text -out server.csr \\\n  -keyout server.key -subj \"/CN=127.0.0.1\"\n\n# generate certification\nopenssl x509 -req -in server.csr -text -days 365 \\\n  -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt\n</code></pre>"},{"location":"0013-postgresql/0019-ssl-in-PG/#configure-in-pgdata","title":"configure in <code>$PGDATA</code>","text":"<p>copy the <code>key</code> and <code>crt</code> to <code>$PGDATA</code></p> <pre><code>export $PGDATA=/home/dev/data\ncp server.key $PGDATA/.\ncp server.crt $PGDATA/.\n</code></pre> <p>configure in <code>postgresql.conf</code> </p> <pre><code>ssl = on\nssl_cert_file = 'server.crt'\nssl_key_file = 'server.key'\n</code></pre> <p>And (re)start the server</p>"},{"location":"0013-postgresql/0019-ssl-in-PG/#connect-and-test","title":"connect and test","text":"<pre><code>psql \"host=127.0.0.1 port=5432 dbname=postgres user=postgres sslmode=require\"\n</code></pre>"},{"location":"0013-postgresql/0019-ssl-in-PG/#server-sides-authorization","title":"Server sides Authorization","text":"<p>Note that the client hasn\u2019t check the certification of the server now. Check in this way:</p> <pre><code>PGSSLROOTCERT=ca.crt \\\npsql \"host=127.0.0.1 port=5432 dbname=postgres user=postgres sslmode=require\"\n</code></pre>"},{"location":"0013-postgresql/0019-ssl-in-PG/#client-sides-authorization","title":"Client sides Authorization","text":"<p>Generate certification similarly</p> <pre><code>openssl req -new -x509 -days 3650 -nodes \\\n  -out ca-client.crt -keyout ca-client.key -subj \"/CN=root-client-ca\"\n\nopenssl req -new -nodes -text -out client.csr \\\n  -keyout client.key -subj \"/CN=postgres\"\n\nopenssl x509 -req -in client.csr -text -days 365 \\\n  -CA ca-client.crt -CAkey ca-client.key -CAcreateserial -out client.crt\n</code></pre> <p>prepare in <code>$PGDATA</code></p> <pre><code>cp ca-client.crt $PGDATA/.\necho -e \"\\nssl_ca_file = 'ca-client.crt'\" &gt;&gt; $PGDATA/postgresql.conf\n</code></pre> <p>and restart</p>"},{"location":"0013-postgresql/0019-ssl-in-PG/#test-connection","title":"test connection","text":"<p>Before connection, remember to set <code>pg_hba.conf</code> to only authorized with cetification.</p> <pre><code>hostssl    all             all             127.0.0.1/32          cert\n</code></pre> <pre><code>psql \"sslrootcert=ca.crt sslcert=client.crt sslkey=client.key \\\n  host=127.0.0.1 dbname=postgres user=postgres sslmode=verify-full\"\n</code></pre>"},{"location":"0013-postgresql/0028-pg_repack/","title":"pg_repack","text":""},{"location":"0013-postgresql/0028-pg_repack/#principle","title":"principle","text":"<p>pg_repack 1.5.0 -- Reorganize tables in PostgreSQL databases with minimal locks</p> <p>https://github.com/reorg/pg_repack</p> <ol> <li>create a log table to record changes made to the original table</li> <li>add a trigger onto the original table, logging INSERTs, UPDATEs and DELETEs into our log table</li> <li>create a new table containing all the rows in the old table</li> <li>build indexes on this new table</li> <li>apply all changes which have accrued in the log table to the new table</li> <li>swap the tables, including indexes and toast tables, using the system catalogs</li> <li>drop the original table</li> </ol> <p>The basic idea is</p> <ol> <li>transport the existent data with a old snapshot</li> <li>record the incremental data into a table and replay the record</li> </ol> <p>And this idea is so general that almost all online-ddl ability in PG(supported in extensions) takes the way.</p>"},{"location":"0013-postgresql/0028-pg_repack/#details","title":"details","text":"<p>Although the idea is so simple, there are many problems to challenge. Such as how to ensure there are no duplicated or lost data in both existent part and incremental part. So code-level details are shown below:</p> <p>All the 7 step are manipulated through 2 connections: See function <code>repack_one_table</code> for detail:</p> <ol> <li> <p>create a log table to record changes made to the original table</p> </li> <li> <p>add a trigger onto the original table, logging INSERTs, UPDATEs and DELETEs into our log table</p> </li> <li> <p><code>conn1</code> starts a transaction and acquire an advisory lock to prevent potential conflict with other repack process</p> </li> <li>get the <code>AccessiveExclusive</code> lock to the original table, <code>tbl</code> for example</li> <li>create the trigger on <code>tbl</code> and the corresponding  <code>log-table</code> where the incremental changes will be stored.</li> <li>(Just comments: If we release the exclusive lock here, we may not able to acquire a shared lock later if another process has gotten a exclusive lock in the interval, which can cause that we have no way to continue or revert what we have done. So we must acquire a lock during the whole process. \ud83d\udc4c)</li> <li><code>conn2</code> tries to acquire the <code>AccessiveShared</code> lock on <code>tbl</code>. Since the <code>conn1</code> 's transaction hasn't finished, this lock acquisition will be blocked.</li> <li><code>conn1</code> kill all connections that tries to perform a DDL operation, whose character is waiting for <code>AccessiveLock</code> . Then, <code>conn1</code> commits. </li> <li> <p>Now <code>conn2</code> get the <code>AccessiveShared</code> lock on <code>tbl</code> , which can ensure that no other dll operation on <code>tbl</code> \u270c\ufe0f</p> </li> <li> <p>create a new table containing all the rows in the old table</p> </li> <li> <p><code>conn1</code> begins a serializable transaction( repeatable read, at least)</p> </li> <li> <p><code>conn1</code> get the <code>vxids</code> of current active transactions</p> </li> <li> <p><code>conn1</code> delete all data in <code>tbl</code> with the current snapshot (This means we don't perform a \u201ctruncate\u201d operation ). This is a very skillful technique:</p> <ol> <li> <p>The table shows the secret:</p> tbl log table visible existent data empty invisible incremental data incremental data </li> <li> <p>All existent data is visible in <code>tbl</code> through the current snapshot</p> </li> <li> <p>All incremental data is invisible in <code>log table</code> and <code>tbl</code> (The latter one isn't important</p> </li> <li> <p>So there is no lost or duplicated data</p> </li> </ol> </li> <li> <p><code>conn1</code> copies all data in <code>tbl</code> to a temp table <code>tbl-tmp</code>  for example</p> </li> <li> <p><code>conn1</code> commits</p> </li> <li> <p>build indexes on this new table. (I don't care this.)</p> </li> <li> <p>apply all changes which have accrued in the log table to the new table</p> </li> <li> <p><code>conn1</code> apply at most 1000 records in <code>log-table</code> , until</p> <ol> <li>the remaining records are few. AND</li> <li>All transactions in <code>vxids</code> finish. This operation is to keep the ISOLATION, but it still has some accidence. #TODO </li> </ol> </li> <li>(Just comments: Now we believe that there is few records in <code>log-table</code> .)</li> <li><code>conn2</code> acquire the <code>AccessiveExclusive</code> lock. Note that no other process can do that</li> <li> <p><code>conn2</code> apply all data in <code>log-table</code></p> </li> <li> <p>swap the tables, including indexes and toast tables, using the system catalogs</p> </li> <li> <p><code>conn2</code> swaps <code>relfilenode</code> between <code>tbl-tmp</code> and <code>tbl</code></p> </li> <li> <p><code>conn2</code> commits</p> </li> <li> <p>drop the original table</p> </li> <li> <p><code>conn1</code> drop the current <code>tbl-tmp</code></p> </li> <li><code>conn1</code> analyze the current <code>tbl</code></li> <li><code>conn1</code> release the advisory lock</li> </ol>"},{"location":"0013-postgresql/0020-slru/0020-slru/","title":"SLRU","text":"<p>\u672c\u6587\u4e3b\u8981\u4e3a<code>SLRU</code>\u672c\u8eab\u7684\u7ed3\u6784\u89e3\u8bfb\u3002</p>"},{"location":"0013-postgresql/0020-slru/0020-slru/#_1","title":"\u7b80\u8ff0","text":"<ul> <li>slru\u7528\u6765\u5e72\u4ec0\u4e48\uff1f<ul> <li>slru\u662f\u4e00\u4e2a\u7b80\u5355\u7684buffer\u7ba1\u7406\u6a21\u5757\uff0csimple slru</li> </ul> </li> <li>\u6709\u4e86buffer pool manager\uff0c\u4e3a\u4ec0\u4e48\u8fd8\u8981slru\uff1f<ul> <li>bpm\u7ba1\u7406\u901a\u7528\u7684page\uff0c\u6bd4\u5982heap\uff0cvm\u7b49</li> <li>slru\u6700\u5927\u7684\u7279\u70b9\u5c31\u662flru\uff0c\u975e\u5e38\u9002\u5408\u5904\u7406xid\u8fd9\u6837\uff0c\u9012\u589e\u7684\u4fe1\u606f\u3002</li> </ul> </li> <li>\u4e0b\u9762\u7684\u4ee3\u7801\u5206\u6790\u57fa\u4e8epg15</li> </ul>"},{"location":"0013-postgresql/0020-slru/0020-slru/#_2","title":"\u5b58\u50a8\u7ed3\u6784","text":"<p>\u4e0ebpm\u4e0d\u540c\uff0c\u901a\u8fc7slru\u7ba1\u7406\u7684page\uff0c\u5176\u6587\u4ef6\u5927\u5c0f\u56fa\u5b9a\uff0c\u4e00\u4e2a\u6587\u4ef6\u670932\u4e2apage\uff0c\u4e00\u4e2apage\u67098KB\uff0c\u6545\u4e00\u4e2a\u6587\u4ef6\u6700\u5927\u4e3a256K\u3002</p> <p>\u4e0eWAL\u4e0d\u540c\uff0cWAL\u6587\u4ef6\u7684\u5927\u5c0f\u5728\u521b\u5efa\u65f6\u5c31\u5df2\u7ecf\u786e\u5b9a\u4e3a16M\uff0c\u4e0eWAL\u6587\u4ef6\u91cd\u7528\u4fdd\u6301\u4e00\u81f4\uff0c\u800cslru\u7684\u6587\u4ef6\uff0c\u5148\u5728\u5185\u5b58\u4e2d\u4ea7\u751f\u76f8\u5e94\u7684page\uff0c\u518d\u4f1a\u53bb\u843d\u76d8\u3002</p> <pre><code>#define SLRU_PAGES_PER_SEGMENT  32\n</code></pre>"},{"location":"0013-postgresql/0020-slru/0020-slru/#slru","title":"\u5185\u5b58slru","text":""},{"location":"0013-postgresql/0020-slru/0020-slru/#buffer","title":"\u5168\u5c40 buffer \u6570\u7ec4","text":"<pre><code>typedef struct SlruSharedData\n{\n    LWLock     *ControlLock;\n\n    /* Number of buffers managed by this SLRU structure */\n    int         num_slots;\n\n    /*\n     * Arrays holding info for each buffer slot.  Page number is undefined\n     * when status is EMPTY, as is page_lru_count.\n     */\n    char      **page_buffer;\n    SlruPageStatus *page_status;\n    bool       *page_dirty;\n    int        *page_number;\n    int        *page_lru_count;\n    LWLockPadded *buffer_locks;\n\n    XLogRecPtr *group_lsn;\n    int         lsn_groups_per_page;\n\n    /*----------\n     * We mark a page \"most recently used\" by setting\n     *      page_lru_count[slotno] = ++cur_lru_count;\n     * The oldest page is therefore the one with the highest value of\n     *      cur_lru_count - page_lru_count[slotno]\n     * The counts will eventually wrap around, but this calculation still\n     * works as long as no page's age exceeds INT_MAX counts.\n     *----------\n     */\n    int         cur_lru_count;\n} SlruSharedData;\n</code></pre> <p>\u4ece\u5185\u5b58\u7ed3\u6784\u4e0a\u770b\uff0c\u662f\u4e00\u4e2a\u6570\u7ec4\uff0c\u6bcf\u4e2a\u5143\u7d20\u4ee3\u8868\u4e00\u4e2apage\u3002\u540c\u65f6\uff0c\u8bb0\u5f55\u8fd9\u4e9bpage\u7684\u4f7f\u7528\u6b21\u6570\u3002</p> <pre><code>page_lru_count[slotno] = ++cur_lru_count;\n</code></pre> <p>\u540c\u65f6\u6bcf\u4e2apage\uff0c\u90fd\u6709\u72b6\u6001\u6807\u8bc6\uff0c\u4ee5\u5728\u5237\u810f\u65f6\uff0c\u786e\u5b9a\u810f\u9875\u3002\u5b9e\u9645\u4e0a\u8fd9\u91cc\u6ca1\u6709\u810f\u9875\u8fd9\u4e2a\u9009\u9879\uff0c\u56e0\u4e3a\u53ea\u6709 <code>valid</code> \u72b6\u6001\u7684\u9875\u624d\u6709\u53ef\u80fd\u662f\u810f\u9875\uff0c\u6709\u5305\u542b\u5173\u7cfb\u3002\u6545\u5728<code>SlruSharedData</code> \u4e2d\u4f7f\u7528 <code>page_dirty</code> \u8fdb\u884c\u5355\u72ec\u6807\u8bc6\u3002</p> <p><pre><code>typedef enum\n{\n    SLRU_PAGE_EMPTY,            /* buffer is not in use */\n    SLRU_PAGE_READ_IN_PROGRESS, /* page is being read in */\n    SLRU_PAGE_VALID,            /* page is valid and not being written */\n    SLRU_PAGE_WRITE_IN_PROGRESS /* page is being written out */\n} SlruPageStatus;\n</code></pre> \u5173\u4e8e\u4e3a\u4ec0\u4e48\u9700\u8981\u8bb0\u5f55LSN\u4fe1\u606f <code>group_lsn</code>\uff1a\u8fd9\u4e0e <code>WAL</code> \u8bbe\u8ba1\u6709\u5173\u3002\u5bf9\u4e8e <code>WAL</code> \u800c\u8a00\uff0c\u65e0\u8bba\u662f\u540c\u6b65\u63d0\u4ea4\u6216\u662f\u5f02\u6b65\u63d0\u4ea4\uff0c\u90fd\u9700\u8981\u5728\u5bf9\u5e94\u7684 <code>buffer page</code> \u843d\u76d8\u524d\u843d\u76d8,\u6240\u4ee5 <code>slru</code> \u4e5f\u9700\u8981\u6ee1\u8db3\u8fd9\u6837\u7684\u89c4\u5219\u3002\u540c\u65f6\uff0c\u53ef\u80fd\u662f\u4e3a\u4e86\u8282\u7ea6\u5185\u5b58\uff08\u8282\u7ea6\u7684\u5185\u5b58\u5b9e\u5728\u6709\u9650\uff09\uff0c\u6216\u662f\u51cf\u5c11<code>WAL flush</code>\u7684\u8c03\u7528\u6b21\u6570\u4ee5\u589e\u52a0 <code>IO</code> \u6548\u7387\uff0c<code>slru</code>\u7684\u5b9e\u73b0\u4e2d\u5e76\u4e0d\u8bb0\u5f55\u6bcf\u4e2a<code>buffer page</code>\u7684 <code>LSN</code>\uff0c\u800c\u662f\u8bb0\u5f55\u4e00\u7ec4 <code>page</code> \u7684 <code>LSN</code>\uff0c\u5728\u5237\u4e0b\u4e00\u4e2a <code>page</code> \u524d\uff0c\u9700\u8981\u628a\u4e00\u7ec4 <code>page</code> \u4e2d\u6700\u5927\u7684 <code>LSN</code> \u524d\u7684 <code>WAL</code> \u843d\u76d8\u3002\u800c\u8fd9\u6837\u7684\u201c\u4e00\u7ec4\u201d\u7684\u957f\u5ea6\uff0c\u5c31\u4e3a<code>lsn_groups_per_page</code></p>"},{"location":"0013-postgresql/0020-slru/0020-slru/#pointer","title":"\u5404\u4e2a\u8fdb\u7a0b\u79c1\u6709\u7684pointer","text":"<pre><code>/*\n * SlruCtlData is an unshared structure that points to the active information\n * in shared memory.\n */\ntypedef struct SlruCtlData\n{\n    SlruShared  shared;\n\n    /*\n     * Decide whether a page is \"older\" for truncation and as a hint for\n     * evicting pages in LRU order.  \n     */\n    bool        (*PagePrecedes) (int, int);\n\n    /*\n     * Dir is set during SimpleLruInit and does not change thereafter. Since\n     * it's always the same, it doesn't need to be in shared memory.\n     */\n    char        Dir[64];\n} SlruCtlData;\n</code></pre> <p>\u521d\u59cb\u5316\u65f6\uff0c\u5373\u8fd4\u56de\u4e00\u4e2a<code>SlruCtlData</code>\u3002<code>Dir</code> \u662f\u521d\u59cb\u5316\u65f6\u7684\u6807\u8bb0\uff0c\u4e0d\u540c\u6a21\u5757\u4f1a\u586b\u5145\u5bf9\u5e94\u7684\u540d\u79f0\u3002</p>"},{"location":"0013-postgresql/0020-slru/0020-slru/#_3","title":"\u6838\u5fc3\u529f\u80fd","text":"<ol> <li><code>SimpleLruZeroPage</code>\uff1a\u65b0\u589e\u4e00\u4e2apage</li> <li><code>SimpleLruReadPage</code> \uff1a\u8bfb\u4e00\u4e2apage</li> <li><code>SimpleLruWritePage</code> \uff1a\u5199\u4e00\u4e2apage</li> </ol>"},{"location":"0013-postgresql/0020-slru/0020-slru/#_4","title":"\u57fa\u7840\u51fd\u6570","text":"<ul> <li>\u9009\u62e9\u4e00\u4e2a\u7a7aslot</li> </ul> <pre><code>/* Select the slot to re-use when we need a free slot. */\n/* Control lock must be held at entry, and will be held at exit. */\nstatic int\nSlruSelectLRUPage(SlruCtl ctl, int pageno)\n{\n    for (;;)\n        # return if we have such a slot\n        # return if we have an empty slot \"SLRU_PAGE_EMPTY\"\n        # select a lru slot\n            # return it if it's clean. Or\n            # victim it if dirty\n    # loop end -- It's a very clever design to dealing with corner cases\n    #             such as the victim page being re-dirtied while we wrote it.\n}\n</code></pre> <ul> <li>\u8bb0\u5f55\u4e00\u4e2a\"most recently used\"\u7684page\uff0c<code>cur_lru_count++</code> \u5e76\u7528\u5176\u8d4b\u503c </li> </ul> <pre><code>#define SlruRecentlyUsed(shared, slotno)    \\\n    do { \\\n        int     new_lru_count = (shared)-&gt;cur_lru_count; \\\n        if (new_lru_count != (shared)-&gt;page_lru_count[slotno]) { \\\n            (shared)-&gt;cur_lru_count = ++new_lru_count; \\\n            (shared)-&gt;page_lru_count[slotno] = new_lru_count; \\\n        } \\\n    } while (0)\n</code></pre> <ul> <li>\u4ece\u78c1\u76d8\u4e2d\u8bfb\u53d6\u4e00\u4e2a <code>page</code></li> </ul> <pre><code>SlruPhysicalReadPage\n{\n    int segno = pageno / SLRU_PAGES_PER_SEGMENT;\n    SlruFileName(ctl, path, segno);\n\n    /*\n     * In a crash-and-restart situation, it's possible for us to receive\n     * commands to set the commit status of transactions whose bits are in\n     * already-truncated segments of the commit log\n     */\n    fd = OpenTransientFile(path, O_RDONLY | PG_BINARY);\n    if (fd &lt; 0 &amp;&amp; !InRecovery) ereport()\n\n    pg_pread(fd, shared-&gt;page_buffer[slotno], BLCKSZ, offset)\n}\n</code></pre> <ul> <li>\u5411\u78c1\u76d8\u4e2d\u5199\u5165\u4e00\u4e2a <code>page</code></li> </ul> <pre><code>SlruPhysicalWritePage\n{\n    /* We must flush WAL before flush slru pages */\n    if (shared-&gt;group_lsn != NULL)\n    {\n        max_lsn = shared-&gt;group_lsn[lsnindex++];\n        XLogFlush(max_lsn);\n    }\n\n    SlruFileName(ctl, path, segno);\n    fd = OpenTransientFile(path, O_RDWR | O_CREAT | PG_BINARY);\n    pg_pwrite(fd, shared-&gt;page_buffer[slotno], BLCKSZ, offset)\n    /* Queue up a sync request for the checkpointer. */\n    ...\n}\n</code></pre>"},{"location":"0013-postgresql/0020-slru/0020-slru/#interface","title":"interface","text":"<ul> <li> <p>\u65b0\u589e\u4e00\u4e2a <code>page</code> \u5230buffer\u3002 <pre><code>/* Initialize (or reinitialize) a page to zeroes. */\nint\nSimpleLruZeroPage(SlruCtl ctl, int pageno)\n{\n    slotno = SlruSelectLRUPage(ctl, pageno);\n    SlruRecentlyUsed(shared, slotno);\n\n    # SlruSelectLRUPage may return a in-use page, we must clear it\n    MemSet(shared-&gt;page_buffer[slotno], 0, BLCKSZ);\n\n    SimpleLruZeroLSNs(ctl, slotno);\n}\n</code></pre></p> </li> <li> <p>\u4ece <code>disk</code> \u4e2d\u8bfb\u53d6\u4e00\u4e2a <code>page</code> <pre><code>/* Control lock must be held at entry, and will be held at exit. */\nSimpleLruReadPage\n{\n    #infinite loop\n        slotno = SlruSelectLRUPage(ctl, pageno);\n        # for in IO slots, just wait\n        /* update in-memory status */\n        shared-&gt;page_number[slotno] = pageno;\n        shared-&gt;page_status[slotno] = SLRU_PAGE_READ_IN_PROGRESS;\n        shared-&gt;page_dirty[slotno] = false;\n\n        /* Acquire per-buffer lock and release control lock */\n        LWLockAcquire(&amp;shared-&gt;buffer_locks[slotno].lock, LW_EXCLUSIVE);\n        LWLockRelease(shared-&gt;ControlLock);\n\n        ok = SlruPhysicalReadPage(ctl, pageno, slotno);\n\n        /* re-acquire control lock */\n        LWLockAcquire(shared-&gt;ControlLock, LW_EXCLUSIVE);\n        # others\n}\n</code></pre> \u8fd9\u91cc\u7684\u9501\u8bbe\u8ba1\u5f88\u7279\u522b\uff1a</p> </li> <li>\u5728 <code>SlruSelectLRUPage</code> \u9700\u8981\u83b7\u53d6\u5168\u5c40\u9501</li> <li>\u5728 <code>SimpleLruReadPage</code> \u4e2d\uff0c\u5148\u521d\u59cb\u5316\u5185\u5b58\uff0c\u518d\u83b7\u53d6 <code>per-buffer</code> \u9501\uff0c\u540c\u65f6\u91ca\u653e <code>ControlLock</code></li> </ul> <p>\u5728\u770b\u51fd\u6570 <code>SimpleLruZeroPage</code> <pre><code>/* Control lock must be held at entry, and will be held at exit. */\nSimpleLruZeroPage\n{\n    slotno = SlruSelectLRUPage(ctl, pageno);\n    shared-&gt;page_number[slotno] = pageno;\n    shared-&gt;page_status[slotno] = SLRU_PAGE_VALID;\n    shared-&gt;page_dirty[slotno] = true;\n}\n</code></pre> \u96be\u9053\uff0c\u4e00\u65e6\u83b7\u53d6 <code>ControlLock</code>\uff0c\u5373\u53ef\u5bf9\u4efb\u610f <code>slot</code> \u8fdb\u884c\u4fee\u6539\uff1f</p> <p>\u5b9e\u9645\u4e0a\uff0c<code>SimpleLruReadPage</code> \u8bfb\u53d6\u7684 <code>page</code>\uff0c\u5fc5\u987b\u5df2\u5b58\u5728\u4e8e\u78c1\u76d8\uff08\u6216\u8005\u7ecf\u7531 <code>WAL</code> \u6765\u4fdd\u8bc1\uff09\u3002 \u800c <code>SimpleLruZeroPage</code> \u6240\u521d\u59cb\u5316\u7684 <code>page</code> \u5fc5\u987b\u4e0d\u5b58\u5728\u3002\u4ece\u4f7f\u7528\u903b\u8f91\u4e0a\u4fdd\u8bc1\u4e8c\u8005\u4e0d\u4ea7\u751f\u51b2\u7a81\u3002</p> <ul> <li>SimpleLruWritePage(SlruInternalWritePage)</li> </ul> <pre><code>/* Control lock must be held at entry, and will be held at exit. */\nSlruInternalWritePage\n{\n    /* If a write is in progress, wait for it to finish */\n    /* Do nothing if page is not dirty */\n\n    /* update in-memory status */\n    shared-&gt;page_status[slotno] = SLRU_PAGE_WRITE_IN_PROGRESS;\n    shared-&gt;page_dirty[slotno] = false;\n\n    /* Acquire per-buffer lock and release control lock */\n    LWLockAcquire(&amp;shared-&gt;buffer_locks[slotno].lock, LW_EXCLUSIVE);\n    LWLockRelease(shared-&gt;ControlLock);\n\n    SlruPhysicalWritePage(ctl, pageno, slotno, fdata);\n\n    /* re-acquire control lock */\n    LWLockAcquire(shared-&gt;ControlLock, LW_EXCLUSIVE);\n\n    shared-&gt;page_status[slotno] = SLRU_PAGE_VALID;\n}\n</code></pre>"},{"location":"0013-postgresql/0020-slru/0021-clog/","title":"CLOG","text":""},{"location":"0013-postgresql/0020-slru/0021-clog/#overview","title":"Overview","text":"<p>This chapter explains the content of <code>clog</code></p> <p><code>clog</code>(commit log), records the commit status of each transaction. The log exists both in memory mannaged by <code>slru</code> buffer and disk for durability. The commit status can be the four kinds below: <pre><code>#define TRANSACTION_STATUS_IN_PROGRESS      0x00\n#define TRANSACTION_STATUS_COMMITTED        0x01\n#define TRANSACTION_STATUS_ABORTED          0x02\n#define TRANSACTION_STATUS_SUB_COMMITTED    0x03\n</code></pre></p>"},{"location":"0013-postgresql/0020-slru/0021-clog/#in-disk-representation","title":"In-Disk Representation","text":"<p>Thinking that the commit status of each transaction composites an array <code>clog[]</code> and <code>clog[xid]</code> records the status, we can easily store the array to disk by the <code>slru</code>.</p> <p>The status of one transaction needs two bits to represent: <pre><code>#define CLOG_BITS_PER_XACT  2\n#define CLOG_XACTS_PER_BYTE 4\n#define CLOG_XACTS_PER_PAGE (BLCKSZ * CLOG_XACTS_PER_BYTE)\n#define CLOG_XACT_BITMASK   ((1 &lt;&lt; CLOG_BITS_PER_XACT) - 1)\n</code></pre></p> <p>So we can get the xid's index and offset in page and byte. <pre><code>#define TransactionIdToPage(xid)    ((xid) / (TransactionId) CLOG_XACTS_PER_PAGE)\n#define TransactionIdToPgIndex(xid) ((xid) % (TransactionId) CLOG_XACTS_PER_PAGE)\n#define TransactionIdToByte(xid)    (TransactionIdToPgIndex(xid) / CLOG_XACTS_PER_BYTE)\n#define TransactionIdToBIndex(xid)  ((xid) % (TransactionId) CLOG_XACTS_PER_BYTE)\n</code></pre></p> <p>Thinking of that one slru segment contains 32 pages, so we name the clog file as <code>0000</code>(contains xid in [0, 32 * CLOG_XACTS_PER_PAGE - 1]), <code>0001</code>(contains xid in [32 * CLOG_XACTS_PER_PAGE, 32 * CLOG_XACTS_PER_PAGE * 2 - 1]) and so on. Because four hex numbers can represent \\(16^4=2^{12}\\) files with \\(2^{12} \\times 32 \\times 8192 \\times 4 = 2^{32}\\) transactions' status(a int32 size)</p> <p>Attension, such simple mapping means that the pages in clog file don't have page headers. So we can't record <code>LSN</code>, <code>checksum</code> in each page. The lack of <code>LSN</code> means the changes of clog page wouldn't be recorded in <code>WAL</code> but clog doesn't need it indeed.</p>"},{"location":"0013-postgresql/0020-slru/0021-clog/#extend-and-truncate","title":"Extend And Truncate","text":"<p>During the process of generating a new <code>xid</code>, we make sure that the slru page exists. * If it's the first xid of the page, we allocate a new page in clog buffer.   * Also generate a WAL to record the birth of the page. * If not, the page must exist in memory or flushed into disk. So it's for slru   layer to manage such situation.</p> <p>Keep in mind that the general self-increment xid does't begin at zero: <pre><code>#define FirstNormalTransactionId    ((TransactionId) 3)\n</code></pre> so: * During bootstrap, initialize the first clog page * During extend new pages, be careful about the <code>FirstNormalTransactionId</code>,   since it is not the first xid in page representation but the first general one.</p> <p>The above behaviors indicate that although a clog segment at most occupies 256K space, it doesn't have such size just after initialization. We extend 8K pages one by one during the xid increment.</p> <p>Since at most half of <code>uint32</code> xids can be in use, it's natural to clean up out of date clog files. Different from extending a page, we always delete a whole page. So once we promote the <code>frozenxid</code>, we try to find some clog files to delete: 1. The judgement whether there is a file can be deleted is completed in slru    layer(a loop to scan the directory), but clog layer supports a hook to judge    one file. 2. Advance the oldest clog xid in shared memory 3. Generate a clog truncate WAL record 4. Real truncate. Complemented in slru layer.</p> <p>Details of the two kind WAL record will be shown later.</p>"},{"location":"0013-postgresql/0020-slru/0021-clog/#set-and-get","title":"Set And Get","text":"<p>Concerned with subtransactions ...</p> <p>I can't totally figure out the commit tree without knowing the mechanism of subtransaction. Just assuming subxids as a set of xids related to the main xid seems not convictive enough for me. So I remain it here now and will finish it after reading subtransactions)</p> <p>For now, it's enough to knowing that 1. The pair of operations wouldn't generate any WAL record 2. They are done during the commit or abort procedure.</p>"},{"location":"0013-postgresql/0020-slru/0021-clog/#record-changes-in-wal","title":"Record changes in WAL","text":"<p>Recall what mentioned above: * Extending a new page and delete a segment will generata a WAL record. * Setting commit status wouldn't</p> <p>For the latter one, it's unbelievable but tricky. Since only the transactions that changes the content data(some hint flags are exception, such as tuple infomask) will have a xid(and then record on clog segment). During the replay of such transactions' commit(or abort) WAL record, we can redo the clog by the way.</p> <p>For the former one, it's a matter of course, since we must guarantee the clog to be recovery-safe. But some details deserve a glance; * For extending a new page, it makes no difference that we flush the WAL record   now or later. Since once we want to set status in a non-existent page during   recovery, we can padding a new empty page. This trick doesn't affect the page   usage. * For deleting a clog segment, we have no chance to remedy the lost of clogs,   and the disaster means a lot of tuple can be accessed at all. So regardless of   the synchronous commit level, we must ensure the WAL record has flushed into   disk before really delete the segments.</p>"},{"location":"0013-postgresql/0022-wal/0022-wal-basic/","title":"WAL\u57fa\u7840","text":"<p>From <code>access/transam/README</code></p>"},{"location":"0013-postgresql/0022-wal/0022-wal-basic/#write-ahead-log-coding","title":"Write-Ahead Log Coding","text":"<p>\u57fa\u672c\u601d\u60f3\uff0c\u65e5\u5fd7\u5728\u6570\u636e\u9875\u524d\u843d\u76d8</p> <ol> <li><code>LSN</code>\uff1a\u5237\u810f\u524d\u68c0\u67e5<code>LSN</code>\u5bf9\u5e94\u7684\u65e5\u5fd7\u5df2\u7ecf\u843d\u76d8<ol> <li>\u4f18\u52bf\uff1a\u4ec5\u5728\u5fc5\u8981\u7684\u65f6\u5019\u7b49\u5f85<code>XLOG</code>\u7684<code>IO</code>\u3002\uff08\u5f02\u6b65<code>IO</code>\uff09</li> <li><code>LSN</code>\u7684\u68c0\u67e5\u6a21\u5757\u53ea\u7528\u5728 buffer manager \u4e2d\u5b9e\u73b0</li> <li>\u5728WAL\u56de\u653e\u65f6\uff0c\u907f\u514d\u76f8\u540c\u7684\u65e5\u5fd7\u88ab\u91cd\u590d\u56de\u653e\uff08\u53ef\u91cd\u5165\uff09\u3002\uff08TODO\uff1afull page write\u662f\u5426\u5728\u53e6\u4e00\u4e2a\u5c42\u9762\u4e0a\u4fdd\u8bc1\u4e86\u53ef\u91cd\u5165\uff09</li> </ol> </li> <li>WAL \u5305\u542b\u4e00\u4e2a\uff08\u6216\u4e00\u5c0f\u7ec4\uff09\u9875\u7684\u589e\u91cf\u66f4\u65b0\u7684\u91cd\u505a\u4fe1\u606f\u3002<ol> <li>\u4f9d\u8d56\u6587\u4ef6\u7cfb\u7edf\u548c\u786c\u4ef6\u7684\u539f\u5b50\u5199\uff0c\u4e0d\u53ef\u9760\uff01</li> <li>checkpoint\uff0ccheckpointer\u540e\u7684\u7b2c\u4e00\u6b21\u5199\u5168\u9875\u3002\u901a\u8fc7 checkpoint \u7559\u4e0b\u7684 <code>LSN</code> \u6765\u5224\u65ad\u662f\u5426\u4e3a\u7b2c\u4e00\u6b21\u5199</li> </ol> </li> <li>\u5199\u4e0bWAL\u65e5\u5fd7\u7684\u903b\u8f91\u4e3a<ol> <li>pin and exclusive-lock the shared buffer </li> <li>START_CRIT_SECTION\uff0c\u53d1\u751f\u9519\u8bef\u65f6\u786e\u4fdd\u6574\u4e2a\u6570\u636e\u5e93\u80fd\u7acb\u5373\u91cd\u542f</li> <li>\u5728shared buffer\u4e0a\uff0c\u8fdb\u884c\u5bf9\u5e94\u7684\u4fee\u6539</li> <li>\u6807\u8bb0\u4e3a\u810f\u9875\uff0c<ol> <li>\u5fc5\u987b\u5728WAL\u65e5\u5fd7\u5199\u5165\u524d\u5b8c\u6210\uff08TODO\uff0c\u4e3a\u4ec0\u4e48\uff1f<code>SyncOneBuffer</code>\uff09</li> <li>\u53ea\u6709\u5728\u8981\u5199WAL\u65f6\uff0c\u624d\u80fd\u6807\u8bb0\u810f\u9875\uff08TODO\uff0c\u4e3a\u4ec0\u4e48\uff1f\uff09</li> </ol> </li> <li>\u4f7f\u7528<code>XLogBeginInsert</code> \u548c <code>XLogRegister*</code> \u51fd\u6570\u6784\u5efaWAL\uff0c\u4f7f\u7528\u8fd4\u56de\u7684<code>LSN</code>\u6765\u66f4\u65b0<code>page</code></li> <li>END_CRIT_SECTION\uff0c\u9000\u51fa</li> <li>\u89e3\u9501\u548cunpin \uff08\u6ce8\u610f\u987a\u5e8f\uff09</li> </ol> </li> </ol> <p>\u4e00\u4e9b\u590d\u6742\u7684\u64cd\u4f5c\uff0c\u9700\u8981\u539f\u5b50\u5730\u5199\u4e0b\u4e00\u4e32WAL\u8bb0\u5f55\uff0c\u4f46\u4e2d\u95f4\u72b6\u6001\u5fc5\u987b\u81ea\u6d3d(self-consistent)\u3002\u8fd9\u6837\u5728\u56de\u653ewal\u65e5\u5fd7\u65f6\uff0c\u5982\u679c\u4e2d\u65ad\uff0c\u7cfb\u7edf\u8fd8\u80fd\u591f\u6b63\u5e38\u8fd0\u884c\u3002\u6ce8\u610f\uff1a\u6b64\u65f6\u76f8\u5f53\u4e8e\u4e8b\u52a1\u56de\u6eda\uff0c\u4f46\u662f\u5176\u90e8\u5206\u66f4\u6539\u5df2\u7ecf\u843d\u76d8\u3002\u4e3e\u4f8b\uff1a * \u5728btree\u7d22\u5f15\u4e2d\uff0c\u9875\u7684\u5206\u88c2\u5206\u4e3a\u4e24\u6b65\uff081\uff09\u5206\u914d\u4e00\u4e2a\u65b0\u9875\uff082\uff09\u5728\u4e0a\u4e00\u5c42\u7684\u9875(parent page)\u4e2d\u65b0\u63d2\u5165\u4e00\u6761\u6570\u636e\u3002 * \u4f46\u662f\u56e0\u4e3a\u9501\uff0c\u8fd9\u4f1a\u5f62\u6210\u4e24\u4e2a\u72ec\u7acb\u7684WAL\u65e5\u5fd7\u3002\u5728\u56de\u653eWAL\u65e5\u5fd7\u65f6     * \u56de\u653e\u7b2c\uff081\uff09\u4e2a\u65e5\u5fd7\uff1a         * \u5206\u914d\u4e00\u4e2a\u65b0\u9875\uff0c\u5c06\u5143\u7ec4\u79fb\u52a8\u8fdb\u53bb         * \u8bbe\u7f6e\u6807\u8bb0\u4f4d\uff0c\u8868\u793a\u4e0a\u4e00\u5c42\u7684\u9875\u6ca1\u6709\u66f4\u65b0     * \u56de\u653e\u7b2c\uff082\uff09\u4e2a\u65e5\u5fd7\uff1a         * \u5728\u4e0a\u4e00\u5c42\u7684\u9875\u4e2d\u65b0\u63d2\u5165\u4e00\u6761\u6570\u636e         * \u6e05\u9664\u7b2c\uff081\uff09\u4e2a\u65e5\u5fd7\u4e2d\u7684\u6807\u8bb0\u4f4d * \u6807\u5fd7\u4f4d\u901a\u5e38\u60c5\u51b5\u4e0b\u4e0d\u53ef\u89c1\uff0c\u56e0\u4e3a\u5bf9 child page \u7684\u4fee\u6539\u65f6\u6301\u6709\u7684\u9501\uff0c\u5728\u4e24\u4e2a\u64cd\u4f5c\u5b8c\u6210\u540e\u624d\u4f1a\u91ca\u653e\u3002 * \u4ec5\u5728\u5199\u4e0b\u7b2c\uff082\uff09\u4e2a\u65e5\u5fd7\u524d\uff0c\u6570\u636e\u5e93\u6070\u597d\u5d29\u6e83\uff0c\u6807\u5fd7\u4f4d\u624d\u4f1a\u88ab\u611f\u77e5\u3002\uff08\u8be5\u6807\u5fd7\u4f4d\u5e94\u8be5\u6ca1\u6709MVCC\uff0c\u5426\u5219\u4f1a\u5728\u4e8b\u52a1\u5c42\u5c4f\u853d\uff09     * \u641c\u7d22\u65f6\uff0c\u4e0d\u7ba1\u8fd9\u4e2a\u4e2d\u95f4\u72b6\u6001     * \u63d2\u5165\u65f6\uff0c\u5982\u679c\u53d1\u73b0\u8fd9\u4e2a\u4e2d\u95f4\u72b6\u6001\uff0c\u5148\u5728\u4e0a\u4e00\u5c42\u7684\u9875\u63d2\u5165\u5bf9\u5e94key\uff0c\u4ee5\u4fee\u590d\u8fd9\u4e2a\u201c\u5d29\u6e83\u201d\u72b6\u6001\uff0c\u518d\u7ee7\u7eed\u63d2\u5165</p>"},{"location":"0013-postgresql/0022-wal/0023-wal-insert/","title":"WAL\u65e5\u5fd7\u7684\u63d2\u5165","text":""},{"location":"0013-postgresql/0022-wal/0023-wal-insert/#_1","title":"\u63a5\u53e3\u51fd\u6570","text":"<p>\u4e00\u4e2aWAL\u8bb0\u5f55\u5305\u542b 1. WAL\u8bb0\u5f55\u7c7b\u578b\u3002\uff08TODO\u4e0d\u540c\u7684\u4fee\u6539\u6709\u4e0d\u540c\u7684\u8bb0\u5f55\u65b9\u5f0f\uff1f\uff09 2. \u8fd9\u4e2a\u9875\u7684\u4fee\u6539\u65b9\u5f0f 3. \u88ab\u4fee\u6539\u7684\u9875\u7684\u4fe1\u606f\u3002\u88ab\u4fee\u6539\u7684\u9875\u901a\u8fc7\u4e00\u4e2a\u552f\u4e00ID\u6807\u8bc6\uff0c\u4e5f\u53ef\u4ee5\u6709\u66f4\u591a\u7684\u5173\u8054\u6570\u636e\uff08\"record-specific data associated with the block\"\uff09\u3002\u5982\u679c\u8981\u5199full page\uff0c\u5c31\u6ca1\u6709\u5173\u8054\u6570\u636e</p>"},{"location":"0013-postgresql/0022-wal/0023-wal-insert/#wal5","title":"\u6784\u5efa\u4e00\u4e2aWAL\u8bb0\u5f55\u5305\u542b5\u4e2a\u6838\u5fc3\u51fd\u6570","text":"<ul> <li><code>void XLogBeginInsert(void)</code><ul> <li>\u521d\u59cb\u5316\u76f8\u5173\u72b6\u6001</li> <li>\u5982\u679c\u5f53\u524d\u65e0\u6cd5\u6784\u5efaWAL\u65e5\u5fd7\uff08\u4f8b\u5982\u5728recovery\u6a21\u5f0f\uff09\uff0c\u5219\u62a5\u9519</li> </ul> </li> <li><code>void XLogRegisterBuffer(uint8 block_id, Buffer buf, uint8 flags);</code><ul> <li>\u589e\u52a0\u4e86\u6570\u636e\u5757\u7684\u4fe1\u606f\uff1b\u6ce8\u518c\u4e00\u4e2abuffer\u7684\u5f15\u7528\uff0c\u76f8\u5f53\u4e8e\u4e0a\u8ff0WAL\u65e5\u5fd7\u7684\u7b2c\u4e09\u90e8\u5206</li> <li> <p>block_id is an arbitrary number used to identify this page reference in the redo routine</p> </li> <li>\u5728redo\u9636\u6bb5\uff0c\u53ef\u4ee5\u6839\u636e\u8fd9\u4e9b\u4fe1\u606f\u627e\u5230\u9700\u8981redo\u7684page <pre><code>    regbuf = &amp;registered_buffers[block_id];\n    /*\n     * Returns the relfilenode, fork number and block number associated with\n     * a buffer\n     */\n    BufferGetTag(buffer, &amp;regbuf-&gt;rnode, &amp;regbuf-&gt;forkno, &amp;regbuf-&gt;block);\n    regbuf-&gt;page = BufferGetPage(buffer);\n    regbuf-&gt;flags = flags;\n    regbuf-&gt;rdata_tail = (XLogRecData *) &amp;regbuf-&gt;rdata_head;\n    regbuf-&gt;rdata_len = 0;\n</code></pre></li> </ul> </li> </ul> <p>registered_buffer\u7684\u7ed3\u6784 <pre><code>typedef struct\n{\n    /* xxx */\n\n    /* info to re-find the page */\n    ForkNumber  forkno;\n    BlockNumber block;\n    Page        page;\n\n    /* a loop-linked structure to store the data change of each buffer */\n    uint32       rdata_len;      /* total length of data in rdata chain */\n    XLogRecData *rdata_head;    /* head of the chain of data registered with\n                                * this block */\n    XLogRecData *rdata_tail;    /* last entry in the chain, or &amp;rdata_head if\n                                 * empty */\n\n    /* xxx */\n\n} registered_buffer;\n\ntypedef struct XLogRecData\n{\n    struct XLogRecData *next;   /* next struct in chain, or NULL */\n    char       *data;           /* start of rmgr data to include */\n    uint32      len;            /* length of rmgr data to include */\n} XLogRecData;\n</code></pre> * <code>void XLogRegisterData(char *data, int len);</code>     * \u5411WAL\u65e5\u5fd7\u4e2d\u5199\u5165\u4efb\u610f\u6570\u636e     * \u53ef\u591a\u6b21\u8c03\u7528\uff0c\u4fdd\u8bc1\u8fde\u7eed\u3002\u8fd9\u6837\u5728rodo\u65f6\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u8fde\u7eed\u7684\u6570\u636e <pre><code>    rdata = &amp;rdatas[num_rdatas++];\n    rdata-&gt;data = data;\n    rdata-&gt;len = len;\n</code></pre> * <code>void XLogRegisterBufData(uint8 block_id, char *data, int len);</code> <pre><code>    rdata = &amp;rdatas[num_rdatas++];\n    rdata-&gt;data = data;\n    rdata-&gt;len = len;\n\n    regbuf = &amp;registered_buffers[block_id];\n    regbuf-&gt;rdata_tail-&gt;next = rdata;\n    regbuf-&gt;rdata_tail = rdata;\n    regbuf-&gt;rdata_len += len;\n</code></pre> \u53ef\u89c1\uff0c<code>XLogRegisterBufData</code> \u548c <code>XLogRegisterData</code> \u7684\u6838\u5fc3\u533a\u522b\u5728\uff0c\u524d\u8005\u5199\u5165\u7684\u6570\u636e\u4f1a\u5173\u8054\u5230\u5177\u4f53\u7684buffer\uff0c\u800c\u540e\u8005\u6ca1\u6709 * <code>XLogInsert</code>   * Insert the record. <pre><code>    do\n    {\n        GetFullPageWriteInfo(&amp;RedoRecPtr, &amp;doPageWrites);\n        rdt = XLogRecordAssemble(rmid, info, RedoRecPtr, doPageWrites,\n                                 &amp;fpw_lsn, &amp;num_fpi);\n\n        EndPos = XLogInsertRecord(rdt, fpw_lsn, curinsert_flags, num_fpi);\n    } while (EndPos == InvalidXLogRecPtr);\n</code></pre></p>"},{"location":"0013-postgresql/0022-wal/0023-wal-insert/#_2","title":"\u6570\u636e\u7ed3\u6784\u6c47\u603b","text":""},{"location":"0013-postgresql/0022-wal/0023-wal-insert/#registered_buffers","title":"registered_buffers","text":"<p>\u6bcf\u4e00\u4e2abuffer\u5bf9\u5e94registered_buffers\u4e2d\u7684\u4e00\u4e2a\u5143\u7d20\uff08\u4e00\u4e2a<code>registered buffer</code>\uff09 <pre><code>void\nXLogEnsureRecordSpace(int max_block_id, int ndatas)\n{\n    if (nbuffers &gt; max_registered_buffers)\n    {\n        registered_buffers = (registered_buffer *)\n            repalloc(registered_buffers, sizeof(registered_buffer) * nbuffers);\n        max_registered_buffers = nbuffers;\n    }\n}\n</code></pre></p>"},{"location":"0013-postgresql/0022-wal/0023-wal-insert/#_3","title":"\u5177\u4f53\u7684\u63d2\u5165\u65b9\u5f0f","text":"<p>\u4e0a\u8ff0\u4ee3\u7801\u4e2d\u7684<code>XLogRecordAssemble</code>\u548c<code>XLogInsertRecord</code>\u5df2\u7ecf\u6982\u62ec\u4e86\u5177\u4f53\u7684\u63d2\u5165\u6b65\u9aa4</p>"},{"location":"0013-postgresql/0022-wal/0023-wal-insert/#xlogrecordassemble","title":"XLogRecordAssemble","text":"<p>Assemble a WAL record from the registered data and buffers into an XLogRecData chain <pre><code>static XLogRecData *\nXLogRecordAssemble(RmgrId rmid, uint8 info,\n                   XLogRecPtr RedoRecPtr, bool doPageWrites,\n                   XLogRecPtr *fpw_lsn, int *num_fpi)\n{\n    for (block_id = 0; block_id &lt; max_registered_block_id; block_id++)\n    {\n        if (needs_data)\n        {\n            rdt_datas_last-&gt;next = regbuf-&gt;rdata_head;\n        }\n    }\n}\n</code></pre></p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/","title":"1 \u6982\u8ff0","text":"<p>\u672c\u6587\u4ecb\u7ecd PostgreSQL \u4e2d Heap Only Tuple(HOT) \u6280\u672f\u4ee5\u53ca\u521b\u5efa\u7d22\u5f15\u76f8\u5173\u7684\u77e5\u8bc6\uff0c\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a 1. HOT \u7684\u57fa\u672c\u539f\u7406 2. \u666e\u901a\u7684\u521b\u5efa\u7d22\u5f15 (Create Index) \u6d41\u7a0b 3. \u540c\u65f6\u521b\u5efa\u7d22\u5f15 (Create Index Concurrently CIC) \u7684\u539f\u7406</p> <p>\u672c\u6587\u4e0d\u5305\u62ec\uff1a 1. btree \u7b49\u7d22\u5f15\u7684\u5177\u4f53\u5b9e\u73b0\u65b9\u5f0f 2. PostgreSQL \u5bf9\u7d22\u5f15\u8bbf\u95ee\u65b9\u5f0f (Access Method) \u7684\u62bd\u8c61</p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#2-hot","title":"2 HOT \u57fa\u7840","text":"<p>\u7b80\u5355\u800c\u8a00, HOT(Heap Only Tuple) \u6307\u6ca1\u6709\u7d22\u5f15\u6307\u5411\u7684\u5143\u7ec4\uff0c\u7528\u4e8e\u6d88\u9664\u5143\u7ec4\u66f4\u65b0\u5f15\u8d77\u7684\u7d22\u5f15\u81a8\u80c0\uff0c\u539f\u7406\u5982\u4e0b\u56fe\uff1a</p> <p></p> <ol> <li>\u5143\u7ec4\u6307\u5411\u53e6\u4e00\u4e2a\u5143\u7ec4\uff1a\u7d22\u5f15\u6307\u5411 line_ptr_1 \uff0cline_ptr_1 \u6307\u5411 tuple_1 \uff0ctuple_1 \u88ab\u66f4\u65b0\u540e\u6210\u4e3a tuple_2\uff0c\u6b64\u65f6 tuple_1 \u6307\u5411 tuple_2\uff0c\u800c\u7d22\u5f15\u6307\u5411\u7684 line pointer \u6ca1\u6709\u53d1\u751f\u53d8\u5316\u3002 </li> <li>line pointer \u4e5f\u53ef\u4ee5\u6307\u5411\u53e6\u4e00\u4e2a line pointer\uff1a\u7d22\u5f15\u6307\u5411 line_ptr_3 , line_ptr_3 \u6307\u5411 line_ptr_4 \uff0cline_ptr_4 \u6307\u5411 tuple3</li> </ol> <p>\u663e\u7136\uff0cHOT \u6280\u672f\u5177\u6709\u5982\u4e0b\u4f18\u70b9</p> <ol> <li>\u5bf9\u4e8e\u88ab\u66f4\u65b0\u7684\u5143\u7ec4\uff0c\u65e0\u9700\u521b\u5efa\u65b0\u7684\u7d22\u5f15\u6307\u9488\u6307\u5411\u65b0\u5143\u7ec4</li> <li>\u65e7\u5143\u7ec4\u53ef\u4ee5\u88ab\u201c\u666e\u901a\u64cd\u4f5c\u201d\u5220\u9664\u6389\uff0c\u5e76\u4e0d\u4e00\u5b9a\u9700\u8981 vacuum \uff08\u76f8\u5f53 vacuum \u7684\u5de5\u4f5c\u88ab\u5206\u7ed9\u4e86\u666e\u901a\u7684 dml \uff09</li> </ol> <p>\u540c\u65f6\uff0c\u89e6\u53d1 HOT \u94fe\u4e5f\u9700\u8981\u4e25\u683c\u7684\u9650\u5236\uff1a</p> <ol> <li>\u8be5\u66f4\u65b0\u4e0d\u4f1a\u4fee\u6539\u8868\u7684\u7d22\u5f15\u6240\u5f15\u7528\u7684\u4efb\u4f55\u5217\uff0c\u4e0d\u5305\u62ec\u6c47\u603b\u7d22\u5f15</li> <li>\u5305\u542b\u65e7\u884c\u7684\u9875\u9762\u6709\u8db3\u591f\u7684\u7a7a\u95f2\u7a7a\u95f4\u7528\u4e8e\u5b58\u653e\u66f4\u65b0\u540e\u7684\u884c\uff0c\u5373\uff0cHOT \u94fe\u4e0d\u80fd\u8de8 page</li> </ol>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#2-1-hot","title":"2-1 HOT \u94fe\u7684\u6784\u5efa","text":"<p>\uff08\u4e00\uff09\uff1a\u8868 tbl(x int, y int) \u5728 x \u4e0a\u6709\u7d22\u5f15\uff0c\u5148\u63d2\u5165\u4e00\u884c  tuple_1=(x=1, y=1) \uff0c\u7ed3\u679c\u5982\u4e0b</p> <p></p> <p>\uff08\u4e8c\uff09\uff1a\u5f53\u66f4\u65b0 tuple_1 \u4e3a (x=1,y=2) \u65f6\uff0c \u65b0\u589e lp_2, \u548c tuple_2 \uff0c\u4f46\u662f\u4e0d\u4f1a\u65b0\u589e\u7d22\u5f15\u6307\u9488\uff0c\u800c\u662f\u7531 tuple_1 \u7684 header \u4f1a\u8bb0\u5f55 tuple_2 \u7684\u4f4d\u7f6e\u3002</p> <p></p> <p>\u4ece\u53ef\u89c1\u6027\u7684\u89d2\u5ea6\u601d\u8003\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u5feb\u7167\u800c\u8a00\uff0c\u4e00\u4e2a HOT \u94fe\u4e0a\u6700\u591a\u53ea\u6709\u4e00\u4e2a tuple \u53ef\u89c1\u3002</p> <p>\u6240\u4ee5\u4f7f\u7528\u7d22\u5f15\u626b\u63cf\u65f6\uff0c\u4f1a\u5148\u627e\u5230 tuple_1 \u5224\u65ad tuple_ 1 \u662f\u5426\u7b26\u5408\u53ef\u89c1\u6027\uff1a</p> <ol> <li>\u5982\u679c tuple_1 \u53ef\u89c1\uff0c\u90a3\u4e48\u7acb\u5373\u8fd4\u56de\uff0c\u4e0d\u5728\u5411\u4e0b\u641c\u7d22\u3002</li> <li>\u5982\u679c tuple_1 \u4e0d\u53ef\u89c1\uff0c\u518d\u7ee7\u7eed\u5411\u4e0b\u641c\u7d20\u3002</li> </ol> <p>\uff08\u4e09\uff09\uff1a\u518d\u66f4\u65b0 tuple_1 \u4e3a tuple3=(x=1, y=3)\uff0c\u7ed3\u679c\u5982\u4e0b</p> <p></p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#2-2","title":"2-2 \u6e05\u7406","text":"<p>\u663e\u7136\u5982\u679c\u4e00\u4e2atuple\u4e00\u76f4\u88ab\u66f4\u65b0\uff0c\u90a3\u4e48\u5176 HOT \u94fe\u4f1a\u5f88\u957f\uff0c\u5f71\u54cd\u7d22\u5f15\u641c\u7d22\u7684\u6027\u80fd\uff0c\u6240\u4ee5\u9700\u8981\u53bb\u6e05\u7406 HOT \u94fe\uff0c\u6e05\u7406\u5206\u4e3a\u4e24\u6b65\uff0c\u4e00\u4e2a\u662f pruning \uff08\u4fee\u526a\uff09\uff0c\u53e6\u4e00\u4e2a\u662f defragmentation \uff08\u788e\u7247\u6574\u7406\uff09</p> <p>\uff08\u56db\uff09\uff1apruning \uff08\u4fee\u526a\uff09\uff1a\u7b49 tuple_1 \u548c tuple_2 \u591a\u6240\u6709\u4e8b\u52a1\u90fd\u4e0d\u53ef\u89c1\u65f6\uff0c\u5219\u901a\u8fc7\u4fee\u6539 line pointers\uff0c\u51cf\u5c11 hot \u94fe\u7684\u957f\u5ea6\u3002 line pointer 2 \u53ef\u4ee5\u88ab\u5176\u4ed6\u64cd\u4f5c\u590d\u7528\uff0c\u4f46\u662f tuple_1 \u548c tuple_2 \u5360\u7528\u7684\u7a7a\u95f4\u4ecd\u6ca1\u6709\u88ab\u6e05\u7406\u3002\u5982\u56fe\uff1a</p> <p></p> <p>\uff08\u4e94\uff09\uff1adefragmentation \uff08\u788e\u7247\u6574\u7406\uff09\uff1a\u5c06\u5bf9\u5e94\u7684 tuple \u5f7b\u5e95\u5220\u9664\uff0c\u5982\u56fe</p> <p></p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#3-create-index","title":"3 Create Index \u7684\u6d41\u7a0b","text":"<p>\u8be5\u7ae0\u8282\u4ecb\u7ecd\u666e\u901a\u7684\u521b\u5efa\u7d22\u5f15\u7684\u5927\u81f4\u8fc7\u7a0b\uff0c\u5c24\u5176\u662f\u7f13\u5b58\u4e00\u81f4\u6027\u548c\u5bf9 HOT \u7684\u7279\u6b8a\u5904\u7406</p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#3-1","title":"3-1 \u51c6\u5907\u6b65\u9aa4","text":"<ol> <li>\u6743\u9650\u6821\u9a8c\uff1a\u5305\u62ec</li> <li>\u9009\u62e9\u7d22\u5f15\u540d\uff0c access method \uff08\u4e3b\u8981\u662f\u786e\u8ba4 access method \u662f\u5426\u5b58\u5728\uff09</li> <li>\u52a0\u9501\uff1ashared lock\uff0c\u963b\u6b62\u5199\u5165</li> </ol>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#3-2","title":"3-2 \u521b\u5efa\u7a7a\u7d22\u5f15","text":"<ol> <li>\u521b\u5efa heap <code>heap_create</code></li> <li>build relcache</li> <li>\u521b\u5efa\u6587\u4ef6 <code>smgrcreate</code></li> <li>\u8bb0\u5f55\u4f9d\u8d56</li> <li>\u5411 <code>pg_class</code> , <code>pg_index</code> , <code>pg_attribute</code>  \u4e2d\u5199\u5165\u5bf9\u5e94\u7684\u8bb0\u5f55</li> <li>\u6ce8\u518c\u5bf9\u5e94\u8868\u7684\u7f13\u5b58\u65e0\u6548\u4fe1\u606f\uff0c\u4ee5\u4fbf\u5728\u4e8b\u52a1\u7ed3\u675f\u65f6\u53d1\u9001 <code>CacheInvalidateRelcache</code></li> </ol>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#3-3-index-access-method","title":"3-3 \u8c03\u7528\u5bf9\u5e94\u7684 index access method \u521b\u5efa\u7d22\u5f15","text":"<p>\u8fd9\u91cc\u548c HOT \u5173\u7cfb\u8f83\u5927\uff0c\u9700\u8981\u7b80\u5355\u5c55\u5f00\uff1a</p> <p>\u5728 index access method \u5185\u90e8\uff0c\u4f1a\u4f7f\u7528\u56de\u8c03\u51fd\u6570 <code>heapam_index_build_range_scan</code> \u6765\u626b\u63cf heap\uff0c\u4ee5\u786e\u5b9a\u6709\u54ea\u4e9b tuple \u9700\u8981\u52a0\u5165\u5230\u7d22\u5f15\u4e2d\uff1a</p> <ol> <li>\u8be5\u626b\u63cf\u4f7f\u7528\u7684\u5feb\u7167\u4e3a <code>SnapshotAny</code> \uff0c\u5373\u6240\u6709\u5143\u7ec4\u90fd\u9700\u8981\u88ab\u5904\u7406\u3002</li> <li>\u6bcf\u5f53\u626b\u63cf\u5230\u4e00\u4e2a\u5143\u7ec4\u65f6\uff0c\u9700\u8981\u50cf <code>vacuum</code> \u4e00\u6837\u5224\u65ad\u8be5\u5143\u7ec4\u7684\u72b6\u6001\uff0c\u5305\u62ec\uff1a</li> <li>\u5bf9\u6240\u6709\u4e8b\u52a1\u90fd\u4e0d\u53ef\u89c1 (<code>HEAPTUPLE_DEAD</code>) \uff0c\u90a3\u4e48\u663e\u7136\u4e0d\u9700\u8981\u5bf9\u4ed6\u521b\u5efa\u7d22\u5f15</li> <li>\u5982\u679c\u6240\u6709\u4e8b\u52a1\u90fd\u53ef\u89c1 (<code>HEAPTUPLE_LIVE</code>)\uff0c\u90a3\u4e48\u663e\u7136\u9700\u8981\u5bf9\u4ed6\u521b\u5efa\u7d22\u5f15</li> <li>\u5982\u679c\u4e00\u4e9b\u4e8b\u52a1\u53ef\u89c1\uff1a<ol> <li>(<code>HEAPTUPLE_RECENTLY_DEAD</code>) \uff0c\u6700\u8fd1\u88ab\u5220\u9664\uff0c\u4f46\u662f\u6709\u4e9b\u4e8b\u52a1\u4ecd\u7136\u53ef\u4ee5\u770b\u5230 \uff08\u91cd\u70b9\u5904\u7406\uff09\uff1a</li> <li>(<code>INSERT_IN_PROGRESS</code>) \u548c (<code>DELETE_IN_PROGRESS</code>) \uff0c\u6b63\u5728\u88ab\u63d2\u5165\u3001\u5220\u9664 \uff1a\u8003\u8651\u5230\u5927\u90e8\u5206\u60c5\u51b5\u4e0b <code>create index</code> \u8bed\u53e5\u4e0d\u4f1a\u5728\u4e8b\u52a1\u5757\u4e2d\u6267\u884c\uff0c\u8fd9\u91cc\u8df3\u8fc7\u3002</li> </ol> </li> </ol>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#3-3-1-heaptuple_recently_dead","title":"3-3-1 \u5982\u4f55\u5904\u7406 <code>HEAPTUPLE_RECENTLY_DEAD</code>","text":""},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#3-3-1-1-hot","title":"3-3-1-1 \u975e HOT","text":"<p>\u8bf4\u660e\u8be5 tuple \u88ab\u5220\u9664\u4e86\uff0c\u4f46\u662f\u6709\u4e00\u4e9b\u4e8b\u52a1\u4ecd\u7136\u5bf9\u5176\u53ef\u89c1\uff0c\u90a3\u4e48\u4e5f\u9700\u8981\u52a0\u5165\u5230\u7d22\u5f15\u4e2d\u3002\u5426\u5219\u8fd9\u4e9b\u4e8b\u52a1\u540e\u7eed\u901a\u8fc7\u5f53\u524d\u521b\u5efa\u7684\u7d22\u5f15\u5c31\u65e0\u6cd5\u627e\u5230\u8be5\u5143\u7ec4\u3002</p> <p></p> <p>\u6ce8\u610f\uff1a\u5728\u5224\u65ad\u4e00\u4e2a\u8868\u6709\u54ea\u4e9b\u7d22\u5f15\u65f6\uff0c\u4f7f\u7528\u5feb\u7167\u662f\u201c\u6700\u65b0\u7684\u5feb\u7167\u201d\uff0c\u800c\u975e\u5f53\u524d\u4e8b\u52a1\u7684\u5feb\u7167\u3002</p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#3-3-1-2-hot","title":"3-3-1-2 HOT","text":"<p>\u5982\u679c\u8be5 tuple \u5728 HOT \u94fe\u4e2d\uff0c\u95ee\u9898\u5c31\u6709\u4e9b\u68d8\u624b\u3002</p> <ol> <li>\u6b64\u65f6\u4e0d\u65b9\u4fbf\u5c06 HOT \u94fe\u7834\u574f\u6389\u3002\uff08\u521b\u5efa\u7d22\u5f15\u7684\u65f6\u5019\u76f4\u63a5\u4fee\u6539 HEAP \u4e2d\u5185\u5bb9\u786e\u5b9e\u4e0d\u7b97\u5408\u7406\uff09</li> <li>\u4f46\u5982\u679c\u4e0d\u7834\u574f\uff0c\u5c31\uff08\u5fc5\u987b\uff09\u5c06\u8be5 tuple \u52a0\u5165\u5230\u65b0\u7d22\u5f15\u4e2d\uff0c\u800c\u8be5 HOT \u94fe\u53ef\u80fd\u548c\u65b0\u7d22\u5f15\u51b2\u7a81</li> </ol> <p>\u4e3a\u6b64\uff0cPostgreSQL \u91c7\u53d6\u4e86\u4e00\u79cd\u5de7\u5999\u5730\u65b9\u5f0f</p> <ol> <li>\u4e0d\u5c06\u8be5 tuple \u52a0\u5165\u5230\u65b0\u7d22\u5f15\u4e2d</li> <li>\u5bf9\u4e8e\u4e00\u4e9b\u4ecd\u7136\u53ef\u4ee5\u8bbf\u95ee\u8be5 tuple \u7684\u4e8b\u52a1\uff0c\u963b\u6b62\u5176\u4f7f\u7528\u65b0\u7d22\u5f15\u3002</li> </ol> <p>\u963b\u6b62\u7684\u65b9\u5f0f\u4e3a\uff1apg_index \u4e2d\u6709\u5b57\u6bb5 <code>indcheckxmin</code> \u3002\u5f53\u8be5\u5b57\u6bb5\u4e3a true \u65f6\uff0c\u5982\u679c\u4e8b\u52a1 T \u60f3\u8981\u4f7f\u7528\u8be5\u7d22\u5f15\uff0c\u9700\u8981\u786e\u4fdd\u81ea\u5df1\u6700\u65e7\u7684\u5feb\u7167\u5728\u521b\u5efa\u7d22\u5f15\u7684\u5feb\u7167\u4e4b\u540e\uff0c\u5373\u4e8b\u7269 T \u7684 <code>TransactionXmin</code> \uff08\u903b\u8f91\uff09\u5927\u4e8e <code>pg_index</code>  \u4e2d\u5bf9\u5e94 tuple \u7684 <code>xmin</code> </p> <ol> <li><code>TransactionXmin</code> \u8868\u793a\u5f53\u524d\u4e8b\u52a1\u7684\u6240\u6709\u5feb\u7167\u4e2d\uff0c\u6700\u5c0f\u7684\u7684 xmin\u3002\uff08\u5feb\u7167\u4e2d\uff0c <code>xmin</code> \u524d\u7684\u4e8b\u52a1\u90fd\u7ed3\u675f\u4e86\uff09</li> <li><code>pg_index</code>  \u4e2d\u5bf9\u5e94 tuple \u7684 <code>xmin</code> \u8868\u793a \u8be5\u7d22\u5f15\u521b\u5efa\u7684 xid</li> </ol> <p></p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#3-3-2-hot","title":"3-3-2 \u5bf9 HOT \u94fe\u4e0a\u7684\u5143\u7ec4\u6784\u5efa\u7d22\u5f15","text":"<p>\u7531\u4e8e\u521b\u5efa\u65b0\u7d22\u5f15\u4f1a\u5bfc\u81f4\u5df2\u6709\u7684 HOT \u94fe\u65e0\u6548\uff0c\u8fd9\u91cc\u8fd8\u9700\u8ba8\u8bba\u5982\u4f55\u5c06\u5df2\u6709 HOT \u94fe\u4e2d\u5143\u7ec4\u5982\u4f55\u6784\u5efa\u5230\u7d22\u5f15\u4e2d\u3002\u8003\u8651\u5982\u4e0b\u60c5\u5f62\uff0c\u73b0\u5728\u9700\u8981\u5bf9 <code>y</code> \u8fd9\u4e00\u5217\u521b\u5efa\u7d22\u5f15\uff0c\u53ea\u9700\u8981\u5c06 tuple_3 \u52a0\u5165\u5230\u7d22\u5f15\u4e2d(y=2)\u5373\u53ef\u3002\u7531\u4e8e\u4e00\u4e2a line pointer \u53ea\u80fd\u5728\u4e00\u4e2a HOT \u94fe\u4e2d\uff0c\u6240\u4ee5\u6b64\u65f6\u7d22\u5f15\u5e94\u8be5\u6307\u5411 lp_1\uff08\u6ce8\u610f tuple_1 \u6709 y=1)\u3002</p> <p></p> <p>\u5982\u679c\u60f3\u53bb\u201c\u4f18\u5316\u201c \u65b0HOT\u94fe\u7684\u957f\u5ea6\uff0c\u8ba9\u7d22\u5f15\u6307\u5411 lp_2 \u6216\u8005 lp_3\uff0c\u4f1a\u4ea7\u751f\u5f88\u591a\u95ee\u9898\uff0c\u4f8b\u5982\u6307\u5411 lp_3\uff0c\u5982\u679c\u540e\u7eed\u66f4\u65b0 tuple3 \u4e3a tuple4(x=1,y=2,z=3)\uff0c\u65e7\u5f88\u96be\u6e05\u7406 HOT \u94fe\uff0c</p> <p></p> <p>\u5728\u6e05\u7406\u65f6\u8fd8\u9700\u8981\u6ce8\u610f ptr_3 \u6709\u7d22\u5f15\u6307\u5411\uff0c\u9020\u6210\u4ee3\u7801\u590d\u6742\u5ea6\u5f88\u9ad8</p> <p></p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#4-create-index-concurrently-cic","title":"4 Create Index Concurrently (CIC) \u7684\u539f\u7406\u89e3\u6790","text":"<ul> <li>\u89e3\u51b3\u7684\u95ee\u9898\uff1a</li> <li>\u540c\u6b65\u521b\u5efa\u7d22\u5f15 <code>create index concurrently</code> \u89e3\u51b3\u4e86\u521b\u5efa\u7d22\u5f15\u671f\u95f4\uff0c<code>DML</code> \u8bed\u53e5\u4f1a\u88ab\u963b\u585e\u7684\u95ee\u9898\u3002</li> <li>\u601d\u8def\uff1a</li> <li>\u548c <code>pg_repack</code> , <code>pg_squeeze</code> \u7b49\u91cd\u5199\u8868\u7684\u5de5\u5177\u76f8\u4f3c\uff0c\u5185\u6838\u4e2d\u5b9e\u73b0\u7684\u540c\u6b65\u521b\u5efa\u7d22\u5f15\u4e5f\u4f7f\u7528\u4e86 \u201c\u5b58\u91cf + \u589e\u91cf\u201d \u7684\u65b9\u5f0f\u3002</li> <li>\u4e0d\u540c\u7684\u662f\uff0c\u5b98\u65b9\u63d0\u4f9b\u7684\u540c\u6b65\u521b\u5efa\u7d22\u5f15\u529f\u80fd\uff0c\u51e0\u4e4e\u6ca1\u6709\u548c\u4efb\u4f55\u5176\u4ed6\u7279\u6027\u8026\u5408\uff0c\u4f8b\u5982\u6ca1\u6709\u4f7f\u7528\u89e6\u53d1\u5668\u548c\u903b\u8f91\u590d\u5236\u3002</li> </ul> <p>\u96be\u70b9\u6709\uff1a 1. \u5728\u4e0d\u540c\u7684\u5b57\u6bb5\u4e0a\uff0c\u65b0\u521b\u5efa\u4e00\u4e2a\u7d22\u5f15\u4f1a\u7834\u574f <code>heap</code> \u4e2d\u7684\u539f <code>HOT</code> \u94fe\uff0c\u521b\u5efa\u7684\u8fc7\u7a0b\u4e2d\u4e5f\u4f1a\u5f71\u54cd\u5230\u65b0\u7684 <code>HOT</code> \u94fe\u3002 2. \u5728\u4e0d\u4f7f\u7528\u89e6\u53d1\u5668\u548c\u903b\u8f91\u590d\u5236\u7b49\u529f\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u8bb0\u5f55\u589e\u91cf\u6570\u636e\uff1f</p> <p>\u7b80\u5355\u6d41\u7a0b\uff1a\u901a\u8fc7\u4e09\u4e2a\u4e8b\u52a1\u5b8c\u6210</p> <ol> <li>\u9636\u6bb5\u4e00\uff1a\u521b\u5efa\u7d22\u5f15\u6587\u4ef6\u548c\u4fee\u6539\u7cfb\u7edf\u8868\u3002 \u6b64\u65f6\u7d22\u5f15\u4e3a <code>not ready</code> + <code>not valid</code>\u3002\u4f46\u5176\u4ed6 SQL \u9700\u8981\u9075\u5faa\u5bf9\u5e94\u7684 HOT \u89c4\u5219\u3002</li> <li>\u9636\u6bb5\u4e8c\uff1a\u83b7\u53d6\u5feb\u7167 <code>A</code> \uff0c\u4f7f\u7528\u5bf9\u8be5\u5feb\u7167\u53ef\u89c1\u7684\u5143\u7ec4\u521b\u5efa\u7d22\u5f15\uff0c\u5e76\u8bbe\u7f6e\u4e3a <code>ready</code> \u3002\u9636\u6bb5\u4e8c\u7ed3\u675f\u540e\uff0c\u5176\u4ed6 SQL \u4fee\u6539\u8868\u65f6\uff0c\u4e5f\u9700\u8981\u4fee\u6539\u8be5\u7d22\u5f15\u3002</li> <li>\u9636\u6bb5\u4e09\uff1a\u83b7\u53d6\u5feb\u7167 <code>B</code> \uff0c\u5c06\u5feb\u7167 <code>B</code> \u53ef\u89c1\u4f46\u5feb\u7167 <code>A</code> \u4e0d\u53ef\u89c1\u7684\u5143\u7ec4\u63d2\u5165\u7d22\u5f15\uff0c\u5e76\u8bbe\u7f6e\u4e3a <code>valid</code> \uff0c\u67e5\u8be2\u53ef\u4ee5\u4f7f\u7528\u8be5\u7d22\u5f15\u3002</li> </ol>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#4-1","title":"4-1 \u9636\u6bb5\u4e00\uff1a\u521b\u5efa\u7a7a\u7d22\u5f15","text":"<p>\u521b\u5efa\u7a7a\u7d22\u5f15\u7684\u6838\u5fc3\u539f\u56e0\u662f\uff1a\u5728\u5c06\u5b58\u91cf\u6570\u636e\u52a0\u5165\u7684\u7d22\u5f15\u4e2d\u65f6\uff0c\u786e\u4fdd\u5176\u4ed6\u8fde\u63a5\u7684\u4fee\u6539\u4e0d\u4f1a\u7834\u574f HOT\uff08\u66f4\u8fd1\u4e00\u6b65\u7684\u539f\u56e0\u5728\u9636\u6bb5 2 \u63cf\u8ff0\uff09\u3002\u65b9\u5f0f\u4e3a\u5411 pg_index \u4e2d\u8bb0\u5f55\u4e00\u4e2a <code>indisready==false &amp;&amp; indisvalid==false</code> \u7684\u7d22\u5f15\u3002\u6240\u4ee5\u95ee\u9898\u5728\u4e8e\uff1a\u5176\u4ed6\u8fde\u63a5\u5982\u4f55\u611f\u77e5\u5230\u8be5\u7d22\u5f15\u3002</p> <p>\u6bcf\u4e2a\u8fde\u63a5\u90fd\u4f1a\u7f13\u5b58\u81ea\u5df1 <code>relcache</code> \u548c <code>syscache</code> \uff0c\u5982\u679c\u6ca1\u6709\u63a5\u6536\u5230\u7f13\u5b58\u5931\u6548\u4fe1\u606f\uff0c\u8fd9\u4e9b\u7f13\u5b58\u4f1a\u4e00\u76f4\u4fdd\u7559\u3002\u4e00\u822c\u800c\u8a00\uff0c\u4e8b\u52a1\u5f00\u59cb\u65f6\uff0c\u4f1a\u5904\u7406\u6240\u6709\u7684\u7f13\u5b58\u5931\u6548\u6d88\u606f\uff0c\u5728\u4e8b\u52a1\u7684\u6267\u884c\u7684\u8fc7\u7a0b\u4e2d\uff0c\u4e5f\u6709\u57cb\u70b9\u6765\u5904\u7406\u5931\u6548\u4fe1\u606f\u3002\u800c\u4e14\uff0c\u5904\u7406\u7ed3\u679c\u4e0d\u4f1a\u8fd4\u56de\u7ed9\u53d1\u9001\u7aef\u3002</p> <p>\u6240\u4ee5\u4e3a\u4e86\u4fdd\u8bc1\u5176\u4ed6\u8fde\u63a5\u90fd\u4f1a\u770b\u5230\u65b0\u7d22\u5f15\uff0c\u7b80\u5355\u7684\u60f3\u6cd5\u662f\uff1a\u5728\u521b\u5efa\u7a7a\u7d22\u5f15\u7684\u4e8b\u52a1\u7ed3\u675f\u540e\uff0c\u9700\u8981\u7b49\u5230\u5f53\u524d\u6240\u6709\u5176\u4ed6\u4e8b\u52a1\u5168\u90e8\u7ed3\u675f\uff0c\u624d\u80fd\u5f00\u542f\u7b2c\u4e8c\u9636\u6bb5\u3002</p> <p></p> <p>\u5b9e\u9645\u4e0a\uff0c\u4ee3\u7801\u5b9e\u73b0\u4e0e\u4e0a\u8ff0\u6709\u6240\u5dee\u522b\uff1a</p> <p>PostgreSQL \u4e2d\uff0c\u8fd8\u6709\u4e00\u5904\u4f1a\u5904\u7406\u5931\u6548\u4fe1\u606f\uff1a\u5f53\u8fdb\u7a0b\u6267\u884c\u4fee\u6539\u8868\u7684\u64cd\u4f5c\u65f6\uff0c\u9700\u8981\u6253\u5f00\u8868\u83b7\u53d6 <code>relcache</code> \uff0c\u800c\u5728\u6253\u5f00\u8868\u64cd\u4f5c\u65f6\uff0c\u4f1a\u5904\u7406\u7f13\u5b58\u5931\u6548\u4fe1\u606f\u3002\u6253\u5f00\u8868\u83b7\u53d6 relcache \uff1a</p> <pre><code>relation_open/try_relation_open -&gt; LockRelationOid -&gt; AcceptInvalidationMessages\n</code></pre> <p>\u6240\u4ee5\u6b64\u65f6\uff1a\u5982\u679c\u5f53\u524d\u6267\u884c CIC \u7684\u8fde\u63a5\uff0c\u53ef\u4ee5\u83b7\u53d6\u5230\u8be5\u8868\u7684 <code>ShareLock</code> lock\uff0c\u53ef\u4ee5\u8bf4\u660e</p> <ol> <li>\u6b64\u65f6\u6ca1\u6709\u5176\u4ed6\u4e8b\u52a1\u6253\u5f00\u4e86\u8be5\u8868\u5e76\u4f1a\u80fd\u4fee\u6539\uff1a\u56e0\u4e3a <code>SharedLock</code> \u4ec5\u4e0d\u4e0e <code>select</code> \u3001 <code>select for update/share</code> \u76f8\u51b2\u7a81\uff0c\u4e0e\u4efb\u4f55\u4fee\u6539\u8868\u7684\u9501\u76f8\u51b2\u7a81</li> <li>\u540e\u7eed\u6253\u5f00\u8be5\u8868\u7684\u4e8b\u52a1\uff0c\u90fd\u4f1a\u5904\u7406\u4e4b\u524d\u53d1\u9001\u7684\u7f13\u5b58\u5931\u6548\u4fe1\u606f\uff0c\u53ef\u4ee5\u611f\u77e5\u5230\u8be5\u7a7a\u7d22\u5f15</li> </ol> <p></p> <p>\u5177\u4f53\u4ee3\u7801\u4e3a lmgr \u5c42\u7684 <code>WaitForLockers</code> \u51fd\u6570</p> <pre><code>/*\n * Now we must wait until no running transaction could have the table open\n * with the old list of indexes.  Use ShareLock to consider running\n * transactions that hold locks that permit writing to the table.  Note we\n * do not need to worry about xacts that open the table for writing after\n * this point; they will see the new index when they open it.\n */\nWaitForLockers(heaplocktag, ShareLock, true);\n</code></pre>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#4-2","title":"4-2 \u9636\u6bb5\u4e8c\uff1a\u4f7f\u7528\u5b58\u91cf\u6570\u636e\u521b\u5efa\u7d22\u5f15","text":"<p>\u5728\u786e\u4fdd\u6240\u6709\u8fde\u63a5\u90fd\u53d1\u73b0\u4e86\u8be5\u7d22\u5f15\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u5b58\u91cf\u6570\u636e\u521b\u5efa\u7d22\u5f15</p> <p>\u8be5\u8fc7\u7a0b\u548c\u666e\u901a\u7684\u521b\u5efa\u7d22\u5f15\u76f8\u4f3c\uff0c\u4f46\u662f\u8fdb\u884c <code>heap</code> \u626b\u63cf\u65f6\uff0c\u4f7f\u7528\u7684\u5feb\u7167\u4e0d\u540c\u3002\u5728\u4e00\u822c\u7684\u7d22\u5f15\u521b\u5efa\u4e2d\uff0c\u4f7f\u7528\u7684\u662f <code>SnapshotAny</code> \uff0c\u6240\u6709\u884c\u90fd\u53ef\u89c1\uff0c\u800c CIC \u4e2d\u4f7f\u7528\u7684\u662f\u5f53\u524d\u4e8b\u52a1\u7684\u5feb\u7167\u3002</p> <p>\u95ee\u9898\u4ecd\u7136\u51fa\u73b0\u5728 HOT \u94fe\u4e0a\uff0c\u867d\u7136\u5bf9\u4e8e\u521b\u5efa\u7d22\u5f15\u7684\u5b57\u6bb5\uff0c\u5f53\u524d\u4e0d\u4f1a\u4ea7\u751f\u65b0\u7684 HOT \u94fe\uff0c\u4f46\u662f\u4ecd\u7136\u4f1a\u6709\u65e7\u7684 HOT \u94fe \uff0c\u6240\u4ee5\u6784\u5efa\u7d22\u5f15\u7684\u65b9\u5f0f\u548c\u666e\u901a\u5730\u521b\u5efa\u7d22\u5f15\u76f8\u540c\u3002</p> <p>\u4e3e\u4e2a\u4f8b\u5b50:</p> <ul> <li>\u521d\u59cb\u72b6\u6001\u6709 tuple_1 \u548c tuple_2 \uff0c\u4ee5\u53ca\u5b57\u6bb5 a \u4e0a\u7684\u7d22\u5f15\u3002\u73b0\u5bf9\u5b57\u6bb5 b \u521b\u5efa\u5efa\u7d22\u5f15\uff0c</li> <li>tuple_1 \u5bf9\u5f53\u524d\u5feb\u7167\u4e0d\u53ef\u89c1\uff08too old\uff09</li> <li>tuple_2 \u53ef\u89c1\u3002\u5f53\u628a tuple_2 \u52a0\u5165\u5230\u7d22\u5f15\u4e2d\u65f6\uff0c\u7d22\u5f15\u503c\u4e3a b=2\uff0c\u4f46\u7d22\u5f15\u5165\u53e3\u6307\u5411 b=1 \u7684\u5143\u7ec4\uff08HOT\u94fe\u7684\u5f00\u5934\uff09\uff0c</li> <li>\u5728\u9636\u6bb52\u4e2d\uff0c\u6709\u5176\u4ed6\u4e8b\u52a1\u5c06 tuple_2 \u8fdb\u884c\u6210\u4e86 tuple_3 \uff0c\u5c06 c \u6539\u4e3a\u4e86 2\u3002\u8be5\u66f4\u65b0\u6ee1\u8db3 HOT \uff08a, b \u90fd\u6ca1\u6709\u53d8\uff09\uff0c\u6240\u4ee5\u4ecd\u5728 HOT \u94fe\u4e0a\u3002\u4f46\u662f tuple_3 \u5bf9\u5f53\u524d\u5feb\u7167\uff08CIC\uff09\u4e0d\u53ef\u89c1 (in feature)\uff0c\u6240\u4ee5\u4e0d\u5904\u7406\u3002</li> <li>\u5728\u9636\u6bb52\u4e2d\uff0c\u6709\u5176\u4ed6\u4e8b\u52a1\u5c06 tuple_3 \u8fdb\u884c\u6210\u4e86 tuple_4\uff0c\u5c06 b \u6539\u4e3a\u4e863\u3002\u8be5\u66f4\u65b0\u4e0d\u6ee1\u8db3 HOT\uff0c\u6240\u4ee5\u7d22\u5f15 idx_a \u9700\u8981\u521b\u5efa\u65b0\u7684\u6307\u9488</li> </ul> <p></p> <p>\u5f53\u7d22\u5f15\u6784\u5efa\u5b8c\u6bd5\u540e\uff0c\u5c06 pg_index \u7684\u4e2d\u5bf9\u5e94\u884c\u7684 <code>indisready</code> \u8bbe\u7f6e\u4e3a true\uff0c\u8fd9\u6837\u5176\u4ed6\u4e8b\u52a1\u540e\u7eed\u4fee\u6539\u8868\u65f6\uff0c\u4f1a\u540c\u6b65\u4fee\u6539\u8be5\u7d22\u5f15\u3002\u548c\u9636\u6bb51\u76f8\u4f3c\uff0c\u5f53\u524d\u4e8b\u52a1\u63d0\u4ea4\u540e\uff0c\u5f00\u542f\u65b0\u7684\u4e8b\u7269\uff08xact3\uff09\uff0c\u7b49\u5230\u5176\u4ed6\u4e8b\u52a1\u90fd\u611f\u77e5\u5230 <code>indisready=true</code> \u65f6\uff08\u540c\u6837\u4f7f\u7528 WaitForLockers \u65b9\u6848\uff09\uff0c\u5f00\u59cb\u9636\u6bb5\u4e09\u3002</p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#4-3","title":"4-3 \u9636\u6bb5\u4e09\uff1a \u589e\u91cf\u6570\u636e\u7684\u63d2\u5165","text":"<p>\u8be5\u6b65\u9aa4\u7684\u4e3b\u8981\u5de5\u4f5c\u4e3a\u628a\u9636\u6bb5\u4e8c\u4e2d\u9057\u6f0f\u7684 tuple \u52a0\u5165\u7d22\u5f15\u4e2d\u3002\u65b9\u6cd5\u4e3a\uff1a\u4f7f\u7528\u5f53\u524d\u7684\u4e8b\u52a1\u5feb\u7167\uff0c\u5c06\u8be5\u5feb\u7167\u53ef\u89c1\u7684\u4f46\u662f\u7d22\u5f15\u4e2d\u6ca1\u6709\u7684\u5143\u7ec4\uff0c\u52a0\u5165\u7d22\u5f15\u4e2d\uff0c\u5177\u4f53\u505a\u6cd5\u4e3a\uff1a</p> <p>\uff08\u4e00\uff09\u626b\u63cf\u7d22\u5f15\uff0c\u83b7\u53d6\u7d22\u5f15\u4e2d\u6240\u6709\u7684 ctid\uff0c\u5e76\u8fdb\u884c\u6392\u5e8f\uff0c\u5f97\u5230 <code>Tuplesortstate</code></p> <p>\uff08\u4e8c\uff09\u4f7f\u7528\u5f53\u524d\u5feb\u7167\uff0c\u8fdb\u884c\u5168\u8868\u626b\u63cf\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u884c\uff0c\u5728 <code>Tuplesortstate</code> \u641c\u7d22\u5bf9\u5e94\u7684 ctid\u3002\u6ce8\u610f\uff0c\u5982\u679c\u5168\u8868\u626b\u63cf\u5f97\u5230\u7684\u662f heap only tuple\uff0c\u5219\u4f7f\u7528\u5176\u6839 tuple \u7684 ctid\u3002\u5982\u679c\u5728 <code>Tuplesortstate</code> \u4e2d\u6ca1\u6709\u627e\u6253\uff0c\u5219\u5c06\u8be5\u5143\u7ec4\u63d2\u5165\u5230\u7d22\u5f15\u4e2d\u3002</p> <p>\u4e3e\u4e2a\u4f8b\u5b50\uff1a tuple_3 \u867d\u7136\u662f\u5728\u9636\u6bb5\u4e8c\u4e2d\u65b0\u589e\u7684 tuple \uff0c\u4f46\u662f\u5176\u6839 tuple\uff0c\u5373 tuple_1 \u5df2\u7ecf\u5728\u7d22\u5f15\u4e2d\u4e86\uff0c\u6240\u4ee5\u5728\u9636\u6bb5\u4e09\u4e2d\u5ffd\u7565\u3002\u800c tuple_4 \u4e0d\u5728 HOT \u94fe\u4e2d\uff0c\u4e5f\u4e0d\u5728\u7d22\u5f15\u4e2d\uff0c\u6240\u4ee5\u9700\u8981\u63d2\u5165\u5230\u7d22\u5f15\u4e2d\u3002</p> <p></p> <p>\u589e\u91cf\u6570\u636e\u63d2\u5165\u7ed3\u675f\u540e\uff0c\u4ecd\u4e0d\u80fd\u8bbe\u7f6e <code>indisvalid=true</code> \uff1a\u8003\u8651\u4e00\u4e2a\u5143\u7ec4\uff0c\u5b83\u5728\u9636\u6bb5\u4e8c\u4e2d\u88ab\u521b\u5efa\uff0c\u5374\u5728\u9636\u6bb5\u4e09\u524d\u88ab\u5220\u9664\uff0c\u6240\u4ee5\u6b64\u65f6\u8be5\u5143\u7ec4\u4ecd\u7136\u4e0d\u5728\u7d22\u5f15\u4e2d\uff0c\u4f46\u662f\u53ef\u80fd\u6709\u5176\u4ed6\u4e8b\u52a1\uff08\u4e8b\u52a1 T\uff09\u53ef\u4ee5\u770b\u5230\u8be5\u5143\u7ec4\uff0c\u6545\u6b64\u65f6\u9700\u8981\u7b49\u4e8b\u52a1 T \u7ed3\u675f\u3002\u7531\u4e8e\u65e0\u6cd5\u786e\u4fdd\u4e8b\u52a1 T \u4f1a\u4fee\u6539\u8868\uff0c\u6240\u4ee5\u8fd9\u91cc\u4e0d\u80fd\u4f7f\u7528\u9636\u6bb5\u4e00\u4e2d\u7684 <code>WaitForLockers</code> \u65b9\u6cd5\uff0c\u53ea\u80fd\u7b49\u5f85\u3002</p> <p>\u6240\u4ee5\u6d41\u7a0b\u4e3a\u5c06\u589e\u91cf\u6570\u636e\u63d2\u5165\u5143\u7ec4\u540e\uff0c\u83b7\u53d6\u5f53\u524d\u5feb\u7167\u7684 xmin\uff0c\u8bb0\u4e3a xminlimit\uff0c\u5e76\u63d0\u4ea4\u3002\u4e4b\u540e\u5f00\u542f\u65b0\u7684\u4e8b\u7269\uff0c\u7b49\u5f85\u6240\u6709\u542b\u6709 <code>snap.xmin&lt;xminlimit</code> \u7684\u5feb\u7167\u7684\u4e8b\u52a1\u5168\u90e8\u63d0\u4ea4\uff0c\u518d\u8bbe\u7f6e <code>indisvalid=true</code> \u5e76\u63d0\u4ea4\u3002</p> <p></p> <p>\u63d0\u4ea4\u540e\uff0c\u6240\u4ee5\u4e8b\u52a1\uff08\u5305\u62ec\u6b63\u5728\u8fd0\u884c\u7684\uff09\u90fd\u53ef\u4ee5\u4f7f\u7528\u65b0\u7d22\u5f15\u4e86\u3002</p>"},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#4-3-faq","title":"4-3 FAQ","text":""},{"location":"0013-postgresql/0024-index-in-pg/0025-hot-and-create-index/#4-3-1-unique-index","title":"4-3-1 unique index","text":"<p>\u95ee\u9898\uff1a\u521b\u5efa unique index \u65f6\uff0c\u9636\u6bb5\u4e8c\u548c\u9636\u6bb5\u4e09\u7684\u4e24\u6b21\u63d2\u5165\uff0c\u4f1a\u5f15\u8d77 unique index \u7684\u51b2\u7a81\uff1f</p> <p>unique \u51b2\u7a81\u90fd\u662f\u5728\u5404\u81ea\u7d22\u5f15\u7684 <code>aminsert</code> \u4e2d\u5b9e\u73b0\u7684\uff0c\u53ea\u6709 btree \u5b9e\u73b0\u4e86 unique \u7279\u6027</p> <p>\u4e3e\u4f8b1\uff1a\u8868\u6709 a,b \u4e09\u4e2a\u5b57\u6bb5\uff0c\u5176\u4e2d a \u4e0a\u6709\u7d22\u5f15</p> <ol> <li>tuple_1(1,1) \u5728\u9636\u6bb5\u4e8c\u4e2d\u88ab\u52a0\u5165\u5230\u7d22\u5f15\u4e2d\u3002</li> <li>\u5728\u9636\u6bb5\u4e8c\u4e2d\uff0c\u6709\u5176\u4ed6\u4e8b\u52a1\u5c06 tuple_1 \u66f4\u65b0\u4e3a\u4e86 tuple_2(2,1)</li> <li>\u5728\u9636\u6bb5\u4e09\u4e2d\uff0c\u5c06 tuple_2 \u63d2\u5165\u5230\u7d22\u5f15\u4e2d\u65f6\uff0c\u7d22\u5f15\u53d1\u73b0 tuple_1 \u53ef\u80fd\uff0c\u4f7f\u7528 <code>SNAPSHOT_DIRTY</code> \u770b tuple_1 \uff0c\u53d1\u73b0 tuple_1 \u5df2\u7ecf\u88ab\u5220\u9664\uff0c\u6240\u4ee5\u5b9e\u9645\u4e0a\u6ca1\u6709\u51b2\u7a81\uff0c\u8be5\u60c5\u51b5\u548c\u4e00\u822c\u7684\u7d22\u5f15\u63d2\u5165\u76f8\u540c\uff1a</li> </ol> <p></p> <p>\u4e3e\u4f8b2\uff1a\u8868\u6709 a,b \u4e09\u4e2a\u5b57\u6bb5\uff0c\u5176\u4e2d a \u4e0a\u6709\u7d22\u5f15</p> <ol> <li>tuple_1(1,1) \u5728\u9636\u6bb5\u4e8c\u4e2d\u88ab\u52a0\u5165\u5230\u7d22\u5f15\u4e2d\u3002</li> <li>\u5728\u9636\u6bb5\u4e8c\u4e2d\uff0c\u6709\u5176\u4ed6\u4e8b\u52a1\u5c06 tuple_1 \u66f4\u65b0\u4e3a\u4e86 tuple_2(2,1)</li> <li>\u5728\u9636\u6bb5\u4e09\u4e2d\uff0c\u6709\u5176\u4ed6\u4e8b\u52a1\u5c06 tuple_2 \u66f4\u65b0\u4e3a\u4e86 tuple_3(3,1)\uff0c\u800c\u6b64\u65f6\u6267\u884c CIC \u7684\u4e8b\u52a1\u5feb\u7167\u53ea\u80fd\u770b\u89c1 tuple_2</li> <li>\u5728\u9636\u6bb5\u4e09\u4e2d\uff0c\u5c06 tuple_2 \u63d2\u5165\u5230\u7d22\u5f15\u4e2d\u65f6\uff1a</li> <li>\u53d1\u73b0 tuple_1 \u53ef\u80fd\u6709\u51b2\u7a81\uff0c\u4f7f\u7528 <code>SNAPSHOT_DIRTY</code> \u770b tuple_1 \uff0c\u53d1\u73b0 tuple_1 \u5df2\u7ecf\u88ab\u5220\u9664\uff0c\u6240\u4ee5\u5b9e\u9645\u4e0a\u6ca1\u6709\u51b2\u7a81</li> <li>\u53d1\u73b0 tuple_3 \u53ef\u80fd\u6709\u51b2\u7a81\uff0c\u4f7f\u7528 <code>SNAPSHOT_DIRTY</code> \u770b tuple_3 \uff0c\u53d1\u73b0 tuple_3 \u6ca1\u6709\u5220\u9664\uff0c\u6b64\u65f6\u518d\u4f7f\u7528 <code>SNAPSHOT_SELF</code>\u00a0\u770b  tuple_2 \uff08\u5373\u5c06\u8981\u63d2\u5165\u7684\u5143\u7ec4\uff09\uff0c\u53d1\u73b0 tuple_2 \u5df2\u7ecf\u88ab\u5220\u9664\uff0c\u6545\u63d2\u5165\u5931\u8d25\uff0c\u4f46\u4e0d\u62a5\u9519\u3002</li> </ol> <p></p>"},{"location":"0031-learn_rust/0032-bstree/","title":"0032:Rust \u4e2d\u7684\u4e8c\u53c9\u641c\u7d22\u6811","text":"<p>\u3010\u672a\u5b8c\u5f85\u7eed\u3011</p> <ol> <li>\u8fd8\u662f\u901a\u8fc7\u5199\u4ee3\u7801\u6765\u5b66\u4e60\u65b0\u8bed\u8a00\u7b26\u5408\u6211\u7684\u4e60\u60ef\uff0c\u5199\u7684\u8fc7\u7a0b\u4e2d\u80fd\u611f\u77e5\u5230\u5fae\u5999\u7684\u5dee\u522b\u3002</li> <li>\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5173\u4e8e rust \u7684\u7b14\u8bb0\uff0c\u6240\u4ee5\u4f1a\u63d0\u5230\u5947\u5947\u602a\u602a\u7684\u5185\u5bb9</li> <li>\u4e8c\u53c9\u641c\u7d22\u6811\u5c5e\u4e8e\u975e\u5e38\u7b80\u5355\u7684\u5185\u5bb9\uff0c\u5176\u5b9e\u73b0\u4e0d\u518d\u8d58\u8ff0\u3002</li> </ol>"},{"location":"0031-learn_rust/0032-bstree/#_1","title":"\u6570\u636e\u7ed3\u6784\u8bbe\u8ba1","text":"<ol> <li>\u8003\u8651\u5230\u4e00\u4e2a\u8282\u70b9\u5728\u4efb\u4f55\u65f6\u5019\u90fd\u53ea\u6709\u4e00\u4e2a\u8282\u70b9\u6307\u5411\uff0c\u6240\u4ee5\u4f7f\u7528 <code>Box</code> \u4f5c\u4e3a\u6307\u9488\u975e\u5e38\u5408\u7406\u3002</li> <li>\u540c\u65f6\u4e00\u4e2a\u8282\u70b9\u7684\u5de6\u53f3\u5b50\u6811\u53ef\u80fd\u4e3a\u7a7a\uff0c\u800c Box \u672c\u8eab\u4e0d\u80fd\u4e3a\u7a7a\uff0c\u6240\u4ee5\u8fd8\u9700\u8981\u4f7f\u7528 <code>Option</code> \u5728\u8fdb\u884c\u4e00\u6b21\u5c01\u88c5</li> </ol> <p>\u6545\u5f97\u5230\u5982\u4e0b\u7684\u6570\u636e\u5b9a\u4e49\uff0c\u76f8\u8f83\u4e8e C/C++ \uff0c\u660e\u663e\u590d\u6742\u4e00\u4e9b <pre><code>struct BstreeNode&lt;T&gt; {\n    pub val: T,\n    pub left: Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;,\n    pub right: Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;,\n}\n</code></pre></p>"},{"location":"0031-learn_rust/0032-bstree/#copy-trait","title":"Copy trait","text":"<p>\u5728 C \u4e2d\uff0c\u5b9e\u73b0 insert \u6216 delete \u63a5\u53e3\uff0c\u9700\u8981\u8003\u8651\u53c2\u6570\u4f20\u9012\u4e3a \u201c\u5f15\u7528\u4f20\u9012\u201d \u8fd8\u662f \u201c\u62f7\u8d1d\u4f20\u9012\u201d\uff0c\u4e00\u822c\u800c\u8a00\u4f1a\u4f18\u5148\u8003\u8651\u8bbe\u8ba1\u4e3a\u5f15\u7528\u4f20\u9012\u3002</p> <p>\u4f46\u662f rust \u4e2d\uff0c\u503c\u4f20\u9012\u6709\u4e24\u79cd\u60c5\u51b5 1. \u8be5\u7c7b\u578b\u6709 <code>Copy trait</code> \uff0c\u90a3\u4e48\u53d8\u91cf\u4f5c\u4e3a\u51fd\u6570\u53c2\u6570\u65f6\uff0c\u6570\u636e\u4f1a\u88ab\u62f7\u8d1d\u4e00\u4efd\uff0c\u8c03\u7528\u540e\u53d8\u91cf\u53ef\u4ee5\u7ee7\u7eed\u4f7f\u7528\u3002 2. \u8be5\u7c7b\u578b\u65e0 <code>Copy trait</code> \uff0c\u90a3\u4e48\u53d8\u91cf\u4e3a\u51fd\u6570\u53c2\u6570\u65f6\uff0c\u6570\u636e\uff08\u4e5f\u53ef\u80fd\uff09\u4f1a\u88ab\u62f7\u8d1d\u4e00\u4efd\uff08\u53ef\u80fd\u4f1a\u88ab\u5185\u8054\u4f18\u5316\uff09\uff0c\u4f46\u662f\u8c03\u7528\u540e\u53d8\u91cf\u65e0\u6cd5\u4f7f\u7528</p> <p>\u4e00\u822c\u800c\u8a00\uff0c\u57fa\u672c\u6570\u636e\u7c7b\u578b\uff08\u5982 i32, f64 \u7b49\uff09\u90fd\u6709 <code>Copy trait</code> \uff0c\u800c\u590d\u6742\u6570\u636e\u7c7b\u578b\uff0c\u5c24\u5176\u662f\u5728\u5806\u4e0a\u6709\u5185\u5b58\u4f7f\u7528\u7684\uff08\u5982 String, Vec \u7b49\uff09\u5219\u6ca1\u6709 <code>Copy trait</code> \u3002</p>"},{"location":"0031-learn_rust/0032-bstree/#option","title":"Option \u4e2d\u503c\u7684\u79fb\u52a8\u95ee\u9898","text":"<p>\u8fd8\u8bb0\u5f97 cloudflare \u7684\u5d29\u6e83\u4e8b\u4ef6\u4e48 \uff0c\u5728 Option \u4e2d\u65e0\u8111\u4f7f\u7528 <code>unwrap()</code> \u83b7\u53d6\u5176\u4e2d\u7684\u53d8\u91cf\u53ef\u80fd\u4f1a\u5bfc\u81f4\u5d29\u6e83\u3002</p> <p></p> <p>\u5e76\u4e14\u6839\u636e\u4e00\u4e9b\u5de5\u7a0b\u5b9e\u8df5\uff0c\u4ee3\u7801\u4e2d\u5e94\u8be5\u5b8c\u5168\u7981\u7528 <code>unwrap()</code> \uff0c\u4e3a\u6b64\uff0c rust \u7ed9\u4e86\u4e00\u4e2a <code>Some()</code> \u8bed\u6cd5\u7528\u4e8e\u83b7\u53d6 <code>Option</code> \u4e2d\u7684\u503c\uff0c\u4f8b\u5982</p> <pre><code>    pub fn insert(mut node: &amp;mut Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;, val: T) -&gt; bool {\n        while let Some(n) = node {\n        }\n\n        /* More lines follow */\n</code></pre> <p>\u5bf9\u4e8e\u975e\u5f15\u7528\u7c7b\u578b\u7684 <code>Option</code> \u53d8\u91cf \uff0c\u4f7f\u7528 <code>Some()</code> \u8bed\u6cd5\u53ef\u80fd\u4f1a\u5bfc\u81f4 <code>Option</code> \u53d8\u91cf\u4e2d\u7684\u503c\u88ab\u79fb\u52a8\uff08move\uff09\uff0c\u4ece\u800c\u5bfc\u81f4\u540e\u7eed\u65e0\u6cd5\u4f7f\u7528\u8be5 <code>Option</code> \u53d8\u91cf\u3002\u8fd9\u548c <code>Copy trait</code> \u6709\u5173\u3002\u5bf9\u4e8e <code>i32</code> \u8fd9\u6837\u7684\u6709 <code>Copy trait</code> \u7684\u7c7b\u578b\uff0c\u4f7f\u7528 <code>Some()</code> \u4f1a\u662f\u5f97\u503c\u7684\u4e00\u4e2a\u62f7\u8d1d\uff0c\u539f <code>Option</code> \u53d8\u91cf\u4ecd\u7136\u53ef\u4ee5\u4f7f\u7528\uff1a <pre><code>let op_int: Option&lt;i32&gt; = Some(1);\n\nif let Some(mut val1) = op_int {\n    val1 = 2;\n    println!(\"Taken value: {val1}\");\n}\n\nif op_int.is_some() {\n    println!(\"{:?}\", op_int.unwrap());\n}\n</code></pre> \u5bf9\u4e8e <code>String</code> \u8fd9\u6837\u7684\u65e0 <code>Copy trait</code> \u7684\u7c7b\u578b\uff0c\u4f7f\u7528 <code>Some()</code> \u4f1a\u5bfc\u81f4\u503c\u88ab\u79fb\u52a8\uff0c\u539f <code>Option</code> \u53d8\u91cf\u5c06\u65e0\u6cd5\u518d\u4f7f\u7528\uff1a <pre><code>let op_string = Some(\"alpha\".to_string());\n\nif let Some(mut string_taken) = op_string {\n    string_taken = \"beta\".to_string();\n    println!(\"taken value: {}\", string_taken);\n}\n\n// This is NOT OK \n// if op_string.is_some() {\n//     println!(\"{:?}\", op_string.unwrap());\n// }\n</code></pre></p> <p>\u62a5\u9519\u5185\u5bb9\u4e3a <pre><code>error[E0382]: borrow of partially moved value: `op_string`\n  --&gt; src/option_test.rs:29:12\n   |\n23 |         if let Some(mut string_taken) = op_string {\n   |                     ---------------- value partially moved here\n...\n29 |         if op_string.is_some() {\n   |            ^^^^^^^^^ value borrowed here after partial move\n   |\n   = note: partial move occurs because value has type `String`, which does not implement the `Copy` trait\n</code></pre></p> <p>\u8fd9\u662f\u4e00\u4e2a\u5178\u578b\u7684 <code>partial move</code> \u9519\u8bef\u3002\u867d\u7136 option \u53d8\u91cf\u672c\u8eab\u5e76\u6ca1\u6709\u88ab\u79fb\u52a8\uff0c\u4f46\u662f\u5176\u4e2d\u7684\u503c\u88ab\u79fb\u52a8\u4e86\uff0c\u6240\u4ee5\u65e0\u6cd5\u518d\u4f7f\u7528\u8be5 option \u53d8\u91cf\u3002</p> <p>\u4e3a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u53ef\u4ee5\u83b7\u53d6 <code>Option</code> \u53d8\u91cf\u4e2d\u503c\u7684\u5f15\u7528\uff0c\u4ece\u800c\u907f\u514d\u503c\u88ab\u79fb\u52a8\uff0c\u5177\u4f53\u800c\u8a00\uff0c\u6709\u4e24\u79cd\u5199\u6cd5 <pre><code>let mut op_string_1 = Some(\"alpha\".to_string());\n\n// Method 1: using `ref mut`\n// if let Some(ref mut val) = op_string_1 {\n\n// Method 2: using `as_mut()`. More recommended\nif let Some(val) = op_string_2.as_mut() {\n    *val = \"beta\".to_string();\n    println!(\"taken value of string_1: {}\", val);\n}\n\nif op_string_1.is_some() {\n    println!(\"value of string_1 {:?}\", op_string_1.unwrap());\n}\n</code></pre></p> <p>\u5bf9\u4e8e\u5f15\u7528\u7c7b\u578b\u7684 <code>Option</code> \u53d8\u91cf\uff0c<code>as_mut</code> \u4e5f\u540c\u6837\u9002\u7528\u3002\u5b9e\u9645\u4e0a\uff0c<code>as_mut</code> \u7684\u5b98\u65b9\u4ecb\u7ecd\u4e3a \"Converts from &amp;mut Option to Option&lt;&amp;mut T&gt;\"\uff0c\u4f46\u662f\u5bf9\u4e8e\u975e\u5f15\u7528\u7684 <code>Option</code> \u53d8\u91cf\u800c\u8a00\uff0c<code>as_mut</code> \u4f1a\u81ea\u52a8\u751f\u6210\u4e00\u4e2a\u53ef\u53d8\u5f15\u7528\u3002\u6240\u4ee5\uff0c\u5982\u4e0b\u7684\u4ee3\u7801\u65e0\u6cd5\u901a\u8fc7\u7f16\u8bd1\uff0c\u56e0\u4e3a\u6709\u4e24\u6b21\u53ef\u53d8\u501f\u7528\uff1a <pre><code>let mut op_string_3 = Some(\"aaa\".to_string());\n\nif let Some(val) = op_string_3.as_mut() {\n    *val = \"bbb\".to_string();\n    println!(\"value of string_3: {}\", val);\n\n    if let Some(val2) = op_string_3.as_mut() {\n        *val2 = \"ccc\".to_string();\n        println!(\"value of string_3: {}\", val2);\n    }\n\n    *val = \"ddd\".to_string();\n}\n</code></pre> <p>\u4f46\u662f\uff0c\u5982\u679c\u53bb\u6389 <code>*val = \"ddd\".to_string();</code> \uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u7f16\u8bd1\u3002\u539f\u56e0\u662f\uff0c\u73b0\u4ee3 <code>rust</code> \u901a\u8fc7\u53d8\u91cf\u6700\u540e\u4f7f\u7528\u7684\u4f4d\u7f6e\u5224\u65ad\u751f\u547d\u5468\u671f\uff0c\u5982\u679c\u6ca1\u6709 <code>*val = \"ddd\".to_string();</code> ,<code>val</code> \u7684\u751f\u547d\u5468\u671f\u5728\u7b2c\u4e00\u6b21 <code>print</code> \u540e\u5c31\u7ed3\u675f\u4e86\uff0c\u6240\u4ee5\u4e0d\u4f1a\u51b2\u7a81\u3002</p>"},{"location":"0031-learn_rust/0032-bstree/#_2","title":"\u7c7b\u578b\u5d4c\u5957","text":"<p>\u4f8b\u5982\uff1a<code>node: &amp;mut Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;</code> , mut\u610f\u5473\u7740\u5185\u90e8\u7684\u6240\u6709\u4e1c\u897f\u90fd\u53ef\u4ee5\u6539\uff0c\u4f8b\u5982\u53ef\u4ee5\u505a\u4e00\u4e0b\u64cd\u4f5c\uff1a</p> <pre><code>if let Some(box_ref) = node {\n    if let Some(node_ref) = box_ref {\n        // some code\n    }\n}\n</code></pre>"},{"location":"0031-learn_rust/0032-bstree/#_3","title":"\u5e76\u975e\u5b8c\u5584\u7684\u501f\u7528\u89c4\u5219\u68c0\u67e5","text":"<p>\u67d0\u4e9b\u4ee3\u7801\u53ef\u80fd\u6ca1\u6709\u8fdd\u80cc\u501f\u7528\u89c4\u5219\u68c0\u67e5\uff0c\u4f46\u662f\u65e0\u6cd5\u901a\u8fc7\u7f16\u8bd1\uff0c\u4f8b\u5982\u6211\u9700\u8981\u5220\u9664\u503c\u6700\u5927\u7684\u8282\u70b9\uff1a</p> <pre><code>fn extract_max(mut node: &amp;mut Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;) -&gt; T {\n    //This is NOT OK since node is borrowed inside the loop\n    while let Some(r) = node {       // `r` borrows from `node`\n        if r.right.is_some() {\n            node = &amp;mut r.right;     // `r` must stay alive for this assignment\n        } else {\n            break;                   // `r` still considered borrowed after break\n        }\n    }\n\n    let mut max_node = node.take().expect(\"fail to get the max value\");\n    *node = max_node.left.take();\n\n    max_node.val\n}\n</code></pre> <p>\u8fd9\u91cc\u7684\u6838\u5fc3\u95ee\u9898\u662f\uff0cnode \u5728\u9000\u51fa\u5faa\u73af\u540e\uff0c\u4ecd\u7136\u88ab\u8ba4\u4e3a\u662f\u88ab\u501f\u7528\u7684\u72b6\u6001\uff0c\u4ece\u800c\u5bfc\u81f4\u540e\u7eed\u7684 <code>take()</code> \u64cd\u4f5c\u65e0\u6cd5\u8fdb\u884c\u3002\u5bf9\u6bd4\u4e0b\u9762\u7684\u4ee3\u7801\uff1a</p> <pre><code>pub fn insert(mut node: &amp;mut Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;, val: T) -&gt; bool {\n    while let Some(n) = node {\n        match val.cmp(&amp;n.val) {\n            std::cmp::Ordering::Less =&gt; node = &amp;mut n.left,\n            std::cmp::Ordering::Greater =&gt; node = &amp;mut n.right,\n            std::cmp::Ordering::Equal =&gt; return false,\n        }\n    }\n\n    *node = Some(BstreeNode::new(val));\n    true\n}\n</code></pre> <p><code>insert</code> \u51fd\u6570\u53ef\u4ee5\u901a\u8fc7\u7f16\u8bd1\uff0c\u539f\u56e0\u5728\u4e8e\u5faa\u73af\u9000\u51fa\u540e\uff0cnode \u4e00\u5b9a\u662f <code>None</code>\uff0c\u6240\u4ee5\u4e0d\u5b58\u5728\u501f\u7528\u7684\u95ee\u9898\u3002</p> <p>\u6240\u4ee5\u8fd9\u662f\u4e00\u4e2a\u975e\u5e38\u96be\u53d7\u7684\u9650\u5236\uff0c\u76ee\u524d\u6211\u77e5\u9053\u7684\uff0c\u6700\u597d\u7684\u5b9e\u73b0 <code>extract_max</code> \u7684\u65b9\u5f0f\u4e3a\uff08\u975e\u9012\u5f52\uff09\uff0c\u4f46\u662f\u8fd9\u79cd\u5b9e\u73b0\u65b9\u5f0f\u4ecd\u4f1a\u4f7f\u7528 <code>expect</code> \uff08\u867d\u7136\u63d0\u524d\u505a\u4e86\u68c0\u67e5\uff09\u3002\u5f53\u7136\u9012\u5f52\u7684\u5199\u6cd5\u66f4\u52a0\u7b80\u6d01\uff0c\u4f46\u662f\u6709\u6808\u6ea2\u51fa\u7684\u95ee\u9898\u3002</p> <pre><code>if node.is_none() {\n    panic!(\"extract_max called on empty node\");\n}\n\nwhile node.as_ref().is_some_and(|n| n.right.is_some()) {\n    node = &amp;mut node.as_mut().expect(\"parano check\").right;\n}\n</code></pre>"},{"location":"0031-learn_rust/0032-bstree/#_4","title":"\u751f\u547d\u5468\u671f\u7684\u7ed1\u5b9a\uff1a","text":"<p>\u5728bstree\u4e2d\uff0c\u5982\u679c\u8981\u901a\u8fc7\u503c\u5f97\u5230\u4e00\u4e2a\u8282\u70b9\u7684\u53ef\u53d8\u5f15\u7528\uff0c\u9700\u8981\u58f0\u660e\u4e00\u4e2a\u7c7b\u4f3c\u7684\u51fd\u6570</p> <pre><code>fn get_target_node_mut(\n    mut node: &amp;mut Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;,\n    val: &amp;T,\n) -&gt; Option&lt;&amp;mut Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;&gt;\n</code></pre> <p>\u4f46\u662f\u8be5\u51fd\u6570\u65e0\u6cd5\u901a\u8fc7\u7f16\u8bd1\uff0c\u62a5\u9519\u5185\u5bb9\u4e3a\uff1a</p> <pre><code>missing lifetime specifier\nthis function's return type contains a borrowed value, but the signature does not say whether it is borrowed from `node` or `val`\n</code></pre> <p>\u8fd9\u662f\u56e0\u4e3a rust \u65e0\u6cd5\u786e\u5b9a\u8fd4\u56de\u503c\u7684\u751f\u547d\u5468\u671f\u5230\u5e95\u662f\u548c <code>node</code> \u76f8\u5173\u8fd8\u662f\u548c <code>val</code> \u76f8\u5173\uff0c\u89e3\u51b3\u65b9\u6848\u4e3a\u589e\u52a0\u751f\u547d\u5468\u671f\u7684\u7ed1\u5b9a\uff1a</p> <pre><code>fn get_target_node_mut&lt;'a&gt;(\n    mut node: &amp;'a mut Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;,\n    val: &amp;T,\n) -&gt; Option&lt;&amp;'a mut Option&lt;Box&lt;BstreeNode&lt;T&gt;&gt;&gt;&gt;\n</code></pre> <p>\u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u7ecf\u5178\u6848\u4f8b\u6765\u8bf4\u660e\u51fd\u6570\u4e2d\u751f\u547d\u5468\u671f\u7ed1\u5b9a\u7684\u5fc5\u8981\u6027\uff1a</p> <pre><code>fn main() {\n    let long_lived = String::from(\"I am global-ish\");\n    let result;\n\n    {\n        let short_lived = String::from(\"I die soon\");\n\n        // We call a function here...\n        result = pick_best(&amp;long_lived, &amp;short_lived); \n    } // &lt;--- `short_lived` is dropped (freed) here!\n\n    // DANGER ZONE: \n    // If `result` points to `short_lived`, accessing it here crashes the program.\n    // If `result` points to `long_lived`, accessing it here is safe.\n    println!(\"Result is: {}\", result); \n}\n</code></pre> <p>\u5728\u5b9e\u73b0\u4e2d\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>?</code> \u6765\u7b80\u5316\u4ee3\u7801:</p> <p><pre><code>let ordering: std::cmp::Ordering = val.cmp(&amp;node.as_ref()?.val);\n</code></pre> <code>?</code> \u5728\u8fd9\u91cc\u7684\u542b\u4e49\u4e3a\uff1a\u5982\u679c <code>node</code> \u4e3a <code>None</code> \uff0c\u5219\u8c03\u7528\u51fd\u6570\u76f4\u63a5\u8fd4\u56de <code>None</code>\uff0c\u7ee7\u7eed\u6267\u884c\u3002\u8fd9\u4e5f\u8981\u6c42\u51fd\u6570\u7684\u8fd4\u56de\u503c\u4e3a <code>Option</code> \u7c7b\u578b\u3002</p>"},{"location":"0031-learn_rust/0032-bstree/#rust","title":"rust \u7684\u5148\u8fdb\u6027","text":""},{"location":"0031-learn_rust/0032-bstree/#trait","title":"trait \u7684\u4f7f\u7528","text":"<p>\u5728\u6a21\u7248\u7f16\u7a0b\u4e2d\uff0ctrait \u4f1a\u8981\u6c42\u53d8\u91cf\u5177\u6709\u7279\u5b9a\u7684\u6027\u8d28\uff0c\u4f7f\u5f97\u6a21\u7248\u7684\u4f5c\u7528\u8303\u56f4\u66f4\u52a0\u660e\u786e\u3002\u4f8b\u5982\uff1a</p> <pre><code>impl&lt;T: std::cmp::Ord&gt; BstreeNode&lt;T&gt; {\n</code></pre> <p>\u53ef\u4ee5\u8981\u6c42\u7c7b\u578b <code>T</code> \u5177\u6709 <code>Ord</code> trait\uff0c\u4ece\u800c\u53ef\u4ee5\u4f7f\u7528 <code>&lt;</code> , <code>&gt;</code> \u7b49\u6bd4\u8f83\u64cd\u4f5c\u7b26\u3002\u540c\u65f6\uff0c\u5728\u5b9e\u73b0\u7684\u5185\u90e8\uff0c\u53ef\u4ee5\u67d0\u4e9b\u51fd\u6570\u5177\u6709\u66f4\u591a\u7684 trait \u9650\u5236\uff0c\u4f8b\u5982:</p> <pre><code>pub fn print_sub_tree&lt;W: Write&gt;(\n    writer: &amp;mut W,\n    node: &amp;Box&lt;BstreeNode&lt;T&gt;&gt;,\n    indent: i32,\n    tag: &amp;str,\n) where\n    T: std::fmt::Display,\n</code></pre> <p>\u53ef\u4ee5\u8981\u6c42\u7c7b\u578b <code>T</code> \u53ef\u4ee5\u88ab\u683c\u5f0f\u5316\u8f93\u51fa\uff0c\u4ece\u800c\u53ef\u4ee5\u4f7f\u7528 <code>{}</code> \u8fdb\u884c\u6253\u5370\u3002</p>"},{"location":"0031-learn_rust/0032-bstree/#option_1","title":"Option \u7c7b\u578b","text":"<p>\u5728\u6211\u76ee\u524d\u7684\u89c6\u89d2\u4e2d\uff0cOption \u89e3\u51b3\u7684\u6700\u5927\u95ee\u9898\u662f\uff0c\u662f\u5e94\u8be5\u7531\u8c03\u7528\u8005\u6216\u662f\u6709\u51fd\u6570\u5b9e\u73b0\u53bb\u5224\u65ad\u4e00\u4e2a\u6307\u9488\u662f\u5426\u4e3a\u7a7a\uff0c\u4e5f\u8d77\u5230\u4e86\u63d0\u9192\u5f00\u53d1\u8005\u6ce8\u610f\u7a7a\u6307\u9488\u7684\u4f5c\u7528\u3002</p>"}]}